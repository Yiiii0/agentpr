{"type":"thread.started","thread_id":"019c9244-d142-7a02-942f-2330d1ee4f17"}
{"type":"turn.started"}
{"type":"item.completed","item":{"id":"item_0","type":"reasoning","text":"**Acknowledging task and resolving path conflict**"}}
{"type":"item.completed","item":{"id":"item_1","type":"agent_message","text":"Using the `agentpr-implement-and-validate` skill for this stage. Iâ€™ll first inspect the in-repo contract and repo docs to confirm required checks and target scope, then implement the smallest possible Forge baseline patch and run the exact validation commands."}}
{"type":"item.completed","item":{"id":"item_2","type":"reasoning","text":"**Inspecting repository state**"}}
{"type":"item.started","item":{"id":"item_3","type":"command_execution","command":"/bin/zsh -lc \"rg --files --hidden -g '\"'!*node_modules*'\"' -g '\"'!*'\"\\\\.git*' | head -n 200\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_4","type":"command_execution","command":"/bin/zsh -lc 'pwd && git rev-parse --abbrev-ref HEAD && git status --short'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_3","type":"command_execution","command":"/bin/zsh -lc \"rg --files --hidden -g '\"'!*node_modules*'\"' -g '\"'!*'\"\\\\.git*' | head -n 200\"","aggregated_output":"LICENSE\nMIGRATION_GUIDE_v1.0.md\nopenclaw/index.ts\nopenclaw/package.json\nopenclaw/README.md\nopenclaw/openclaw.plugin.json\nREADME.md\ncookbooks/customer-support-chatbot.ipynb\ncookbooks/helper/__init__.py\ncookbooks/helper/mem0_teachability.py\ncookbooks/mem0-autogen.ipynb\ndocs/favicon.svg\nvercel-ai-sdk/src/mem0-utils.ts\nvercel-ai-sdk/src/mem0-generic-language-model.ts\nvercel-ai-sdk/src/stream-utils.ts\nvercel-ai-sdk/src/index.ts\nvercel-ai-sdk/src/mem0-provider.ts\nvercel-ai-sdk/src/mem0-provider-selector.ts\nvercel-ai-sdk/src/provider-response-provider.ts\nvercel-ai-sdk/src/mem0-facade.ts\nvercel-ai-sdk/src/mem0-types.ts\nvercel-ai-sdk/teardown.ts\nvercel-ai-sdk/tsconfig.json\nvercel-ai-sdk/tsup.config.ts\nvercel-ai-sdk/package.json\nvercel-ai-sdk/README.md\nvercel-ai-sdk/tests/memory-core.test.ts\nvercel-ai-sdk/tests/mem0-toolcalls.test.ts\nvercel-ai-sdk/tests/generate-output.test.ts\nvercel-ai-sdk/tests/text-properties.test.ts\ndocs/cookbooks/essentials/memory-expiration-short-and-long-term.mdx\ndocs/cookbooks/essentials/building-ai-companion.mdx\ndocs/cookbooks/essentials/exporting-memories.mdx\ndocs/cookbooks/essentials/tagging-and-organizing-memories.mdx\ndocs/cookbooks/essentials/choosing-memory-architecture-vector-vs-graph.mdx\ndocs/cookbooks/essentials/entity-partitioning-playbook.mdx\ndocs/cookbooks/essentials/controlling-memory-ingestion.mdx\nvercel-ai-sdk/tests/utils-test/cohere-integration.test.ts\nvercel-ai-sdk/tests/utils-test/google-integration.test.ts\nvercel-ai-sdk/tests/utils-test/groq-integration.test.ts\nvercel-ai-sdk/tests/utils-test/anthropic-integration.test.ts\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts\ndocs/cookbooks/frameworks/multimodal-retrieval.mdx\ndocs/cookbooks/frameworks/llamaindex-react.mdx\ndocs/cookbooks/frameworks/eliza-os-character.mdx\ndocs/cookbooks/frameworks/gemini-3-with-mem0-mcp.mdx\ndocs/cookbooks/frameworks/chrome-extension.mdx\ndocs/cookbooks/frameworks/llamaindex-multiagent.mdx\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-groq.test.ts\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai.test.ts\nvercel-ai-sdk/tests/mem0-provider-tests/mem0_anthropic.test.ts\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-cohere.test.ts\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-google.test.ts\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts\nvercel-ai-sdk/jest.config.js\ndocs/cookbooks/companions/nodejs-companion.mdx\ndocs/cookbooks/companions/voice-companion-openai.mdx\ndocs/cookbooks/companions/travel-assistant.mdx\ndocs/cookbooks/companions/quickstart-demo.mdx\ndocs/cookbooks/companions/ai-tutor.mdx\ndocs/cookbooks/companions/youtube-research.mdx\ndocs/cookbooks/companions/local-companion-ollama.mdx\nvercel-ai-sdk/config/test-config.ts\nvercel-ai-sdk/nodemon.json\nvercel-ai-sdk/pnpm-lock.yaml\nCONTRIBUTING.md\nopenmemory/docker-compose.yml\ndocs/cookbooks/integrations/mastra-agent.mdx\ndocs/cookbooks/integrations/tavily-search.mdx\ndocs/cookbooks/integrations/openai-tool-calls.mdx\ndocs/cookbooks/integrations/agents-sdk-tool.mdx\ndocs/cookbooks/integrations/aws-bedrock.mdx\ndocs/cookbooks/integrations/neptune-analytics.mdx\ndocs/cookbooks/integrations/healthcare-google-adk.mdx\ndocs/_snippets/blank-notif.mdx\ndocs/_snippets/paper-release.mdx\ndocs/_snippets/get-help.mdx\ndocs/_snippets/async-memory-add.mdx\ndocs/cookbooks/operations/content-writing.mdx\ndocs/cookbooks/operations/email-automation.mdx\ndocs/cookbooks/operations/team-task-agent.mdx\ndocs/cookbooks/operations/deep-research.mdx\ndocs/cookbooks/operations/support-inbox.mdx\ndocs/cookbooks/overview.mdx\ndocs/openapi.json\nopenmemory/README.md\nopenmemory/run.sh\nopenmemory/api/main.py\nopenmemory/api/.env.example\nevaluation/evals.py\nevaluation/Makefile\ndocs/api-reference/entities/delete-user.mdx\ndocs/api-reference/entities/get-users.mdx\ndocs/migration/oss-to-platform.mdx\ndocs/migration/api-changes.mdx\ndocs/migration/breaking-changes.mdx\ndocs/migration/v0-to-v1.mdx\nopenmemory/api/Dockerfile\nopenmemory/api/alembic.ini\nopenmemory/api/requirements.txt\nopenmemory/api/README.md\nopenmemory/api/default_config.json\nopenmemory/api/config.json\nopenmemory/api/.dockerignore\nopenmemory/api/.python-version\ndocs/docs.json\ndocs/llms.txt\nopenmemory/backup-scripts/export_openmemory.sh\ndocs/api-reference/events/get-event.mdx\ndocs/api-reference/events/get-events.mdx\ndocs/openmemory/quickstart.mdx\ndocs/openmemory/integrations.mdx\ndocs/openmemory/overview.mdx\nopenmemory/api/alembic/README\ndocs/api-reference/project/add-project-member.mdx\ndocs/api-reference/project/get-project.mdx\ndocs/api-reference/project/get-projects.mdx\ndocs/api-reference/project/delete-project.mdx\ndocs/api-reference/project/get-project-members.mdx\ndocs/api-reference/project/create-project.mdx\ndocs/api-reference/organizations-projects.mdx\nopenmemory/compose/weaviate.yml\nopenmemory/compose/elasticsearch.yml\nopenmemory/compose/qdrant.yml\nopenmemory/compose/opensearch.yml\nopenmemory/compose/milvus.yml\nopenmemory/compose/pgvector.yml\nopenmemory/compose/faiss.yml\nopenmemory/compose/redis.yml\nopenmemory/compose/chroma.yml\nopenmemory/Makefile\nopenmemory/api/app/mcp_server.py\nopenmemory/api/app/schemas.py\ndocs/core-concepts/memory-operations/delete.mdx\ndocs/core-concepts/memory-operations/add.mdx\ndocs/core-concepts/memory-operations/update.mdx\ndocs/core-concepts/memory-operations/search.mdx\ndocs/core-concepts/memory-types.mdx\nevaluation/metrics/llm_judge.py\nevaluation/metrics/utils.py\nserver/main.py\nserver/.env.example\nserver/dev.Dockerfile\nserver/README.md\nserver/Makefile\nserver/Dockerfile\nserver/requirements.txt\nserver/docker-compose.yaml\nembedchain/README.md\ndocs/api-reference/memory/add-memories.mdx\ndocs/api-reference/memory/search-memories.mdx\ndocs/api-reference/memory/history-memory.mdx\ndocs/api-reference/memory/delete-memories.mdx\ndocs/api-reference/memory/batch-update.mdx\ndocs/api-reference/memory/get-memories.mdx\ndocs/api-reference/memory/delete-memory.mdx\ndocs/api-reference/memory/feedback.mdx\ndocs/api-reference/memory/create-memory-export.mdx\ndocs/api-reference/memory/update-memory.mdx\ndocs/api-reference/memory/get-memory-export.mdx\ndocs/api-reference/memory/batch-delete.mdx\ndocs/api-reference/memory/get-memory.mdx\ndocs/templates/api_reference_template.mdx\ndocs/templates/migration_guide_template.mdx\ndocs/templates/concept_guide_template.mdx\ndocs/templates/quickstart_template.mdx\ndocs/templates/operation_guide_template.mdx\ndocs/templates/cookbook_template.mdx\ndocs/templates/section_overview_template.mdx\ndocs/templates/feature_guide_template.mdx\ndocs/templates/release_notes_template.mdx\ndocs/templates/troubleshooting_playbook_template.mdx\ndocs/templates/integration_guide_template.mdx\ndocs/templates/parameters_reference_template.mdx\ndocs/integrations.mdx\nembedchain/notebooks/together.ipynb\nembedchain/notebooks/hugging_face_hub.ipynb\nembedchain/notebooks/embedchain-chromadb-server.ipynb\nembedchain/notebooks/anthropic.ipynb\nembedchain/notebooks/openai.ipynb\nembedchain/notebooks/elasticsearch.ipynb\nembedchain/notebooks/pinecone.ipynb\nembedchain/notebooks/ollama.ipynb\nembedchain/notebooks/aws-bedrock.ipynb\nembedchain/notebooks/vertex_ai.ipynb\nembedchain/notebooks/lancedb.ipynb\nembedchain/notebooks/azure-openai.ipynb\nembedchain/notebooks/openai_azure.yaml\nembedchain/notebooks/chromadb.ipynb\nembedchain/notebooks/azure_openai.yaml\nembedchain/notebooks/gpt4all.ipynb\nembedchain/notebooks/clarifai.ipynb\nembedchain/notebooks/llama2.ipynb\nembedchain/notebooks/cohere.ipynb\nembedchain/notebooks/opensearch.ipynb\nembedchain/notebooks/jina.ipynb\nembedchain/notebooks/embedchain-docs-site-example.ipynb\nembedchain/poetry.lock\nembedchain/poetry.toml\nopenmemory/api/app/utils/permissions.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_4","type":"command_execution","command":"/bin/zsh -lc 'pwd && git rev-parse --abbrev-ref HEAD && git status --short'","aggregated_output":"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0\nfeature/forge-20260224-172250\n?? .agentpr_runtime/\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_5","type":"reasoning","text":"**Inspecting contract files in runtime folder**"}}
{"type":"item.completed","item":{"id":"item_6","type":"agent_message","text":"Iâ€™ve confirmed the workspace is clean except the runtime folder. Next Iâ€™m reading the in-repo contract/runtime artifacts and repo contribution docs to derive the exact implementation and validation commands without touching out-of-repo files."}}
{"type":"item.started","item":{"id":"item_7","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' CONTRIBUTING.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_8","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,220p' .agentpr_runtime/contracts/baseline_mem0_20260224.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_9","type":"command_execution","command":"/bin/zsh -lc 'ls -la .agentpr_runtime && rg --files .agentpr_runtime'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_8","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,220p' .agentpr_runtime/contracts/baseline_mem0_20260224.md\"","aggregated_output":"# baseline_mem0_20260224 contract\nrepo: mem0ai/mem0\nmode: push_only\nengine: codex_exec\ngoal: non_interactive_baseline\nnotes:\n- Run full forge integration workflow in prepared workspace.\n- Keep minimal diff and follow repo contribution rules.\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_7","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' CONTRIBUTING.md\"","aggregated_output":"# Contributing to mem0\n\nLet us make contribution easy, collaborative and fun.\n\n## Submit your Contribution through PR\n\nTo make a contribution, follow these steps:\n\n1. Fork and clone this repository\n2. Do the changes on your fork with dedicated feature branch `feature/f1`\n3. If you modified the code (new feature or bug-fix), please add tests for it\n4. Include proper documentation / docstring and examples to run the feature\n5. Ensure that all tests pass\n6. Submit a pull request\n\nFor more details about pull requests, please read [GitHub's guides](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request).\n\n\n### ðŸ“¦ Development Environment\n\nWe use `hatch` for managing development environments. To set up:\n\n```bash\n# Activate environment for specific Python version:\nhatch shell dev_py_3_9   # Python 3.9\nhatch shell dev_py_3_10  # Python 3.10  \nhatch shell dev_py_3_11  # Python 3.11\nhatch shell dev_py_3_12  # Python 3.12\n\n# The environment will automatically install all dev dependencies\n# Run tests within the activated shell:\nmake test\n```\n\n### ðŸ“Œ Pre-commit\n\nTo ensure our standards, make sure to install pre-commit before starting to contribute.\n\n```bash\npre-commit install\n```\n\n### ðŸ§ª Testing\n\nWe use `pytest` to test our code across multiple Python versions. You can run tests using:\n\n```bash\n# Run tests with default Python version\nmake test\n\n# Test specific Python versions:\nmake test-py-3.9   # Python 3.9 environment\nmake test-py-3.10  # Python 3.10 environment\nmake test-py-3.11  # Python 3.11 environment\nmake test-py-3.12  # Python 3.12 environment\n\n# When using hatch shells, run tests with:\nmake test  # After activating a shell with hatch shell test_XX\n```\n\nMake sure that all tests pass across all supported Python versions before submitting a pull request.\n\nWe look forward to your pull requests and can't wait to see your contributions!\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_9","type":"command_execution","command":"/bin/zsh -lc 'ls -la .agentpr_runtime && rg --files .agentpr_runtime'","aggregated_output":"total 8\ndrwxr-xr-x@ 15 yi  staff   480 Feb 24 19:48 .\ndrwxr-xr-x@ 28 yi  staff   896 Feb 24 17:25 ..\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 bun-global\ndrwxr-xr-x@ 12 yi  staff   384 Feb 24 18:54 cache\n-rw-r--r--@  1 yi  staff  1167 Feb 24 19:47 codex_last_message.txt\ndrwxr-xr-x@  3 yi  staff    96 Feb 24 19:48 contracts\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 coverage\ndrwxr-xr-x@  4 yi  staff   128 Feb 24 18:54 data\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 npm-global\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 pnpm-home\ndrwxr-xr-x@  3 yi  staff    96 Feb 24 18:54 pycache\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 rye-home\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 tmp\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 tox\ndrwxr-xr-x@  2 yi  staff    64 Feb 24 18:54 uv-tools\n.agentpr_runtime/codex_last_message.txt\n.agentpr_runtime/contracts/baseline_mem0_20260224.md\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_10","type":"reasoning","text":"**Searching for workflow documentation**"}}
{"type":"item.started","item":{"id":"item_11","type":"command_execution","command":"/bin/zsh -lc \"rg --files -g '*workflow.md' -g '*prompt_template.md' -g '*mem0.diff' -g '*dexter.diff'\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_12","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"forge|integration baseline|non-interactive|Forge integration|forge integration\" -S .agentpr_runtime README.md **/README.md'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_11","type":"command_execution","command":"/bin/zsh -lc \"rg --files -g '*workflow.md' -g '*prompt_template.md' -g '*mem0.diff' -g '*dexter.diff'\"","aggregated_output":"","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_12","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"forge|integration baseline|non-interactive|Forge integration|forge integration\" -S .agentpr_runtime README.md **/README.md'","aggregated_output":"openclaw/README.md:5:Your agent forgets everything between sessions. This plugin fixes that. It watches conversations, extracts what matters, and brings it back when relevant â€” automatically.\nopenclaw/README.md:94:| `memory_forget` | Delete by ID or by query |\n.agentpr_runtime/contracts/baseline_mem0_20260224.md:7:- Run full forge integration workflow in prepared workspace.\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_13","type":"reasoning","text":"**Assessing baseline integration state**"}}
{"type":"item.started","item":{"id":"item_14","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' .agentpr_runtime/codex_last_message.txt\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_14","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' .agentpr_runtime/codex_last_message.txt\"","aggregated_output":"Status: NEEDS REVIEW\n\nFiles changed:\n- None\n\nTest/lint results:\n- Not run (blocked before implementation/validation).\n- Evidence:\n  - `cat orchestrator/data/contracts/baseline_mem0_20260224.md` -> `No such file or directory`\n  - `find . -maxdepth 5 -type f | rg 'baseline_mem0_20260224\\.md'` -> no matches\n  - `find . -maxdepth 4 -type d | rg 'orchestrator|contracts'` -> no matches\n\nNotes:\n- Required skill `agentpr-implement-and-validate` requires a valid in-repo contract; the task packet contract artifact is missing in this workspace: [orchestrator/data/contracts/baseline_mem0_20260224.md](/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/orchestrator/data/contracts/baseline_mem0_20260224.md).\n- Your safety contract also forbids reading the external instruction files listed in the base prompt (outside this repo), so I cannot legally use them as fallback.\n- Next action: provide the contract artifact inside this repository (or update the task packet to an existing in-repo path), then I can implement and run required validation commands.\n\nWhat was pushed (if any):\n- Nothing was pushed (`allow_agent_push=false`; no commit/push commands run).","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_15","type":"reasoning","text":"**Searching for forge integration references**"}}
{"type":"item.completed","item":{"id":"item_16","type":"agent_message","text":"I found the prior run was blocked on a missing contract path, but this workspace now includes an in-repo contract copy. Iâ€™m now mapping the codebase for existing Forge-related wiring and provider patterns to identify the minimal required change."}}
{"type":"item.started","item":{"id":"item_17","type":"command_execution","command":"/bin/zsh -lc 'ls -la'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_18","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"openai|provider|selector|mem0 provider|mem0-provider\" vercel-ai-sdk/src vercel-ai-sdk/tests -S'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_17","type":"command_execution","command":"/bin/zsh -lc 'ls -la'","aggregated_output":"total 1488\ndrwxr-xr-x@ 28 yi  staff     896 Feb 24 17:25 .\ndrwxr-xr-x@  7 yi  staff     224 Feb 24 19:48 ..\ndrwxr-xr-x@ 15 yi  staff     480 Feb 24 19:48 .agentpr_runtime\ndrwxr-xr-x@ 15 yi  staff     480 Feb 24 19:48 .git\ndrwxr-xr-x@  5 yi  staff     160 Feb 24 17:22 .github\n-rw-r--r--@  1 yi  staff    3338 Feb 24 17:22 .gitignore\n-rw-r--r--@  1 yi  staff     314 Feb 24 17:22 .pre-commit-config.yaml\ndrwxr-xr-x@  6 yi  staff     192 Feb 24 17:25 .pytest_cache\n-rw-r--r--@  1 yi  staff    1958 Feb 24 17:22 CONTRIBUTING.md\n-rw-r--r--@  1 yi  staff   11349 Feb 24 17:22 LICENSE\n-rw-r--r--@  1 yi  staff   37202 Feb 24 17:22 LLM.md\n-rw-r--r--@  1 yi  staff    5057 Feb 24 17:22 MIGRATION_GUIDE_v1.0.md\n-rw-r--r--@  1 yi  staff    1031 Feb 24 17:22 Makefile\n-rw-r--r--@  1 yi  staff    6813 Feb 24 17:22 README.md\ndrwxr-xr-x@  5 yi  staff     160 Feb 24 17:22 cookbooks\ndrwxr-xr-x@ 25 yi  staff     800 Feb 24 17:24 docs\ndrwxr-xr-x@ 16 yi  staff     512 Feb 24 17:22 embedchain\ndrwxr-xr-x@ 10 yi  staff     320 Feb 24 17:22 evaluation\ndrwxr-xr-x@ 10 yi  staff     320 Feb 24 17:22 examples\ndrwxr-xr-x@ 14 yi  staff     448 Feb 24 17:22 mem0\ndrwxr-xr-x@ 11 yi  staff     352 Feb 24 17:22 mem0-ts\ndrwxr-xr-x@  7 yi  staff     224 Feb 24 17:22 openclaw\ndrwxr-xr-x@ 12 yi  staff     384 Feb 24 17:22 openmemory\n-rw-r--r--@  1 yi  staff  671442 Feb 24 17:22 poetry.lock\n-rw-r--r--@  1 yi  staff    3019 Feb 24 17:22 pyproject.toml\ndrwxr-xr-x@ 10 yi  staff     320 Feb 24 17:22 server\ndrwxr-xr-x@ 13 yi  staff     416 Feb 24 17:22 tests\ndrwxr-xr-x@ 15 yi  staff     480 Feb 24 17:22 vercel-ai-sdk\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_19","type":"command_execution","command":"/bin/zsh -lc \"rg -n \\\"\\\\bforge\\\\b|Forge|FORGE\\\" -S\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_18","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"openai|provider|selector|mem0 provider|mem0-provider\" vercel-ai-sdk/src vercel-ai-sdk/tests -S'","aggregated_output":"vercel-ai-sdk/tests/memory-core.test.ts:2:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-utils.ts:1:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-utils.ts:3:import { loadApiKey } from '@ai-sdk/provider-utils';\nvercel-ai-sdk/tests/mem0-toolcalls.test.ts:20:  it(\"should Execute a Tool Call Using OpenAI\", async () => {\nvercel-ai-sdk/tests/mem0-toolcalls.test.ts:21:    const mem0OpenAI = createMem0({\nvercel-ai-sdk/tests/mem0-toolcalls.test.ts:22:      provider: \"openai\",\nvercel-ai-sdk/tests/mem0-toolcalls.test.ts:23:      apiKey: process.env.OPENAI_API_KEY,\nvercel-ai-sdk/tests/mem0-toolcalls.test.ts:30:      model: mem0OpenAI(\"gpt-4o\"),\nvercel-ai-sdk/tests/mem0-toolcalls.test.ts:65:      provider: \"anthropic\",\nvercel-ai-sdk/src/mem0-provider.ts:1:import { ProviderV2 } from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-provider.ts:2:import { LanguageModelV2 } from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-provider.ts:3:import { withoutTrailingSlash } from \"@ai-sdk/provider-utils\";\nvercel-ai-sdk/src/mem0-provider.ts:6:import { LLMProviderSettings } from \"./mem0-types\";\nvercel-ai-sdk/src/mem0-provider.ts:8:export interface Mem0Provider extends ProviderV2 {\nvercel-ai-sdk/src/mem0-provider.ts:20:export interface Mem0ProviderSettings {\nvercel-ai-sdk/src/mem0-provider.ts:38:  provider?: string;\nvercel-ai-sdk/src/mem0-provider.ts:43:   * The configuration for the provider.\nvercel-ai-sdk/src/mem0-provider.ts:45:  config?: LLMProviderSettings ;\nvercel-ai-sdk/src/mem0-provider.ts:49:  options: Mem0ProviderSettings = {\nvercel-ai-sdk/src/mem0-provider.ts:50:    provider: \"openai\",\nvercel-ai-sdk/src/mem0-provider.ts:52:): Mem0Provider {\nvercel-ai-sdk/src/mem0-provider.ts:54:    withoutTrailingSlash(options.baseURL) ?? \"http://api.openai.com\";\nvercel-ai-sdk/src/mem0-provider.ts:70:        provider: options.provider || \"openai\",\nvercel-ai-sdk/src/mem0-provider.ts:90:        provider: options.provider || \"openai\",\nvercel-ai-sdk/src/mem0-provider.ts:111:        provider: options.provider || \"openai\",\nvercel-ai-sdk/src/mem0-provider.ts:121:  const provider = function (\nvercel-ai-sdk/src/mem0-provider.ts:134:  provider.languageModel = createGenericModel;\nvercel-ai-sdk/src/mem0-provider.ts:135:  provider.completion = createCompletionModel;\nvercel-ai-sdk/src/mem0-provider.ts:136:  provider.chat = createChatModel;\nvercel-ai-sdk/src/mem0-provider.ts:138:  return provider as unknown as Mem0Provider;\nvercel-ai-sdk/src/mem0-generic-language-model.ts:6:} from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-generic-language-model.ts:8:import { LanguageModelV2 } from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-generic-language-model.ts:9:// streaming uses provider-native doStream; no middleware needed\nvercel-ai-sdk/src/mem0-generic-language-model.ts:12:import { Mem0ClassSelector } from \"./mem0-provider-selector\";\nvercel-ai-sdk/src/mem0-generic-language-model.ts:13:import { Mem0ProviderSettings } from \"./mem0-provider\";\nvercel-ai-sdk/src/mem0-generic-language-model.ts:34:    public readonly provider_config?: Mem0ProviderSettings\nvercel-ai-sdk/src/mem0-generic-language-model.ts:36:    this.provider = config.provider ?? \"openai\";\nvercel-ai-sdk/src/mem0-generic-language-model.ts:39:  provider: string;\nvercel-ai-sdk/src/mem0-generic-language-model.ts:110:      const provider = this.config.provider;\nvercel-ai-sdk/src/mem0-generic-language-model.ts:113:      const settings: Mem0ProviderSettings = {\nvercel-ai-sdk/src/mem0-generic-language-model.ts:114:        provider: provider,\nvercel-ai-sdk/src/mem0-generic-language-model.ts:125:      const selector = new Mem0ClassSelector(this.modelId, settings, this.provider_config);\nvercel-ai-sdk/src/mem0-generic-language-model.ts:132:      const model = selector.createProvider();\nvercel-ai-sdk/src/mem0-generic-language-model.ts:153:            providerMetadata: {\nvercel-ai-sdk/src/mem0-generic-language-model.ts:180:      const provider = this.config.provider;\nvercel-ai-sdk/src/mem0-generic-language-model.ts:183:      const settings: Mem0ProviderSettings = {\nvercel-ai-sdk/src/mem0-generic-language-model.ts:184:        provider: provider,\nvercel-ai-sdk/src/mem0-generic-language-model.ts:196:      const selector = new Mem0ClassSelector(this.modelId, settings, this.provider_config);\nvercel-ai-sdk/src/mem0-generic-language-model.ts:203:      const baseModel = selector.createProvider();\nvercel-ai-sdk/src/mem0-generic-language-model.ts:205:      // Use the provider's native streaming directly to avoid buffering\nvercel-ai-sdk/src/mem0-provider-selector.ts:1:import { Mem0ProviderSettings } from \"./mem0-provider\";\nvercel-ai-sdk/src/mem0-provider-selector.ts:2:import Mem0AITextGenerator, { ProviderSettings } from \"./provider-response-provider\";\nvercel-ai-sdk/src/mem0-provider-selector.ts:3:import { LanguageModelV2 } from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-provider-selector.ts:5:class Mem0ClassSelector {\nvercel-ai-sdk/src/mem0-provider-selector.ts:7:    provider_wrapper: string;\nvercel-ai-sdk/src/mem0-provider-selector.ts:8:    config: Mem0ProviderSettings;\nvercel-ai-sdk/src/mem0-provider-selector.ts:9:    provider_config?: ProviderSettings;\nvercel-ai-sdk/src/mem0-provider-selector.ts:10:    static supportedProviders = [\"openai\", \"anthropic\", \"cohere\", \"groq\", \"google\"];\nvercel-ai-sdk/src/mem0-provider-selector.ts:12:    constructor(modelId: string, config: Mem0ProviderSettings, provider_config?: ProviderSettings) {\nvercel-ai-sdk/src/mem0-provider-selector.ts:14:        this.provider_wrapper = config.provider || \"openai\";\nvercel-ai-sdk/src/mem0-provider-selector.ts:15:        this.provider_config = provider_config;\nvercel-ai-sdk/src/mem0-provider-selector.ts:18:            provider: this.provider_wrapper,\nvercel-ai-sdk/src/mem0-provider-selector.ts:21:        // Check if provider_wrapper is supported\nvercel-ai-sdk/src/mem0-provider-selector.ts:22:        if (!Mem0ClassSelector.supportedProviders.includes(this.provider_wrapper)) {\nvercel-ai-sdk/src/mem0-provider-selector.ts:23:            throw new Error(`Model not supported: ${this.provider_wrapper}`);\nvercel-ai-sdk/src/mem0-provider-selector.ts:27:    createProvider(): LanguageModelV2 {\nvercel-ai-sdk/src/mem0-provider-selector.ts:28:        return new Mem0AITextGenerator(this.modelId, this.config , this.provider_config || {});\nvercel-ai-sdk/src/mem0-provider-selector.ts:32:export { Mem0ClassSelector };\nvercel-ai-sdk/src/index.ts:2:export type { Mem0Provider, Mem0ProviderSettings } from './mem0-provider'\nvercel-ai-sdk/src/index.ts:3:export { createMem0, mem0 } from './mem0-provider'\nvercel-ai-sdk/tests/utils-test/cohere-integration.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/utils-test/cohere-integration.test.ts:21:  it(\"should retrieve memories and generate text using COHERE provider\", async () => {\nvercel-ai-sdk/tests/utils-test/cohere-integration.test.ts:47:  it(\"should generate text using COHERE provider with memories\", async () => {\nvercel-ai-sdk/tests/text-properties.test.ts:4:interface Provider {\nvercel-ai-sdk/tests/text-properties.test.ts:10:describe.each(testConfig.providers)('TEXT/STREAM PROPERTIES: Tests with model %s', (provider: Provider) => {\nvercel-ai-sdk/tests/text-properties.test.ts:16:    mem0 = testConfig.createTestClient(provider);\nvercel-ai-sdk/tests/text-properties.test.ts:22:      model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/text-properties.test.ts:40:      model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/text-properties.test.ts:52:      model: mem0.completion(provider.activeModel, {\nvercel-ai-sdk/tests/generate-output.test.ts:2:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/generate-output.test.ts:7:interface Provider {\nvercel-ai-sdk/tests/generate-output.test.ts:13:describe.each(testConfig.providers)('TESTS: Generate/Stream Text with model %s', (provider: Provider) => {\nvercel-ai-sdk/tests/generate-output.test.ts:19:    mem0 = testConfig.createTestClient(provider);\nvercel-ai-sdk/tests/generate-output.test.ts:39:      model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/generate-output.test.ts:49:  it(\"should generate text using provider with memories\", async () => {\nvercel-ai-sdk/tests/generate-output.test.ts:51:      model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/generate-output.test.ts:69:  it(\"should stream text using Mem0 provider with new streaming approach\", async () => {\nvercel-ai-sdk/tests/generate-output.test.ts:71:    const baseModel = mem0(provider.activeModel, {\nvercel-ai-sdk/src/mem0-facade.ts:1:import { withoutTrailingSlash } from '@ai-sdk/provider-utils'\nvercel-ai-sdk/src/mem0-facade.ts:5:import { Mem0ProviderSettings } from './mem0-provider'\nvercel-ai-sdk/src/mem0-facade.ts:11:  constructor(options: Mem0ProviderSettings = {\nvercel-ai-sdk/src/mem0-facade.ts:12:    provider: 'openai',\nvercel-ai-sdk/src/mem0-facade.ts:29:      provider: 'openai',\nvercel-ai-sdk/src/mem0-facade.ts:37:      provider: 'openai',\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-groq.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-groq.test.ts:18:      provider: \"groq\",\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-groq.test.ts:26:  it(\"should retrieve memories and generate text using GROQ provider\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-groq.test.ts:49:  it(\"should generate text using GROQ provider with memories\", async () => {\nvercel-ai-sdk/tests/utils-test/google-integration.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/utils-test/google-integration.test.ts:21:  it(\"should retrieve memories and generate text using Google provider\", async () => {\nvercel-ai-sdk/tests/utils-test/google-integration.test.ts:46:  it(\"should generate text using Google provider with memories\", async () => {\nvercel-ai-sdk/src/mem0-types.ts:1:import { Mem0ProviderSettings } from \"./mem0-provider\";\nvercel-ai-sdk/src/mem0-types.ts:2:import { OpenAIProviderSettings } from \"@ai-sdk/openai\";\nvercel-ai-sdk/src/mem0-types.ts:3:import { AnthropicProviderSettings } from \"@ai-sdk/anthropic\";\nvercel-ai-sdk/src/mem0-types.ts:4:import { LanguageModelV2 } from '@ai-sdk/provider';\nvercel-ai-sdk/src/mem0-types.ts:5:import { CohereProviderSettings } from \"@ai-sdk/cohere\";\nvercel-ai-sdk/src/mem0-types.ts:6:import { GroqProviderSettings } from \"@ai-sdk/groq\";\nvercel-ai-sdk/src/mem0-types.ts:35:export interface Mem0ChatConfig extends Mem0ConfigSettings, Mem0ProviderSettings {}\nvercel-ai-sdk/src/mem0-types.ts:37:export interface LLMProviderSettings extends OpenAIProviderSettings, AnthropicProviderSettings, CohereProviderSettings, GroqProviderSettings {}\nvercel-ai-sdk/tests/mem0-provider-tests/mem0_anthropic.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/mem0-provider-tests/mem0_anthropic.test.ts:18:      provider: \"anthropic\",\nvercel-ai-sdk/tests/mem0-provider-tests/mem0_anthropic.test.ts:26:  it(\"should retrieve memories and generate text using ANTHROPIC provider\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0_anthropic.test.ts:48:  it(\"should generate text using ANTHROPIC provider with memories\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-cohere.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-cohere.test.ts:17:      provider: \"cohere\",\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-cohere.test.ts:25:  it(\"should retrieve memories and generate text using COHERE provider\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-cohere.test.ts:48:  it(\"should generate text using COHERE provider with memories\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-google.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-google.test.ts:17:      provider: \"google\",\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-google.test.ts:25:  it(\"should retrieve memories and generate text using Google provider\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-google.test.ts:47:  it(\"should generate text using Google provider with memories\", async () => {\nvercel-ai-sdk/src/provider-response-provider.ts:1:import { LanguageModelV2, LanguageModelV2CallOptions } from \"@ai-sdk/provider\";\nvercel-ai-sdk/src/provider-response-provider.ts:2:import { Mem0ProviderSettings } from \"./mem0-provider\";\nvercel-ai-sdk/src/provider-response-provider.ts:3:import { createOpenAI, OpenAIProviderSettings } from \"@ai-sdk/openai\";\nvercel-ai-sdk/src/provider-response-provider.ts:4:import { CohereProviderSettings, createCohere } from \"@ai-sdk/cohere\";\nvercel-ai-sdk/src/provider-response-provider.ts:5:import { AnthropicProviderSettings, createAnthropic } from \"@ai-sdk/anthropic\";\nvercel-ai-sdk/src/provider-response-provider.ts:6:import { createGoogleGenerativeAI, GoogleGenerativeAIProviderSettings } from \"@ai-sdk/google\";\nvercel-ai-sdk/src/provider-response-provider.ts:7:import { createGroq, GroqProviderSettings } from \"@ai-sdk/groq\";\nvercel-ai-sdk/src/provider-response-provider.ts:9:// Define a private provider field\nvercel-ai-sdk/src/provider-response-provider.ts:15:    readonly provider = \"mem0\";\nvercel-ai-sdk/src/provider-response-provider.ts:21:    constructor(modelId: string, config: Mem0ProviderSettings, provider_config: ProviderSettings) {\nvercel-ai-sdk/src/provider-response-provider.ts:24:        switch (config.provider) {\nvercel-ai-sdk/src/provider-response-provider.ts:25:            case \"openai\":\nvercel-ai-sdk/src/provider-response-provider.ts:27:                    this.languageModel = createOpenAI({\nvercel-ai-sdk/src/provider-response-provider.ts:29:                        ...provider_config as OpenAIProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:32:                    this.languageModel = createOpenAI({\nvercel-ai-sdk/src/provider-response-provider.ts:34:                        ...provider_config as OpenAIProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:37:                    this.languageModel = createOpenAI({\nvercel-ai-sdk/src/provider-response-provider.ts:39:                        ...provider_config as OpenAIProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:46:                    ...provider_config as CohereProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:52:                    ...provider_config as AnthropicProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:58:                    ...provider_config as GroqProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:64:                    ...provider_config as GoogleGenerativeAIProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:70:                    ...provider_config as GoogleGenerativeAIProviderSettings,\nvercel-ai-sdk/src/provider-response-provider.ts:74:                throw new Error(\"Invalid provider\");\nvercel-ai-sdk/src/provider-response-provider.ts:89:export type ProviderSettings = OpenAIProviderSettings | CohereProviderSettings | AnthropicProviderSettings | GroqProviderSettings | GoogleGenerativeAIProviderSettings;\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai.test.ts:9:describe(\"OPENAI MEM0 Tests\", () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai.test.ts:16:      provider: \"openai\",\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai.test.ts:17:      apiKey: process.env.OPENAI_API_KEY,\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai.test.ts:24:  it(\"should retrieve memories and generate text using Mem0 OpenAI provider\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai.test.ts:45:  it(\"should generate text using openai provider with memories\", async () => {\nvercel-ai-sdk/tests/utils-test/anthropic-integration.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/utils-test/anthropic-integration.test.ts:22:  it(\"should retrieve memories and generate text using ANTHROPIC provider\", async () => {\nvercel-ai-sdk/tests/utils-test/anthropic-integration.test.ts:48:  it(\"should generate text using ANTHROPIC provider with memories\", async () => {\nvercel-ai-sdk/tests/utils-test/groq-integration.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/utils-test/groq-integration.test.ts:22:  it(\"should retrieve memories and generate text using GROQ provider\", async () => {\nvercel-ai-sdk/tests/utils-test/groq-integration.test.ts:48:  it(\"should generate text using GROQ provider with memories\", async () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:8:interface Provider {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:14:const provider: Provider = {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:15:  name: \"openai\",\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:17:  apiKey: process.env.OPENAI_API_KEY,\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:19:describe(\"OPENAI Structured Outputs\", () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:25:    mem0 = testConfig.createTestClient(provider);\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:28:  describe(\"openai Object Generation Tests\", () => {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:32:        model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:53:        model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:80:        model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/mem0-provider-tests/mem0-openai-structured-ouput.test.ts:95:        model: mem0(provider.activeModel, {\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:6:import { LanguageModelV2Prompt } from '@ai-sdk/provider';\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:8:import { createOpenAI } from \"@ai-sdk/openai\";\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:10:describe(\"OPENAI Integration Tests\", () => {\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:13:  let openai: any;\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:16:    openai = createOpenAI({\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:17:      apiKey: process.env.OPENAI_API_KEY,\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:21:  it(\"should retrieve memories and generate text using OpenAI provider\", async () => {\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:36:      model: openai(\"gpt-4-turbo\"),\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:46:  it(\"should generate text using openai provider with memories\", async () => {\nvercel-ai-sdk/tests/utils-test/openai-integration.test.ts:51:      model: openai(\"gpt-4-turbo\"),\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_19","type":"command_execution","command":"/bin/zsh -lc \"rg -n \\\"\\\\bforge\\\\b|Forge|FORGE\\\" -S\"","aggregated_output":"openclaw/index.ts:1027:        label: \"Memory Forget\",\ndocs/llms.txt:109:- [Forge](https://docs.mem0.ai/components/llms/models/forge): LLM router with unified access to multiple AI providers\ndocs/open-source/features/async-memory.mdx:389:1. **Keep operations awaited:** Forgetting `await` is the fastest way to miss writesâ€”lint for it or add helper wrappers.\nmem0/llms/openai.py:40:        if os.environ.get(\"FORGE_API_KEY\"):  # Use Forge\nmem0/llms/openai.py:42:                api_key=os.environ.get(\"FORGE_API_KEY\"),\nmem0/llms/openai.py:43:                base_url=os.getenv(\"FORGE_API_BASE\") or \"https://api.forge.tensorblock.co/v1\",\nmem0/llms/openai.py:118:        if os.getenv(\"FORGE_API_KEY\"):\nmem0/llms/openai.py:119:            # Forge uses standard OpenAI API format, no special parameters needed\ndocs/cookbooks/companions/voice-companion-openai.mdx:498:2. **Forgetting Mechanism**: Implement a way to delete or expire memories that are no longer relevant.\ndocs/platform/features/advanced-retrieval.mdx:250:- Forget to handle cases where filtering returns no results\ndocs/core-concepts/memory-operations/delete.mdx:152:- Forget a userâ€™s preferences at their request.\ndocs/platform/features/custom-instructions.mdx:326:- Forget to exclude sensitive information\ndocs/components/llms/models/forge.mdx:2:title: Forge\ndocs/components/llms/models/forge.mdx:5:[Forge](https://forge.tensorblock.co) is an LLM router that provides unified access to multiple AI providers (OpenAI, Anthropic, Google, and more) through a single API. It's compatible with the OpenAI API format, making it easy to integrate with existing applications.\ndocs/components/llms/models/forge.mdx:13:os.environ[\"FORGE_API_KEY\"] = \"your-api-key\"\ndocs/components/llms/models/forge.mdx:39:os.environ[\"FORGE_API_BASE\"] = \"https://api.forge.tensorblock.co/v1\"\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_20","type":"reasoning","text":"**Assessing existing Forge integration**"}}
{"type":"item.completed","item":{"id":"item_21","type":"agent_message","text":"I located existing Forge support in Python (`mem0/llms/openai.py`) and a Forge docs page, which suggests baseline work is likely in the TypeScript SDK path. Iâ€™m now checking CI/workflow files and TS package scripts to identify the exact required validation commands and the narrowest patch."}}
{"type":"item.started","item":{"id":"item_22","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' README.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_23","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' Makefile\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_24","type":"command_execution","command":"/bin/zsh -lc \"rg --files .github/workflows && for f in .github/workflows/*.yml; do echo '---' \"'$f; sed -n '\"'1,260p' \\\"\"'$f\"; done'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_22","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' README.md\"","aggregated_output":"<p align=\"center\">\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"docs/images/banner-sm.png\" width=\"800px\" alt=\"Mem0 - The Memory Layer for Personalized AI\">\n  </a>\n</p>\n<p align=\"center\" style=\"display: flex; justify-content: center; gap: 20px; align-items: center;\">\n  <a href=\"https://trendshift.io/repositories/11194\" target=\"blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/11194\" alt=\"mem0ai%2Fmem0 | Trendshift\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai\">Learn more</a>\n  Â·\n  <a href=\"https://mem0.dev/DiG\">Join Discord</a>\n  Â·\n  <a href=\"https://mem0.dev/demo\">Demo</a>\n  Â·\n  <a href=\"https://mem0.dev/openmemory\">OpenMemory</a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.dev/DiG\">\n    <img src=\"https://img.shields.io/badge/Discord-%235865F2.svg?&logo=discord&logoColor=white\" alt=\"Mem0 Discord\">\n  </a>\n  <a href=\"https://pepy.tech/project/mem0ai\">\n    <img src=\"https://img.shields.io/pypi/dm/mem0ai\" alt=\"Mem0 PyPI - Downloads\">\n  </a>\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square\" alt=\"GitHub commit activity\">\n  </a>\n  <a href=\"https://pypi.org/project/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/pypi/v/mem0ai?color=%2334D058&label=pypi%20package\" alt=\"Package version\">\n  </a>\n  <a href=\"https://www.npmjs.com/package/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/npm/v/mem0ai\" alt=\"Npm package\">\n  </a>\n  <a href=\"https://www.ycombinator.com/companies/mem0\">\n    <img src=\"https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square\" alt=\"Y Combinator S24\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai/research\"><strong>ðŸ“„ Building Production-Ready AI Agents with Scalable Long-Term Memory â†’</strong></a>\n</p>\n<p align=\"center\">\n  <strong>âš¡ +26% Accuracy vs. OpenAI Memory â€¢ ðŸš€ 91% Faster â€¢ ðŸ’° 90% Fewer Tokens</strong>\n</p>\n\n> **ðŸŽ‰ mem0ai v1.0.0 is now available!** This major release includes API modernization, improved vector store support, and enhanced GCP integration. [See migration guide â†’](MIGRATION_GUIDE_v1.0.md)\n\n##  ðŸ”¥ Research Highlights\n- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark\n- **91% Faster Responses** than full-context, ensuring low-latency at scale\n- **90% Lower Token Usage** than full-context, cutting costs without compromise\n- [Read the full paper](https://mem0.ai/research)\n\n# Introduction\n\n[Mem0](https://mem0.ai) (\"mem-zero\") enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over timeâ€”ideal for customer support chatbots, AI assistants, and autonomous systems.\n\n### Key Features & Use Cases\n\n**Core Capabilities:**\n- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization\n- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option\n\n**Applications:**\n- **AI Assistants**: Consistent, context-rich conversations\n- **Customer Support**: Recall past tickets and user history for tailored help\n- **Healthcare**: Track patient preferences and history for personalized care\n- **Productivity & Gaming**: Adaptive workflows and environments based on user behavior\n\n## ðŸš€ Quickstart Guide <a name=\"quickstart\"></a>\n\nChoose between our hosted platform or self-hosted package:\n\n### Hosted Platform\n\nGet up and running in minutes with automatic updates, analytics, and enterprise security.\n\n1. Sign up on [Mem0 Platform](https://app.mem0.ai)\n2. Embed the memory layer via SDK or API keys\n\n### Self-Hosted (Open Source)\n\nInstall the sdk via pip:\n\n```bash\npip install mem0ai\n```\n\nInstall sdk via npm:\n```bash\nnpm install mem0ai\n```\n\n### Basic Usage\n\nMem0 requires an LLM to function, with `gpt-4.1-nano-2025-04-14 from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our [Supported LLMs documentation](https://docs.mem0.ai/components/llms/overview).\n\nFirst step is to instantiate the memory:\n\n```python\nfrom openai import OpenAI\nfrom mem0 import Memory\n\nopenai_client = OpenAI()\nmemory = Memory()\n\ndef chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n    # Retrieve relevant memories\n    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n    memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n\n    # Generate Assistant response\n    system_prompt = f\"You are a helpful AI. Answer the question based on query and memories.\\nUser Memories:\\n{memories_str}\"\n    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n    response = openai_client.chat.completions.create(model=\"gpt-4.1-nano-2025-04-14\", messages=messages)\n    assistant_response = response.choices[0].message.content\n\n    # Create new memories from the conversation\n    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n    memory.add(messages, user_id=user_id)\n\n    return assistant_response\n\ndef main():\n    print(\"Chat with AI (type 'exit' to quit)\")\n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() == 'exit':\n            print(\"Goodbye!\")\n            break\n        print(f\"AI: {chat_with_memories(user_input)}\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nFor detailed integration steps, see the [Quickstart](https://docs.mem0.ai/quickstart) and [API Reference](https://docs.mem0.ai/api-reference).\n\n## ðŸ”— Integrations & Demos\n\n- **ChatGPT with Memory**: Personalized chat powered by Mem0 ([Live Demo](https://mem0.dev/demo))\n- **Browser Extension**: Store memories across ChatGPT, Perplexity, and Claude ([Chrome Extension](https://chromewebstore.google.com/detail/onihkkbipkfeijkadecaafbgagkhglop?utm_source=item-share-cb))\n- **Langgraph Support**: Build a customer bot with Langgraph + Mem0 ([Guide](https://docs.mem0.ai/integrations/langgraph))\n- **CrewAI Integration**: Tailor CrewAI outputs with Mem0 ([Example](https://docs.mem0.ai/integrations/crewai))\n\n## ðŸ“š Documentation & Support\n\n- Full docs: https://docs.mem0.ai\n- Community: [Discord](https://mem0.dev/DiG) Â· [Twitter](https://x.com/mem0ai)\n- Contact: founders@mem0.ai\n\n## Citation\n\nWe now have a paper you can cite:\n\n```bibtex\n@article{mem0,\n  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},\n  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},\n  journal={arXiv preprint arXiv:2504.19413},\n  year={2025}\n}\n```\n\n## âš–ï¸ License\n\nApache 2.0 â€” see the [LICENSE](https://github.com/mem0ai/mem0/blob/main/LICENSE) file for details.","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_23","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' Makefile\"","aggregated_output":".PHONY: format sort lint\n\n# Variables\nISORT_OPTIONS = --profile black\nPROJECT_NAME := mem0ai\n\n# Default target\nall: format sort lint\n\ninstall:\n\thatch env create\n\ninstall_all:\n\tpip install ruff==0.6.9 groq together boto3 litellm ollama chromadb weaviate weaviate-client sentence_transformers vertexai \\\n\t            google-generativeai elasticsearch opensearch-py vecs \"pinecone<7.0.0\" pinecone-text faiss-cpu langchain-community \\\n\t\t\t\t\t\t\tupstash-vector azure-search-documents langchain-memgraph langchain-neo4j langchain-aws rank-bm25 pymochow pymongo psycopg kuzu databricks-sdk valkey\n\n# Format code with ruff\nformat:\n\thatch run format\n\n# Sort imports with isort\nsort:\n\thatch run isort mem0/\n\n# Lint code with ruff\nlint:\n\thatch run lint\n\ndocs:\n\tcd docs && mintlify dev\n\nbuild:\n\thatch build\n\npublish:\n\thatch publish\n\nclean:\n\trm -rf dist\n\ntest:\n\thatch run test\n\ntest-py-3.9:\n\thatch run dev_py_3_9:test\n\ntest-py-3.10:\n\thatch run dev_py_3_10:test\n\ntest-py-3.11:\n\thatch run dev_py_3_11:test\n\ntest-py-3.12:\n\thatch run dev_py_3_12:test\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_24","type":"command_execution","command":"/bin/zsh -lc \"rg --files .github/workflows && for f in .github/workflows/*.yml; do echo '---' \"'$f; sed -n '\"'1,260p' \\\"\"'$f\"; done'","aggregated_output":".github/workflows/ci.yml\n.github/workflows/cd.yml\n--- .github/workflows/cd.yml\nname: Publish Python ðŸ distributions ðŸ“¦ to PyPI and TestPyPI\n\non:\n  release:\n    types: [published]\n\njobs:\n  build-n-publish:\n    name: Build and publish Python ðŸ distributions ðŸ“¦ to PyPI and TestPyPI\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.11'\n\n      - name: Install Hatch\n        run: |\n          pip install hatch\n\n      - name: Install dependencies\n        run: |\n          hatch env create\n\n      - name: Build a binary wheel and a source tarball\n        run: |\n          hatch build --clean\n\n      # TODO: Needs to setup mem0 repo on Test PyPI\n      # - name: Publish distribution ðŸ“¦ to Test PyPI\n      #   uses: pypa/gh-action-pypi-publish@release/v1\n      #   with:\n      #     repository_url: https://test.pypi.org/legacy/\n      #     packages_dir: dist/\n\n      - name: Publish distribution ðŸ“¦ to PyPI\n        if: startsWith(github.ref, 'refs/tags')\n        uses: pypa/gh-action-pypi-publish@release/v1\n        with:\n          packages_dir: dist/\n--- .github/workflows/ci.yml\nname: ci\n\non:\n  push:\n    branches: [main]\n    paths:\n      - 'mem0/**'\n      - 'tests/**'\n      - 'embedchain/**'\n      - '.github/workflows/**'\n      - 'pyproject.toml'\n  pull_request:\n    paths:\n      - 'mem0/**'\n      - 'tests/**'\n      - 'embedchain/**'\n\njobs:\n  check_changes:\n    runs-on: ubuntu-latest\n    outputs:\n      mem0_changed: ${{ steps.filter.outputs.mem0 }}\n      embedchain_changed: ${{ steps.filter.outputs.embedchain }}\n    steps:\n    - uses: actions/checkout@v3\n    - uses: dorny/paths-filter@v2\n      id: filter\n      with:\n        filters: |\n          mem0:\n            - 'mem0/**'\n            - 'tests/**'\n            - '.github/workflows/**'\n            - 'pyproject.toml'\n          embedchain:\n            - 'embedchain/**'\n\n  build_mem0:\n    needs: check_changes\n    if: needs.check_changes.outputs.mem0_changed == 'true'\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.10\", \"3.11\", \"3.12\"]\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Clean up disk space\n        run: |\n          df -h\n          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL\n          sudo docker image prune --all --force\n          sudo docker builder prune -a\n          df -h\n      - name: Install Hatch\n        run: pip install hatch\n      - name: Load cached venv\n        id: cached-hatch-dependencies\n        uses: actions/cache@v3\n        with:\n          path: .venv\n          key: venv-mem0-${{ runner.os }}-${{ hashFiles('**/pyproject.toml') }}\n      - name: Install GEOS Libraries\n        run: sudo apt-get update && sudo apt-get install -y libgeos-dev\n      - name: Install dependencies\n        run: |\n          pip install --upgrade pip\n          pip install -e \".[test,graph,vector_stores,llms,extras]\"\n          pip install ruff\n        if: steps.cached-hatch-dependencies.outputs.cache-hit != 'true'\n      - name: Run Linting\n        run: make lint\n      - name: Run tests and generate coverage report\n        run: make test\n\n  build_embedchain:\n    needs: check_changes\n    if: needs.check_changes.outputs.embedchain_changed == 'true'\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.9\", \"3.10\", \"3.11\", \"3.12\"]\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Install Hatch\n        run: pip install hatch\n      - name: Load cached venv\n        id: cached-hatch-dependencies\n        uses: actions/cache@v3\n        with:\n          path: .venv\n          key: venv-embedchain-${{ runner.os }}-${{ hashFiles('**/pyproject.toml') }}\n      - name: Install dependencies\n        run: cd embedchain && make install_all\n        if: steps.cached-hatch-dependencies.outputs.cache-hit != 'true'\n      - name: Run Formatting\n        run: |\n          mkdir -p embedchain/.ruff_cache && chmod -R 777 embedchain/.ruff_cache\n          cd embedchain && hatch run format\n      - name: Lint with ruff\n        run: cd embedchain && make lint\n      - name: Run tests and generate coverage report\n        run: cd embedchain && make coverage\n      - name: Upload coverage reports to Codecov\n        uses: codecov/codecov-action@v3\n        with:\n          file: coverage.xml\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_25","type":"reasoning","text":"**Inspecting embedded workflow data**"}}
{"type":"item.started","item":{"id":"item_26","type":"command_execution","command":"/bin/zsh -lc 'find .agentpr_runtime -maxdepth 4 -type f | sort'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_27","type":"command_execution","command":"/bin/zsh -lc 'for f in $(find .agentpr_runtime -maxdepth 4 -type f | sort); do echo '\"'---' \"'$f; sed -n '\"'1,220p' \\\"\"'$f\"; done'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_26","type":"command_execution","command":"/bin/zsh -lc 'find .agentpr_runtime -maxdepth 4 -type f | sort'","aggregated_output":".agentpr_runtime/codex_last_message.txt\n.agentpr_runtime/contracts/baseline_mem0_20260224.md\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_27","type":"command_execution","command":"/bin/zsh -lc 'for f in $(find .agentpr_runtime -maxdepth 4 -type f | sort); do echo '\"'---' \"'$f; sed -n '\"'1,220p' \\\"\"'$f\"; done'","aggregated_output":"--- .agentpr_runtime/codex_last_message.txt\nStatus: NEEDS REVIEW\n\nFiles changed:\n- None\n\nTest/lint results:\n- Not run (blocked before implementation/validation).\n- Evidence:\n  - `cat orchestrator/data/contracts/baseline_mem0_20260224.md` -> `No such file or directory`\n  - `find . -maxdepth 5 -type f | rg 'baseline_mem0_20260224\\.md'` -> no matches\n  - `find . -maxdepth 4 -type d | rg 'orchestrator|contracts'` -> no matches\n\nNotes:\n- Required skill `agentpr-implement-and-validate` requires a valid in-repo contract; the task packet contract artifact is missing in this workspace: [orchestrator/data/contracts/baseline_mem0_20260224.md](/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/orchestrator/data/contracts/baseline_mem0_20260224.md).\n- Your safety contract also forbids reading the external instruction files listed in the base prompt (outside this repo), so I cannot legally use them as fallback.\n- Next action: provide the contract artifact inside this repository (or update the task packet to an existing in-repo path), then I can implement and run required validation commands.\n\nWhat was pushed (if any):\n- Nothing was pushed (`allow_agent_push=false`; no commit/push commands run).--- .agentpr_runtime/contracts/baseline_mem0_20260224.md\n# baseline_mem0_20260224 contract\nrepo: mem0ai/mem0\nmode: push_only\nengine: codex_exec\ngoal: non_interactive_baseline\nnotes:\n- Run full forge integration workflow in prepared workspace.\n- Keep minimal diff and follow repo contribution rules.\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_28","type":"reasoning","text":"**Inspecting Forge integration status**"}}
{"type":"item.started","item":{"id":"item_29","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' mem0/llms/openai.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_29","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,260p' mem0/llms/openai.py\"","aggregated_output":"import json\nimport logging\nimport os\nfrom typing import Dict, List, Optional, Union\n\nfrom openai import OpenAI\n\nfrom mem0.configs.llms.base import BaseLlmConfig\nfrom mem0.configs.llms.openai import OpenAIConfig\nfrom mem0.llms.base import LLMBase\nfrom mem0.memory.utils import extract_json\n\n\nclass OpenAILLM(LLMBase):\n    def __init__(self, config: Optional[Union[BaseLlmConfig, OpenAIConfig, Dict]] = None):\n        # Convert to OpenAIConfig if needed\n        if config is None:\n            config = OpenAIConfig()\n        elif isinstance(config, dict):\n            config = OpenAIConfig(**config)\n        elif isinstance(config, BaseLlmConfig) and not isinstance(config, OpenAIConfig):\n            # Convert BaseLlmConfig to OpenAIConfig\n            config = OpenAIConfig(\n                model=config.model,\n                temperature=config.temperature,\n                api_key=config.api_key,\n                max_tokens=config.max_tokens,\n                top_p=config.top_p,\n                top_k=config.top_k,\n                enable_vision=config.enable_vision,\n                vision_details=config.vision_details,\n                http_client_proxies=config.http_client,\n            )\n\n        super().__init__(config)\n\n        if not self.config.model:\n            self.config.model = \"gpt-4.1-nano-2025-04-14\"\n\n        if os.environ.get(\"FORGE_API_KEY\"):  # Use Forge\n            self.client = OpenAI(\n                api_key=os.environ.get(\"FORGE_API_KEY\"),\n                base_url=os.getenv(\"FORGE_API_BASE\") or \"https://api.forge.tensorblock.co/v1\",\n            )\n        elif os.environ.get(\"OPENROUTER_API_KEY\"):  # Use OpenRouter\n            self.client = OpenAI(\n                api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n                base_url=self.config.openrouter_base_url\n                or os.getenv(\"OPENROUTER_API_BASE\")\n                or \"https://openrouter.ai/api/v1\",\n            )\n        else:\n            api_key = self.config.api_key or os.getenv(\"OPENAI_API_KEY\")\n            base_url = self.config.openai_base_url or os.getenv(\"OPENAI_BASE_URL\") or \"https://api.openai.com/v1\"\n\n            self.client = OpenAI(api_key=api_key, base_url=base_url)\n\n    def _parse_response(self, response, tools):\n        \"\"\"\n        Process the response based on whether tools are used or not.\n\n        Args:\n            response: The raw response from API.\n            tools: The list of tools provided in the request.\n\n        Returns:\n            str or dict: The processed response.\n        \"\"\"\n        if tools:\n            processed_response = {\n                \"content\": response.choices[0].message.content,\n                \"tool_calls\": [],\n            }\n\n            if response.choices[0].message.tool_calls:\n                for tool_call in response.choices[0].message.tool_calls:\n                    processed_response[\"tool_calls\"].append(\n                        {\n                            \"name\": tool_call.function.name,\n                            \"arguments\": json.loads(extract_json(tool_call.function.arguments)),\n                        }\n                    )\n\n            return processed_response\n        else:\n            return response.choices[0].message.content\n\n    def generate_response(\n        self,\n        messages: List[Dict[str, str]],\n        response_format=None,\n        tools: Optional[List[Dict]] = None,\n        tool_choice: str = \"auto\",\n        **kwargs,\n    ):\n        \"\"\"\n        Generate a JSON response based on the given messages using OpenAI.\n\n        Args:\n            messages (list): List of message dicts containing 'role' and 'content'.\n            response_format (str or object, optional): Format of the response. Defaults to \"text\".\n            tools (list, optional): List of tools that the model can call. Defaults to None.\n            tool_choice (str, optional): Tool choice method. Defaults to \"auto\".\n            **kwargs: Additional OpenAI-specific parameters.\n\n        Returns:\n            json: The generated response.\n        \"\"\"\n        params = self._get_supported_params(messages=messages, **kwargs)\n\n        params.update(\n            {\n                \"model\": self.config.model,\n                \"messages\": messages,\n            }\n        )\n\n        if os.getenv(\"FORGE_API_KEY\"):\n            # Forge uses standard OpenAI API format, no special parameters needed\n            pass\n        elif os.getenv(\"OPENROUTER_API_KEY\"):\n            openrouter_params = {}\n            if self.config.models:\n                openrouter_params[\"models\"] = self.config.models\n                openrouter_params[\"route\"] = self.config.route\n                params.pop(\"model\")\n\n            if self.config.site_url and self.config.app_name:\n                extra_headers = {\n                    \"HTTP-Referer\": self.config.site_url,\n                    \"X-Title\": self.config.app_name,\n                }\n                openrouter_params[\"extra_headers\"] = extra_headers\n\n            params.update(**openrouter_params)\n\n        else:\n            openai_specific_generation_params = [\"store\"]\n            for param in openai_specific_generation_params:\n                if hasattr(self.config, param):\n                    params[param] = getattr(self.config, param)\n\n        if response_format:\n            params[\"response_format\"] = response_format\n        if tools:  # TODO: Remove tools if no issues found with new memory addition logic\n            params[\"tools\"] = tools\n            params[\"tool_choice\"] = tool_choice\n        response = self.client.chat.completions.create(**params)\n        parsed_response = self._parse_response(response, tools)\n        if self.config.response_callback:\n            try:\n                self.config.response_callback(self, response, params)\n            except Exception as e:\n                # Log error but don't propagate\n                logging.error(f\"Error due to callback: {e}\")\n                pass\n        return parsed_response\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_30","type":"reasoning","text":"**Inspecting FORGE environment usage**"}}
{"type":"item.started","item":{"id":"item_31","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"FORGE_API_KEY|FORGE_API_BASE|forge.tensorblock\" -S mem0 mem0-ts vercel-ai-sdk tests docs/components/llms/models/forge.mdx'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_31","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"FORGE_API_KEY|FORGE_API_BASE|forge.tensorblock\" -S mem0 mem0-ts vercel-ai-sdk tests docs/components/llms/models/forge.mdx'","aggregated_output":"docs/components/llms/models/forge.mdx:5:[Forge](https://forge.tensorblock.co) is an LLM router that provides unified access to multiple AI providers (OpenAI, Anthropic, Google, and more) through a single API. It's compatible with the OpenAI API format, making it easy to integrate with existing applications.\ndocs/components/llms/models/forge.mdx:13:os.environ[\"FORGE_API_KEY\"] = \"your-api-key\"\ndocs/components/llms/models/forge.mdx:39:os.environ[\"FORGE_API_BASE\"] = \"https://api.forge.tensorblock.co/v1\"\nmem0/llms/openai.py:40:        if os.environ.get(\"FORGE_API_KEY\"):  # Use Forge\nmem0/llms/openai.py:42:                api_key=os.environ.get(\"FORGE_API_KEY\"),\nmem0/llms/openai.py:43:                base_url=os.getenv(\"FORGE_API_BASE\") or \"https://api.forge.tensorblock.co/v1\",\nmem0/llms/openai.py:118:        if os.getenv(\"FORGE_API_KEY\"):\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_32","type":"reasoning","text":"**Checking branch history and remotes**"}}
{"type":"item.started","item":{"id":"item_33","type":"command_execution","command":"/bin/zsh -lc 'git remote -v'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_34","type":"command_execution","command":"/bin/zsh -lc 'git log --oneline --decorate -n 20'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_33","type":"command_execution","command":"/bin/zsh -lc 'git remote -v'","aggregated_output":"origin\thttps://github.com/Yiiii0/mem0.git (fetch)\norigin\thttps://github.com/Yiiii0/mem0.git (push)\nupstream\thttps://github.com/mem0ai/mem0.git (fetch)\nupstream\thttps://github.com/mem0ai/mem0.git (push)\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_35","type":"command_execution","command":"/bin/zsh -lc 'git merge-base HEAD origin/main 2>/dev/null && git diff --name-only $(git merge-base HEAD origin/main)..HEAD | sed -n '\"'1,120p'\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_34","type":"command_execution","command":"/bin/zsh -lc 'git log --oneline --decorate -n 20'","aggregated_output":"c05a3bc1 (HEAD -> feature/forge-20260224-172250, origin/feature/forge-20260224-172250) feat: Add Forge LLM provider support\ndb15d5c6 (upstream/main, origin/main, origin/HEAD, main) fix(oss): validate LLM fact output via FactRetrievalSchema before embedding (#4083)\naa4a944b fix: Bug: Openclaw Extension OSS Mode lacks threshold restrictions (#4106) (#4115)\nab5e930c Update OpenClaw integration architecture diagram (#4079)\n0e76de7b Add source openclaw (#4082)\n5a93643f docs: add memory_categorize webhook event type (#4077)\na1408293 (tag: v1.0.4) chore: update user facing timestamp for a memory (#4066)\na6810819 OpenClaw plugin: fix auto-recall injection and auto-capture message drop (#4065)\na02205e5 chore: remove legacy v0.x docs and version dropdown (#4060)\n69a832dc (tag: v1.0.3) chore: add update project options (#3947)\n70baa46c fix: add OpenClaw to docs navigation (#3965)\n3d3e875d Feature: Add OpenClaw plugin and documentation (#3964)\ndba7f045 (tag: v1.0.2) (version-bump): update the project version to v1.0.2 (#3902)\n27e5db58 (fix): mongodb distribution name, azure ai search, and workflow trigger (#3900)\n2c90eedf chore: do a disk cleanup in gh actions to fix memo build (#3899)\na1db0f63 Add DriverInfo metadata to MongoDB vector store (#3648)\n90a7b1af feat(ts-sdk): add support for keyword arguments in add and search methods (#3895)\n69a552d8 fix(docs): Improve light mode support for introduction page and organize thumbnails (#3880)\n417ebffa (ts-sdk-update): Update for TypeScript SDK v2.2. (#3865)\n1dc07d35 (docs): update to use the v2 URL Patterns in delete user route (#3864)\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_35","type":"command_execution","command":"/bin/zsh -lc 'git merge-base HEAD origin/main 2>/dev/null && git diff --name-only $(git merge-base HEAD origin/main)..HEAD | sed -n '\"'1,120p'\"","aggregated_output":"db15d5c6297ee2afaed2e91d86796a86f383949e\ndocs/components/llms/models/forge.mdx\ndocs/llms.txt\nmem0/llms/openai.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_36","type":"reasoning","text":"**Assessing existing commit and validation**"}}
{"type":"item.started","item":{"id":"item_37","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"OpenAILLM|OPENROUTER|FORGE|openai.py|openrouter\" tests mem0 -S'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_38","type":"command_execution","command":"/bin/zsh -lc \"git show --name-only --pretty='' HEAD\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_39","type":"command_execution","command":"/bin/zsh -lc 'git show --stat --oneline HEAD'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_38","type":"command_execution","command":"/bin/zsh -lc \"git show --name-only --pretty='' HEAD\"","aggregated_output":"docs/components/llms/models/forge.mdx\ndocs/llms.txt\nmem0/llms/openai.py\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_37","type":"command_execution","command":"/bin/zsh -lc 'rg -n \"OpenAILLM|OPENROUTER|FORGE|openai.py|openrouter\" tests mem0 -S'","aggregated_output":"mem0/utils/factory.py:37:        \"openai\": (\"mem0.llms.openai.OpenAILLM\", OpenAIConfig),\nmem0/utils/factory.py:42:        \"azure_openai\": (\"mem0.llms.azure_openai.AzureOpenAILLM\", AzureOpenAIConfig),\ntests/llms/test_openai.py:7:from mem0.llms.openai import OpenAILLM\ntests/llms/test_openai.py:21:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:29:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:38:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:45:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:65:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:114:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:135:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:157:    llm = OpenAILLM(config)\ntests/llms/test_openai.py:176:    llm = OpenAILLM(config)\nmem0/configs/llms/openai.py:28:        openrouter_base_url: Optional[str] = None,\nmem0/configs/llms/openai.py:51:            openrouter_base_url: OpenRouter base URL, defaults to None\nmem0/configs/llms/openai.py:73:        self.openrouter_base_url = openrouter_base_url\nmem0/llms/azure_openai.py:16:class AzureOpenAILLM(LLMBase):\nmem0/llms/openai.py:14:class OpenAILLM(LLMBase):\nmem0/llms/openai.py:40:        if os.environ.get(\"FORGE_API_KEY\"):  # Use Forge\nmem0/llms/openai.py:42:                api_key=os.environ.get(\"FORGE_API_KEY\"),\nmem0/llms/openai.py:43:                base_url=os.getenv(\"FORGE_API_BASE\") or \"https://api.forge.tensorblock.co/v1\",\nmem0/llms/openai.py:45:        elif os.environ.get(\"OPENROUTER_API_KEY\"):  # Use OpenRouter\nmem0/llms/openai.py:47:                api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\nmem0/llms/openai.py:48:                base_url=self.config.openrouter_base_url\nmem0/llms/openai.py:49:                or os.getenv(\"OPENROUTER_API_BASE\")\nmem0/llms/openai.py:50:                or \"https://openrouter.ai/api/v1\",\nmem0/llms/openai.py:118:        if os.getenv(\"FORGE_API_KEY\"):\nmem0/llms/openai.py:121:        elif os.getenv(\"OPENROUTER_API_KEY\"):\nmem0/llms/openai.py:122:            openrouter_params = {}\nmem0/llms/openai.py:124:                openrouter_params[\"models\"] = self.config.models\nmem0/llms/openai.py:125:                openrouter_params[\"route\"] = self.config.route\nmem0/llms/openai.py:133:                openrouter_params[\"extra_headers\"] = extra_headers\nmem0/llms/openai.py:135:            params.update(**openrouter_params)\ntests/llms/test_azure_openai.py:6:from mem0.llms.azure_openai import AzureOpenAILLM\ntests/llms/test_azure_openai.py:24:    llm = AzureOpenAILLM(config)\ntests/llms/test_azure_openai.py:44:    llm = AzureOpenAILLM(config)\ntests/llms/test_azure_openai.py:120:        _ = AzureOpenAILLM(config)\ntests/llms/test_azure_openai.py:156:        llm = AzureOpenAILLM(config)\ntests/llms/test_azure_openai.py:184:        llm = AzureOpenAILLM(config)\ntests/llms/test_azure_openai.py:216:        AzureOpenAILLM(config)\ntests/llms/test_azure_openai.py:247:        AzureOpenAILLM(config)\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_39","type":"command_execution","command":"/bin/zsh -lc 'git show --stat --oneline HEAD'","aggregated_output":"c05a3bc1 feat: Add Forge LLM provider support\n docs/components/llms/models/forge.mdx | 44 +++++++++++++++++++++++++++++++++++\n docs/llms.txt                         |  1 +\n mem0/llms/openai.py                   | 28 +++++++++++++++-------\n 3 files changed, 64 insertions(+), 9 deletions(-)\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_40","type":"reasoning","text":"**Reviewing test coverage for forge**"}}
{"type":"item.completed","item":{"id":"item_41","type":"agent_message","text":"I confirmed this branch already contains a Forge-support commit touching 3 files. Iâ€™m reviewing existing OpenAI LLM tests now to decide whether the baseline is complete as-is or needs a small follow-up test patch before validation."}}
{"type":"item.started","item":{"id":"item_42","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,280p' tests/llms/test_openai.py\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_42","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,280p' tests/llms/test_openai.py\"","aggregated_output":"import os\nfrom unittest.mock import Mock, patch\n\nimport pytest\n\nfrom mem0.configs.llms.openai import OpenAIConfig\nfrom mem0.llms.openai import OpenAILLM\n\n\n@pytest.fixture\ndef mock_openai_client():\n    with patch(\"mem0.llms.openai.OpenAI\") as mock_openai:\n        mock_client = Mock()\n        mock_openai.return_value = mock_client\n        yield mock_client\n\n\ndef test_openai_llm_base_url():\n    # case1: default config: with openai official base url\n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\", temperature=0.7, max_tokens=100, top_p=1.0, api_key=\"api_key\")\n    llm = OpenAILLM(config)\n    # Note: openai client will parse the raw base_url into a URL object, which will have a trailing slash\n    assert str(llm.client.base_url) == \"https://api.openai.com/v1/\"\n\n    # case2: with env variable OPENAI_API_BASE\n    provider_base_url = \"https://api.provider.com/v1\"\n    os.environ[\"OPENAI_BASE_URL\"] = provider_base_url\n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\", temperature=0.7, max_tokens=100, top_p=1.0, api_key=\"api_key\")\n    llm = OpenAILLM(config)\n    # Note: openai client will parse the raw base_url into a URL object, which will have a trailing slash\n    assert str(llm.client.base_url) == provider_base_url + \"/\"\n\n    # case3: with config.openai_base_url\n    config_base_url = \"https://api.config.com/v1\"\n    config = OpenAIConfig(\n        model=\"gpt-4.1-nano-2025-04-14\", temperature=0.7, max_tokens=100, top_p=1.0, api_key=\"api_key\", openai_base_url=config_base_url\n    )\n    llm = OpenAILLM(config)\n    # Note: openai client will parse the raw base_url into a URL object, which will have a trailing slash\n    assert str(llm.client.base_url) == config_base_url + \"/\"\n\n\ndef test_generate_response_without_tools(mock_openai_client):\n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\", temperature=0.7, max_tokens=100, top_p=1.0)\n    llm = OpenAILLM(config)\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    ]\n\n    mock_response = Mock()\n    mock_response.choices = [Mock(message=Mock(content=\"I'm doing well, thank you for asking!\"))]\n    mock_openai_client.chat.completions.create.return_value = mock_response\n\n    response = llm.generate_response(messages)\n\n    mock_openai_client.chat.completions.create.assert_called_once_with(\n        model=\"gpt-4.1-nano-2025-04-14\", messages=messages, temperature=0.7, max_tokens=100, top_p=1.0, store=False\n    )\n    assert response == \"I'm doing well, thank you for asking!\"\n\n\ndef test_generate_response_with_tools(mock_openai_client):\n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\", temperature=0.7, max_tokens=100, top_p=1.0)\n    llm = OpenAILLM(config)\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Add a new memory: Today is a sunny day.\"},\n    ]\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"add_memory\",\n                \"description\": \"Add a memory\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\"data\": {\"type\": \"string\", \"description\": \"Data to add to memory\"}},\n                    \"required\": [\"data\"],\n                },\n            },\n        }\n    ]\n\n    mock_response = Mock()\n    mock_message = Mock()\n    mock_message.content = \"I've added the memory for you.\"\n\n    mock_tool_call = Mock()\n    mock_tool_call.function.name = \"add_memory\"\n    mock_tool_call.function.arguments = '{\"data\": \"Today is a sunny day.\"}'\n\n    mock_message.tool_calls = [mock_tool_call]\n    mock_response.choices = [Mock(message=mock_message)]\n    mock_openai_client.chat.completions.create.return_value = mock_response\n\n    response = llm.generate_response(messages, tools=tools)\n\n    mock_openai_client.chat.completions.create.assert_called_once_with(\n        model=\"gpt-4.1-nano-2025-04-14\", messages=messages, temperature=0.7, max_tokens=100, top_p=1.0, tools=tools, tool_choice=\"auto\", store=False\n    )\n\n    assert response[\"content\"] == \"I've added the memory for you.\"\n    assert len(response[\"tool_calls\"]) == 1\n    assert response[\"tool_calls\"][0][\"name\"] == \"add_memory\"\n    assert response[\"tool_calls\"][0][\"arguments\"] == {\"data\": \"Today is a sunny day.\"}\n\n\ndef test_response_callback_invocation(mock_openai_client):\n    # Setup mock callback\n    mock_callback = Mock()\n    \n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\", response_callback=mock_callback)\n    llm = OpenAILLM(config)\n    messages = [{\"role\": \"user\", \"content\": \"Test callback\"}]\n    \n    # Mock response\n    mock_response = Mock()\n    mock_response.choices = [Mock(message=Mock(content=\"Response\"))]\n    mock_openai_client.chat.completions.create.return_value = mock_response\n    \n    # Call method\n    llm.generate_response(messages)\n    \n    # Verify callback called with correct arguments\n    mock_callback.assert_called_once()\n    args = mock_callback.call_args[0]\n    assert args[0] is llm  # llm_instance\n    assert args[1] == mock_response  # raw_response\n    assert \"messages\" in args[2]  # params\n\n\ndef test_no_response_callback(mock_openai_client):\n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\")\n    llm = OpenAILLM(config)\n    messages = [{\"role\": \"user\", \"content\": \"Test no callback\"}]\n    \n    # Mock response\n    mock_response = Mock()\n    mock_response.choices = [Mock(message=Mock(content=\"Response\"))]\n    mock_openai_client.chat.completions.create.return_value = mock_response\n    \n    # Should complete without calling any callback\n    response = llm.generate_response(messages)\n    assert response == \"Response\"\n    \n    # Verify no callback is set\n    assert llm.config.response_callback is None\n\n\ndef test_callback_exception_handling(mock_openai_client):\n    # Callback that raises exception\n    def faulty_callback(*args):\n        raise ValueError(\"Callback error\")\n    \n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\", response_callback=faulty_callback)\n    llm = OpenAILLM(config)\n    messages = [{\"role\": \"user\", \"content\": \"Test exception\"}]\n    \n    # Mock response\n    mock_response = Mock()\n    mock_response.choices = [Mock(message=Mock(content=\"Expected response\"))]\n    mock_openai_client.chat.completions.create.return_value = mock_response\n    \n    # Should complete without raising\n    response = llm.generate_response(messages)\n    assert response == \"Expected response\"\n    \n    # Verify callback was called (even though it raised an exception)\n    assert llm.config.response_callback is faulty_callback\n\n\ndef test_callback_with_tools(mock_openai_client):\n    mock_callback = Mock()\n    config = OpenAIConfig(model=\"gpt-4.1-nano-2025-04-14\", response_callback=mock_callback)\n    llm = OpenAILLM(config)\n    messages = [{\"role\": \"user\", \"content\": \"Test tools\"}]\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"test_tool\",\n                \"description\": \"A test tool\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\"param1\": {\"type\": \"string\"}},\n                    \"required\": [\"param1\"],\n                },\n            }\n        }\n    ]\n    \n    # Mock tool response\n    mock_response = Mock()\n    mock_message = Mock()\n    mock_message.content = \"Tool response\"\n    mock_tool_call = Mock()\n    mock_tool_call.function.name = \"test_tool\"\n    mock_tool_call.function.arguments = '{\"param1\": \"value1\"}'\n    mock_message.tool_calls = [mock_tool_call]\n    mock_response.choices = [Mock(message=mock_message)]\n    mock_openai_client.chat.completions.create.return_value = mock_response\n    \n    llm.generate_response(messages, tools=tools)\n    \n    # Verify callback called with tool response\n    mock_callback.assert_called_once()\n    # Check that tool_calls exists in the message\n    assert hasattr(mock_callback.call_args[0][1].choices[0].message, 'tool_calls')\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_43","type":"reasoning","text":"**Assessing test and lint setup**"}}
{"type":"item.started","item":{"id":"item_44","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,320p' pyproject.toml\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_44","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,320p' pyproject.toml\"","aggregated_output":"[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"mem0ai\"\nversion = \"1.0.4\"\ndescription = \"Long-term memory for AI Agents\"\nauthors = [\n    { name = \"Mem0\", email = \"founders@mem0.ai\" }\n]\nreadme = \"README.md\"\nlicense = \"Apache-2.0\"\nlicense-files = [\"LICENSE\"]\nrequires-python = \">=3.9,<4.0\"\ndependencies = [\n    \"qdrant-client>=1.9.1\",\n    \"pydantic>=2.7.3\",\n    \"openai>=1.90.0\",\n    \"posthog>=3.5.0\",\n    \"pytz>=2024.1\",\n    \"sqlalchemy>=2.0.31\",\n    \"protobuf>=5.29.0,<6.0.0\",\n]\n\n[project.optional-dependencies]\ngraph = [\n    \"langchain-neo4j>=0.4.0\",\n    \"langchain-aws>=0.2.23\",\n    \"langchain-memgraph>=0.1.0\",\n    \"neo4j>=5.23.1\",\n    \"rank-bm25>=0.2.2\",\n    \"kuzu>=0.11.0\",\n]\nvector_stores = [\n    \"vecs>=0.4.0\",\n    \"chromadb>=0.4.24\",\n    \"cassandra-driver>=3.29.0\",\n    \"weaviate-client>=4.4.0,<4.15.0\",\n    \"pinecone<=7.3.0\",\n    \"pinecone-text>=0.10.0\",\n    \"faiss-cpu>=1.7.4\",\n    \"upstash-vector>=0.1.0\",\n    \"azure-search-documents>=11.4.0b8\",\n    \"psycopg>=3.2.8\",\n    \"psycopg-pool>=3.2.6,<4.0.0\",\n    \"pymongo>=4.13.2\",\n    \"pymochow>=2.2.9\",\n    \"pymysql>=1.1.0\",\n    \"dbutils>=3.0.3\",\n    \"valkey>=6.0.0\",\n    \"databricks-sdk>=0.63.0\",\n    \"azure-identity>=1.24.0\",\n    \"redis>=5.0.0,<6.0.0\",\n    \"redisvl>=0.1.0,<1.0.0\",\n    \"elasticsearch>=8.0.0,<9.0.0\",\n    \"pymilvus>=2.4.0,<2.6.0\",\n    \"langchain-aws>=0.2.23\",\n]\nllms = [\n    \"groq>=0.3.0\",\n    \"together>=0.2.10\",\n    \"litellm>=1.74.0\",\n    \"openai>=1.90.0\",\n    \"ollama>=0.1.0\",\n    \"vertexai>=0.1.0\",\n    \"google-generativeai>=0.3.0\",\n    \"google-genai>=1.0.0\",\n]\nextras = [\n    \"boto3>=1.34.0\",\n    \"langchain-community>=0.0.0\",\n    \"sentence-transformers>=5.0.0\",\n    \"elasticsearch>=8.0.0,<9.0.0\",\n    \"opensearch-py>=2.0.0\",\n    \"fastembed>=0.3.1\",\n]\ntest = [\n    \"pytest>=8.2.2\",\n    \"pytest-mock>=3.14.0\",\n    \"pytest-asyncio>=0.23.7\",\n]\ndev = [\n    \"ruff>=0.6.5\",\n    \"isort>=5.13.2\",\n    \"pytest>=8.2.2\",\n]\n\n[tool.pytest.ini_options]\npythonpath = [\".\"]\n\n[tool.hatch.build]\ninclude = [\n    \"mem0/**/*.py\",\n]\nexclude = [\n    \"**/*\",\n    \"!mem0/**/*.py\",\n]\n\n[tool.hatch.build.targets.wheel]\npackages = [\"mem0\"]\nonly-include = [\"mem0\"]\n\n[tool.hatch.build.targets.wheel.shared-data]\n\"README.md\" = \"README.md\"\n\n[tool.hatch.envs.dev_py_3_9]\npython = \"3.9\"\nfeatures = [\n  \"test\",\n  \"graph\",\n  \"vector_stores\",\n  \"llms\",\n  \"extras\",\n]\n\n[tool.hatch.envs.dev_py_3_10]\npython = \"3.10\"\nfeatures = [\n  \"test\",\n  \"graph\",\n  \"vector_stores\",\n  \"llms\",\n  \"extras\",\n]\n\n[tool.hatch.envs.dev_py_3_11]\npython = \"3.11\"\nfeatures = [\n  \"test\",\n  \"graph\",\n  \"vector_stores\",\n  \"llms\",\n  \"extras\",\n]\n\n[tool.hatch.envs.dev_py_3_12]\npython = \"3.12\"\nfeatures = [\n  \"test\",\n  \"graph\",\n  \"vector_stores\",\n  \"llms\",\n  \"extras\",\n]\n\n[tool.hatch.envs.default.scripts]\nformat = [\n    \"ruff format\",\n]\nformat-check = [\n    \"ruff format --check\",\n]\nlint = [\n    \"ruff check\",\n]\nlint-fix = [\n    \"ruff check --fix\",\n]\ntest = [\n    \"pytest tests/ {args}\",\n]\n\n[tool.ruff]\nline-length = 120\nexclude = [\"embedchain/\", \"openmemory/\"]\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_45","type":"reasoning","text":"**Reviewing dependency and style changes**"}}
{"type":"item.started","item":{"id":"item_46","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,220p' docs/llms.txt\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.started","item":{"id":"item_47","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,220p' docs/components/llms/models/forge.mdx\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_47","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,220p' docs/components/llms/models/forge.mdx\"","aggregated_output":"---\ntitle: Forge\n---\n\n[Forge](https://forge.tensorblock.co) is an LLM router that provides unified access to multiple AI providers (OpenAI, Anthropic, Google, and more) through a single API. It's compatible with the OpenAI API format, making it easy to integrate with existing applications.\n\n## Usage\n\n```python\nimport os\nfrom mem0 import Memory\n\nos.environ[\"FORGE_API_KEY\"] = \"your-api-key\"\n\nconfig = {\n    \"llm\": {\n        \"provider\": \"openai\",\n        \"config\": {\n            \"model\": \"OpenAI/gpt-4o-mini\",\n            \"temperature\": 0.2,\n            \"max_tokens\": 2000,\n        }\n    }\n}\n\nm = Memory.from_config(config)\nmessages = [\n    {\"role\": \"user\", \"content\": \"I'm planning to watch a movie tonight. Any recommendations?\"},\n    {\"role\": \"assistant\", \"content\": \"How about thriller movies? They can be quite engaging.\"},\n    {\"role\": \"user\", \"content\": \"I'm not a big fan of thriller movies but I love sci-fi movies.\"},\n    {\"role\": \"assistant\", \"content\": \"Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future.\"}\n]\nm.add(messages, user_id=\"alice\", metadata={\"category\": \"movies\"})\n```\n\nYou can optionally set a custom base URL:\n\n```python\nos.environ[\"FORGE_API_BASE\"] = \"https://api.forge.tensorblock.co/v1\"\n```\n\n## Config\n\nAll available parameters for the `openai` config are present in [Master List of All Params in Config](../config).\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_46","type":"command_execution","command":"/bin/zsh -lc \"sed -n '1,220p' docs/llms.txt\"","aggregated_output":"# Mem0\n\n> Mem0 is a self-improving memory layer for LLM applications, enabling personalized AI experiences that retain context across sessions, adapt over time, and reduce costs by intelligently storing and retrieving relevant information.\n\nMem0 provides both a managed platform and open-source solutions for adding persistent memory to AI agents and applications. Unlike traditional RAG systems that are stateless, Mem0 creates stateful agents that remember user preferences, learn from interactions, and evolve behavior over time.\n\nKey differentiators:\n- **Stateful vs Stateless**: Retains context across sessions rather than forgetting after each interaction\n- **Intelligent Memory Management**: Uses LLMs to extract, filter, and organize relevant information\n- **Dual Storage Architecture**: Combines vector embeddings with graph databases for comprehensive memory\n- **Sub-50ms Retrieval**: Lightning-fast memory lookups for real-time applications\n- **Multimodal Support**: Handles text, images, and documents seamlessly\n\n## Getting Started\n\n- [Introduction](https://docs.mem0.ai/introduction): Overview of Mem0's memory layer for AI agents, including stateless vs stateful agents and how memory fits in the agent stack\n- [Platform Quickstart](https://docs.mem0.ai/platform/quickstart): Get started with Mem0 Platform (managed) in minutes\n- [Open Source Python Quickstart](https://docs.mem0.ai/open-source/python-quickstart): Get started with Mem0 Open Source using Python\n- [Open Source Node.js Quickstart](https://docs.mem0.ai/open-source/node-quickstart): Get started with Mem0 Open Source using Node.js\n- [Platform Overview](https://docs.mem0.ai/platform/overview): Managed solution with 4-line integration, sub-50ms latency, and intuitive dashboard\n- [Open Source Overview](https://docs.mem0.ai/open-source/overview): Self-hosted solution with full infrastructure control and customization\n\n## Core Concepts\n\n- [Memory Types](https://docs.mem0.ai/core-concepts/memory-types): Working memory (short-term session awareness), factual memory (structured knowledge), episodic memory (past conversations), and semantic memory (general knowledge)\n- [Memory Operations - Add](https://docs.mem0.ai/core-concepts/memory-operations/add): How Mem0 processes conversations through information extraction, conflict resolution, and dual storage\n- [Memory Operations - Search](https://docs.mem0.ai/core-concepts/memory-operations/search): Retrieval of relevant memories using semantic search with query processing and result ranking\n- [Memory Operations - Update](https://docs.mem0.ai/core-concepts/memory-operations/update): Modifying existing memories when new information conflicts or supplements stored data\n- [Memory Operations - Delete](https://docs.mem0.ai/core-concepts/memory-operations/delete): Removing outdated or irrelevant memories to maintain memory quality\n\n## Platform (Managed Solution)\n\n- [Platform Quickstart](https://docs.mem0.ai/platform/quickstart): Complete guide to using Mem0 Platform with Python, JavaScript, and cURL examples\n- [Platform vs Open Source](https://docs.mem0.ai/platform/platform-vs-oss): Compare managed platform vs self-hosted options\n- [Advanced Memory Operations](https://docs.mem0.ai/platform/advanced-memory-operations): Sophisticated memory management techniques for complex applications\n\n### Essential Platform Features\n- [V2 Memory Filters](https://docs.mem0.ai/platform/features/v2-memory-filters): Advanced filtering and querying capabilities\n- [Async Client](https://docs.mem0.ai/platform/features/async-client): Non-blocking operations for high-concurrency applications\n- [Multimodal Support](https://docs.mem0.ai/platform/features/multimodal-support): Integration of images and documents (JPG, PNG, MDX, TXT, PDF) via URLs or Base64\n- [Custom Categories](https://docs.mem0.ai/platform/features/custom-categories): Define domain-specific categories to improve memory organization\n- [Async Mode Default Changes](https://docs.mem0.ai/platform/features/async-mode-default-change): Understanding new async behavior defaults\n\n### Advanced Platform Features\n- [Graph Memory](https://docs.mem0.ai/platform/features/graph-memory): Build and query relationships between entities for contextually relevant retrieval\n- [Graph Threshold](https://docs.mem0.ai/platform/features/graph-threshold): Configure graph relationship sensitivity and strength\n- [Advanced Retrieval](https://docs.mem0.ai/platform/features/advanced-retrieval): Enhanced search with keyword search, reranking, and filtering capabilities\n- [Criteria-Based Retrieval](https://docs.mem0.ai/platform/features/criteria-retrieval): Targeted memory retrieval using custom criteria\n- [Contextual Add](https://docs.mem0.ai/platform/features/contextual-add): Add memories with enhanced context awareness\n- [Custom Instructions](https://docs.mem0.ai/platform/features/custom-instructions): Customize how Mem0 processes and stores information\n\n### Data Management\n- [Direct Import](https://docs.mem0.ai/platform/features/direct-import): Bulk import existing data into Mem0 memory\n- [Memory Export](https://docs.mem0.ai/platform/features/memory-export): Export memories in structured formats using customizable Pydantic schemas\n- [Timestamp Support](https://docs.mem0.ai/platform/features/timestamp): Temporal memory management with time-based queries\n- [Expiration Dates](https://docs.mem0.ai/platform/features/expiration-date): Automatic memory cleanup with configurable expiration\n\n### Integration Features\n- [Webhooks](https://docs.mem0.ai/platform/features/webhooks): Real-time notifications for memory events\n- [Feedback Mechanism](https://docs.mem0.ai/platform/features/feedback-mechanism): Improve memory quality through user feedback\n- [Group Chat Support](https://docs.mem0.ai/platform/features/group-chat): Multi-conversation memory management\n\n### Platform Support\n- [FAQs](https://docs.mem0.ai/platform/faqs): Frequently asked questions about Mem0 Platform\n- [Contribute Guide](https://docs.mem0.ai/platform/contribute): Contributing to Mem0 Platform development\n\n## Open Source\n\n### Getting Started\n- [Python Quickstart](https://docs.mem0.ai/open-source/python-quickstart): Installation, configuration, and usage examples for Python SDK\n- [Node.js Quickstart](https://docs.mem0.ai/open-source/node-quickstart): Installation, configuration, and usage examples for Node.js SDK\n- [Configuration Guide](https://docs.mem0.ai/open-source/configuration): Complete configuration options for self-hosted deployment\n\n### Open Source Features\n- [OpenAI Compatibility](https://docs.mem0.ai/open-source/features/openai_compatibility): Seamless integration with OpenAI-compatible APIs\n- [REST API Server](https://docs.mem0.ai/open-source/features/rest-api): FastAPI-based server with core operations and OpenAPI documentation\n- [Graph Memory](https://docs.mem0.ai/open-source/features/graph-memory): Build and query entity relationships using graph stores like Neo4j\n- [Metadata Filtering](https://docs.mem0.ai/open-source/features/metadata-filtering): Advanced filtering using custom metadata fields\n- [Reranker Search](https://docs.mem0.ai/open-source/features/reranker-search): Enhanced search results with reranking models\n- [Async Memory](https://docs.mem0.ai/open-source/features/async-memory): Asynchronous memory operations for better performance\n- [Multimodal Support](https://docs.mem0.ai/open-source/features/multimodal-support): Handle text, images, and documents in self-hosted setup\n\n### Customization\n- [Custom Fact Extraction](https://docs.mem0.ai/open-source/features/custom-fact-extraction-prompt): Tailor information extraction for specific use cases\n- [Custom Memory Update Prompt](https://docs.mem0.ai/open-source/features/custom-update-memory-prompt): Customize how memories are updated and merged\n\n## Components\n\n- [LLM Overview](https://docs.mem0.ai/components/llms/overview): Comprehensive guide to Large Language Model integration and configuration options\n- [Vector Database Overview](https://docs.mem0.ai/components/vectordbs/overview): Guide to supported vector databases for semantic memory storage\n- [Embeddings Overview](https://docs.mem0.ai/components/embedders/overview): Embedding model configuration for semantic understanding\n\n### Supported LLMs\n\n- [OpenAI](https://docs.mem0.ai/components/llms/models/openai): Integration with OpenAI models including GPT-4 and structured outputs\n- [Anthropic](https://docs.mem0.ai/components/llms/models/anthropic): Claude model integration with advanced reasoning capabilities\n- [Google AI](https://docs.mem0.ai/components/llms/models/google_AI): Gemini model integration for multimodal applications\n- [Groq](https://docs.mem0.ai/components/llms/models/groq): High-performance LPU optimized models for fast inference\n- [AWS Bedrock](https://docs.mem0.ai/components/llms/models/aws_bedrock): Enterprise-grade AWS managed model integration\n- [Azure OpenAI](https://docs.mem0.ai/components/llms/models/azure_openai): Microsoft Azure hosted OpenAI models for enterprise environments\n- [Ollama](https://docs.mem0.ai/components/llms/models/ollama): Local model deployment for privacy-focused applications\n- [vLLM](https://docs.mem0.ai/components/llms/models/vllm): High-performance inference framework\n- [LM Studio](https://docs.mem0.ai/components/llms/models/lmstudio): Local model management and deployment\n- [Together](https://docs.mem0.ai/components/llms/models/together): Open-source model inference platform\n- [DeepSeek](https://docs.mem0.ai/components/llms/models/deepseek): Advanced reasoning models\n- [Sarvam](https://docs.mem0.ai/components/llms/models/sarvam): Indian language models\n- [XAI](https://docs.mem0.ai/components/llms/models/xai): xAI models integration\n- [LiteLLM](https://docs.mem0.ai/components/llms/models/litellm): Unified LLM interface and proxy\n- [Forge](https://docs.mem0.ai/components/llms/models/forge): LLM router with unified access to multiple AI providers\n- [LangChain](https://docs.mem0.ai/components/llms/models/langchain): LangChain LLM integration\n- [OpenAI Structured](https://docs.mem0.ai/components/llms/models/openai_structured): OpenAI with structured output support\n- [Azure OpenAI Structured](https://docs.mem0.ai/components/llms/models/azure_openai_structured): Azure OpenAI with structured outputs\n\n### Supported Vector Databases\n\n- [Qdrant](https://docs.mem0.ai/components/vectordbs/dbs/qdrant): High-performance vector similarity search engine\n- [Pinecone](https://docs.mem0.ai/components/vectordbs/dbs/pinecone): Managed vector database with serverless and pod deployment options\n- [Chroma](https://docs.mem0.ai/components/vectordbs/dbs/chroma): AI-native open-source vector database optimized for speed\n- [Weaviate](https://docs.mem0.ai/components/vectordbs/dbs/weaviate): Open-source vector search engine with built-in ML capabilities\n- [PGVector](https://docs.mem0.ai/components/vectordbs/dbs/pgvector): PostgreSQL extension for vector similarity search\n- [Milvus](https://docs.mem0.ai/components/vectordbs/dbs/milvus): Open-source vector database for AI applications at scale\n- [Redis](https://docs.mem0.ai/components/vectordbs/dbs/redis): Real-time vector storage and search with Redis Stack\n- [Supabase](https://docs.mem0.ai/components/vectordbs/dbs/supabase): Open-source Firebase alternative with vector support\n- [Upstash Vector](https://docs.mem0.ai/components/vectordbs/dbs/upstash_vector): Serverless vector database\n- [Elasticsearch](https://docs.mem0.ai/components/vectordbs/dbs/elasticsearch): Distributed search and analytics engine\n- [OpenSearch](https://docs.mem0.ai/components/vectordbs/dbs/opensearch): Open-source search and analytics platform\n- [FAISS](https://docs.mem0.ai/components/vectordbs/dbs/faiss): Facebook AI Similarity Search library\n- [MongoDB](https://docs.mem0.ai/components/vectordbs/dbs/mongodb): Document database with vector search capabilities\n- [Azure AI Search](https://docs.mem0.ai/components/vectordbs/dbs/azure): Microsoft's enterprise search service\n- [Vertex AI Vector Search](https://docs.mem0.ai/components/vectordbs/dbs/vertex_ai): Google Cloud's vector search service\n- [Databricks](https://docs.mem0.ai/components/vectordbs/dbs/databricks): Delta Lake integration for vector search\n- [Baidu](https://docs.mem0.ai/components/vectordbs/dbs/baidu): Baidu vector database integration\n- [LangChain](https://docs.mem0.ai/components/vectordbs/dbs/langchain): LangChain vector store integration\n- [S3 Vectors](https://docs.mem0.ai/components/vectordbs/dbs/s3_vectors): Amazon S3 Vectors integration\n\n### Supported Embeddings\n\n- [OpenAI Embeddings](https://docs.mem0.ai/components/embedders/models/openai): High-quality text embeddings with customizable dimensions\n- [Azure OpenAI Embeddings](https://docs.mem0.ai/components/embedders/models/azure_openai): Enterprise Azure-hosted embedding models\n- [Google AI](https://docs.mem0.ai/components/embedders/models/google_ai): Gemini embedding models\n- [AWS Bedrock](https://docs.mem0.ai/components/embedders/models/aws_bedrock): Amazon embedding models through Bedrock\n- [Hugging Face](https://docs.mem0.ai/components/embedders/models/hugging_face): Open-source embedding models for local deployment\n- [Vertex AI](https://docs.mem0.ai/components/embedders/models/vertexai): Google Cloud's enterprise embedding models\n- [Ollama](https://docs.mem0.ai/components/embedders/models/ollama): Local embedding models for privacy-focused applications\n- [Together](https://docs.mem0.ai/components/embedders/models/together): Open-source model embeddings\n- [LM Studio](https://docs.mem0.ai/components/embedders/models/lmstudio): Local model embeddings\n- [LangChain](https://docs.mem0.ai/components/embedders/models/langchain): LangChain embedder integration\n\n## Integrations\n\n- [LangChain](https://docs.mem0.ai/integrations/langchain): Seamless integration with LangChain framework for enhanced agent capabilities\n- [LangGraph](https://docs.mem0.ai/integrations/langgraph): Build stateful, multi-actor applications with persistent memory\n- [LlamaIndex](https://docs.mem0.ai/integrations/llama-index): Enhanced RAG applications with intelligent memory layer\n- [CrewAI](https://docs.mem0.ai/integrations/crewai): Multi-agent systems with shared and individual memory capabilities\n- [AutoGen](https://docs.mem0.ai/integrations/autogen): Microsoft's multi-agent conversation framework with memory\n- [Vercel AI SDK](https://docs.mem0.ai/integrations/vercel-ai-sdk): Build AI-powered web applications with persistent memory\n- [Flowise](https://docs.mem0.ai/integrations/flowise): No-code LLM workflow builder with memory capabilities\n- [Dify](https://docs.mem0.ai/integrations/dify): LLMOps platform integration for production AI applications\n\n## Cookbooks and Examples\n\n### Cookbooks Overview\n- [Cookbooks Overview](https://docs.mem0.ai/cookbooks/overview): Complete guide to Mem0 examples and implementation patterns\n\n### Essential Guides\n- [Building AI Companion](https://docs.mem0.ai/cookbooks/essentials/building-ai-companion): Core patterns for building AI agents with memory\n- [Partition Memories by Entity](https://docs.mem0.ai/cookbooks/essentials/entity-partitioning-playbook): Keep multi-tenant assistants isolated by tagging user, agent, app, and session identifiers\n- [Controlling Memory Ingestion](https://docs.mem0.ai/cookbooks/essentials/controlling-memory-ingestion): Fine-tune what gets stored in memory and when\n- [Memory Expiration](https://docs.mem0.ai/cookbooks/essentials/memory-expiration-short-and-long-term): Implement short-term and long-term memory strategies\n- [Tagging and Organizing Memories](https://docs.mem0.ai/cookbooks/essentials/tagging-and-organizing-memories): Advanced memory organization and categorization\n- [Exporting Memories](https://docs.mem0.ai/cookbooks/essentials/exporting-memories): Backup and transfer memory data between systems\n- [Choosing Memory Architecture](https://docs.mem0.ai/cookbooks/essentials/choosing-memory-architecture-vector-vs-graph): Vector vs Graph memory architectures comparison\n\n### AI Companion Examples\n- [AI Tutor](https://docs.mem0.ai/cookbooks/companions/ai-tutor): Educational AI that adapts to learning progress\n- [Travel Assistant](https://docs.mem0.ai/cookbooks/companions/travel-assistant): Travel planning agent that learns preferences\n- [Voice Companion](https://docs.mem0.ai/cookbooks/companions/voice-companion-openai): Voice-enabled AI with conversational memory\n- [Local Companion](https://docs.mem0.ai/cookbooks/companions/local-companion-ollama): Privacy-focused companion using local models\n- [Node.js Companion](https://docs.mem0.ai/cookbooks/companions/nodejs-companion): JavaScript-based AI companion applications\n- [YouTube Research Assistant](https://docs.mem0.ai/cookbooks/companions/youtube-research): AI that researches and learns from video content\n\n### Operations & Automation\n- [Support Inbox](https://docs.mem0.ai/cookbooks/operations/support-inbox): Customer service agents with conversation history\n- [Email Automation](https://docs.mem0.ai/cookbooks/operations/email-automation): Smart email processing with contextual memory\n- [Content Writing](https://docs.mem0.ai/cookbooks/operations/content-writing): AI writers that maintain brand voice and style\n- [Deep Research](https://docs.mem0.ai/cookbooks/operations/deep-research): Research assistants that build on previous findings\n- [Team Task Agent](https://docs.mem0.ai/cookbooks/operations/team-task-agent): Collaborative AI agents with shared project memory\n\n### Integration Examples\n- [OpenAI Tool Calls](https://docs.mem0.ai/cookbooks/integrations/openai-tool-calls): Mem0 integrated with OpenAI function calling\n- [AWS Bedrock](https://docs.mem0.ai/cookbooks/integrations/aws-bedrock): Enterprise memory with AWS managed services\n- [Tavily Search](https://docs.mem0.ai/cookbooks/integrations/tavily-search): Web search with persistent memory of results\n- [Healthcare Google ADK](https://docs.mem0.ai/cookbooks/integrations/healthcare-google-adk): Medical AI applications with memory\n- [Mastra Agent](https://docs.mem0.ai/cookbooks/integrations/mastra-agent): Mastra framework integration with memory\n\n### Framework Examples\n- [LlamaIndex React](https://docs.mem0.ai/cookbooks/frameworks/llamaindex-react): React applications with LlamaIndex and memory\n- [LlamaIndex Multiagent](https://docs.mem0.ai/cookbooks/frameworks/llamaindex-multiagent): Multi-agent systems with shared memory\n- [Eliza OS Character](https://docs.mem0.ai/cookbooks/frameworks/eliza-os-character): Character-based AI with persistent personality\n- [Chrome Extension](https://docs.mem0.ai/cookbooks/frameworks/chrome-extension): Browser extensions that remember user interactions\n- [Multimodal Retrieval](https://docs.mem0.ai/cookbooks/frameworks/multimodal-retrieval): Memory systems handling text, images, and documents\n\n## API Reference\n\n- [Memory APIs](https://docs.mem0.ai/api-reference/memory/add-memories): Comprehensive API documentation for memory operations\n- [Add Memories](https://docs.mem0.ai/api-reference/memory/add-memories): REST API for storing new memories with detailed request/response formats\n- [Search Memories](https://docs.mem0.ai/api-reference/memory/search-memories): Advanced search API with filtering and ranking capabilities\n- [Get All Memories](https://docs.mem0.ai/api-reference/memory/get-memories): Retrieve all memories with pagination and filtering options\n- [Update Memory](https://docs.mem0.ai/api-reference/memory/update-memory): Modify existing memories with conflict resolution\n- [Delete Memory](https://docs.mem0.ai/api-reference/memory/delete-memory): Remove memories individually or in batches\n\n## Optional\n\n- [FAQs](https://docs.mem0.ai/platform/faqs): Frequently asked questions about Mem0's Platform capabilities and implementation details\n- [Changelog](https://docs.mem0.ai/changelog): Detailed product updates and version history for tracking new features and improvements\n- [Contributing Guide](https://docs.mem0.ai/contributing/development): Guidelines for contributing to Mem0's open-source development\n- [OpenMemory](https://docs.mem0.ai/openmemory/overview): Open-source memory infrastructure for research and experimentation\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_48","type":"reasoning","text":"**Reviewing latest commit diff**"}}
{"type":"item.started","item":{"id":"item_49","type":"command_execution","command":"/bin/zsh -lc 'git show --patch --stat HEAD -- mem0/llms/openai.py docs/components/llms/models/forge.mdx docs/llms.txt'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_49","type":"command_execution","command":"/bin/zsh -lc 'git show --patch --stat HEAD -- mem0/llms/openai.py docs/components/llms/models/forge.mdx docs/llms.txt'","aggregated_output":"commit c05a3bc161bc18c96c045ca3e28bf2f700e32ad2\nAuthor: Yiiii0 <yiqiaozhou@outlook.com>\nDate:   Tue Feb 24 17:31:53 2026 -0500\n\n    feat: Add Forge LLM provider support\n    \n    ## Changes\n    \n    - Add Forge provider integration with docs and tests\n    - Environment variable: FORGE_API_KEY\n    - Base URL: https://api.forge.tensorblock.co/v1\n    - Model format: Provider/model-name (e.g., OpenAI/gpt-4o)\n    - Non-breaking: purely additive, existing providers are untouched\n    \n    ## About Forge\n    \n    Forge (https://github.com/TensorBlock/forge) is an open-source middleware that routes inference across 40+ upstream providers (including OpenAI, Anthropic, Gemini, DeepSeek, and OpenRouter). It is OpenAI API compatible â€” works with the standard OpenAI SDK by changing base_url and api_key.\n    \n    ## Motivation\n    \n    We have seen growing interest from users who standardize on Forge for their model management and want to use it natively with mem0. This integration aims to bridge that gap.\n    \n    ## Key Benefits\n    \n    - Self-Hosted & Privacy-First: Forge is open-source and designed to be self-hosted, critical for users who require data sovereignty\n    - Future-Proofing: acts as a decoupling layer â€” instead of maintaining individual adapters for every new provider, Forge users can access them immediately\n    - Compatibility: supports established aggregators (like OpenRouter) as well as direct provider connections (BYOK)\n    \n    ## References\n    \n    - Repo: https://github.com/TensorBlock/forge\n    - Docs: https://www.tensorblock.co/api-docs/overview\n    - Main Page: https://www.tensorblock.co/\n---\n docs/components/llms/models/forge.mdx | 44 +++++++++++++++++++++++++++++++++++\n docs/llms.txt                         |  1 +\n mem0/llms/openai.py                   | 28 +++++++++++++++-------\n 3 files changed, 64 insertions(+), 9 deletions(-)\n\ndiff --git a/docs/components/llms/models/forge.mdx b/docs/components/llms/models/forge.mdx\nnew file mode 100644\nindex 00000000..f7d003aa\n--- /dev/null\n+++ b/docs/components/llms/models/forge.mdx\n@@ -0,0 +1,44 @@\n+---\n+title: Forge\n+---\n+\n+[Forge](https://forge.tensorblock.co) is an LLM router that provides unified access to multiple AI providers (OpenAI, Anthropic, Google, and more) through a single API. It's compatible with the OpenAI API format, making it easy to integrate with existing applications.\n+\n+## Usage\n+\n+```python\n+import os\n+from mem0 import Memory\n+\n+os.environ[\"FORGE_API_KEY\"] = \"your-api-key\"\n+\n+config = {\n+    \"llm\": {\n+        \"provider\": \"openai\",\n+        \"config\": {\n+            \"model\": \"OpenAI/gpt-4o-mini\",\n+            \"temperature\": 0.2,\n+            \"max_tokens\": 2000,\n+        }\n+    }\n+}\n+\n+m = Memory.from_config(config)\n+messages = [\n+    {\"role\": \"user\", \"content\": \"I'm planning to watch a movie tonight. Any recommendations?\"},\n+    {\"role\": \"assistant\", \"content\": \"How about thriller movies? They can be quite engaging.\"},\n+    {\"role\": \"user\", \"content\": \"I'm not a big fan of thriller movies but I love sci-fi movies.\"},\n+    {\"role\": \"assistant\", \"content\": \"Got it! I'll avoid thriller recommendations and suggest sci-fi movies in the future.\"}\n+]\n+m.add(messages, user_id=\"alice\", metadata={\"category\": \"movies\"})\n+```\n+\n+You can optionally set a custom base URL:\n+\n+```python\n+os.environ[\"FORGE_API_BASE\"] = \"https://api.forge.tensorblock.co/v1\"\n+```\n+\n+## Config\n+\n+All available parameters for the `openai` config are present in [Master List of All Params in Config](../config).\ndiff --git a/docs/llms.txt b/docs/llms.txt\nindex fed2454a..e9ff6b73 100644\n--- a/docs/llms.txt\n+++ b/docs/llms.txt\n@@ -106,6 +106,7 @@ Key differentiators:\n - [Sarvam](https://docs.mem0.ai/components/llms/models/sarvam): Indian language models\n - [XAI](https://docs.mem0.ai/components/llms/models/xai): xAI models integration\n - [LiteLLM](https://docs.mem0.ai/components/llms/models/litellm): Unified LLM interface and proxy\n+- [Forge](https://docs.mem0.ai/components/llms/models/forge): LLM router with unified access to multiple AI providers\n - [LangChain](https://docs.mem0.ai/components/llms/models/langchain): LangChain LLM integration\n - [OpenAI Structured](https://docs.mem0.ai/components/llms/models/openai_structured): OpenAI with structured output support\n - [Azure OpenAI Structured](https://docs.mem0.ai/components/llms/models/azure_openai_structured): Azure OpenAI with structured outputs\ndiff --git a/mem0/llms/openai.py b/mem0/llms/openai.py\nindex a486ff86..1c16bcb8 100644\n--- a/mem0/llms/openai.py\n+++ b/mem0/llms/openai.py\n@@ -37,7 +37,12 @@ class OpenAILLM(LLMBase):\n         if not self.config.model:\n             self.config.model = \"gpt-4.1-nano-2025-04-14\"\n \n-        if os.environ.get(\"OPENROUTER_API_KEY\"):  # Use OpenRouter\n+        if os.environ.get(\"FORGE_API_KEY\"):  # Use Forge\n+            self.client = OpenAI(\n+                api_key=os.environ.get(\"FORGE_API_KEY\"),\n+                base_url=os.getenv(\"FORGE_API_BASE\") or \"https://api.forge.tensorblock.co/v1\",\n+            )\n+        elif os.environ.get(\"OPENROUTER_API_KEY\"):  # Use OpenRouter\n             self.client = OpenAI(\n                 api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n                 base_url=self.config.openrouter_base_url\n@@ -102,13 +107,18 @@ class OpenAILLM(LLMBase):\n             json: The generated response.\n         \"\"\"\n         params = self._get_supported_params(messages=messages, **kwargs)\n-        \n-        params.update({\n-            \"model\": self.config.model,\n-            \"messages\": messages,\n-        })\n \n-        if os.getenv(\"OPENROUTER_API_KEY\"):\n+        params.update(\n+            {\n+                \"model\": self.config.model,\n+                \"messages\": messages,\n+            }\n+        )\n+\n+        if os.getenv(\"FORGE_API_KEY\"):\n+            # Forge uses standard OpenAI API format, no special parameters needed\n+            pass\n+        elif os.getenv(\"OPENROUTER_API_KEY\"):\n             openrouter_params = {}\n             if self.config.models:\n                 openrouter_params[\"models\"] = self.config.models\n@@ -123,13 +133,13 @@ class OpenAILLM(LLMBase):\n                 openrouter_params[\"extra_headers\"] = extra_headers\n \n             params.update(**openrouter_params)\n-        \n+\n         else:\n             openai_specific_generation_params = [\"store\"]\n             for param in openai_specific_generation_params:\n                 if hasattr(self.config, param):\n                     params[param] = getattr(self.config, param)\n-            \n+\n         if response_format:\n             params[\"response_format\"] = response_format\n         if tools:  # TODO: Remove tools if no issues found with new memory addition logic\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_50","type":"reasoning","text":"**Checking test and lint setup**"}}
{"type":"item.started","item":{"id":"item_51","type":"command_execution","command":"/bin/zsh -lc 'hatch --version'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_51","type":"command_execution","command":"/bin/zsh -lc 'hatch --version'","aggregated_output":"Hatch, version 1.16.3\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_52","type":"reasoning","text":"**Planning sequential checks**"}}
{"type":"item.completed","item":{"id":"item_53","type":"agent_message","text":"Iâ€™m moving to validation now using the repoâ€™s documented CI commands for mem0 changes: `make lint` and `make test`. If either fails, Iâ€™ll triage and patch minimally."}}
{"type":"item.started","item":{"id":"item_54","type":"command_execution","command":"/bin/zsh -lc 'make lint'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_54","type":"command_execution","command":"/bin/zsh -lc 'make lint'","aggregated_output":"Creating environment: default\nInstalling project in development mode\nChecking dependencies\nAll checks passed!\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_55","type":"reasoning","text":"**Running tests with default features**"}}
{"type":"item.started","item":{"id":"item_56","type":"command_execution","command":"/bin/zsh -lc 'make test'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_56","type":"command_execution","command":"/bin/zsh -lc 'make test'","aggregated_output":"============================= test session starts ==============================\nplatform darwin -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0\nconfigfile: pyproject.toml\nplugins: anyio-4.12.1, langsmith-0.7.3\ncollected 17 items / 52 errors\n\n==================================== ERRORS ====================================\n________________ ERROR collecting tests/configs/test_prompts.py ________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/configs/test_prompts.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/configs/test_prompts.py:1: in <module>\n    from mem0.configs import prompts\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n______ ERROR collecting tests/embeddings/test_azure_openai_embeddings.py _______\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_azure_openai_embeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_azure_openai_embeddings.py:5: in <module>\n    from mem0.configs.embeddings.base import BaseEmbedderConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________ ERROR collecting tests/embeddings/test_fastembed_embeddings.py ________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_fastembed_embeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_fastembed_embeddings.py:5: in <module>\n    from mem0.configs.embeddings.base import BaseEmbedderConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n__________ ERROR collecting tests/embeddings/test_gemini_emeddings.py __________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_gemini_emeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_gemini_emeddings.py:5: in <module>\n    from mem0.configs.embeddings.base import BaseEmbedderConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_______ ERROR collecting tests/embeddings/test_huggingface_embeddings.py _______\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_huggingface_embeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_huggingface_embeddings.py:6: in <module>\n    from mem0.configs.embeddings.base import BaseEmbedderConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________ ERROR collecting tests/embeddings/test_lm_studio_embeddings.py ________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_lm_studio_embeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_lm_studio_embeddings.py:5: in <module>\n    from mem0.configs.embeddings.base import BaseEmbedderConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________ ERROR collecting tests/embeddings/test_ollama_embeddings.py __________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_ollama_embeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_ollama_embeddings.py:5: in <module>\n    from mem0.configs.embeddings.base import BaseEmbedderConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________ ERROR collecting tests/embeddings/test_openai_embeddings.py __________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_openai_embeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_openai_embeddings.py:5: in <module>\n    from mem0.configs.embeddings.base import BaseEmbedderConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________ ERROR collecting tests/embeddings/test_vertexai_embeddings.py _________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/embeddings/test_vertexai_embeddings.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/embeddings/test_vertexai_embeddings.py:5: in <module>\n    from mem0.embeddings.vertexai import VertexAIEmbedding\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_______________ ERROR collecting tests/llms/test_azure_openai.py _______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_azure_openai.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_azure_openai.py:5: in <module>\n    from mem0.configs.llms.azure import AzureOpenAIConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________ ERROR collecting tests/llms/test_azure_openai_structured.py __________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_azure_openai_structured.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_azure_openai_structured.py:3: in <module>\n    from mem0.llms.azure_openai_structured import SCOPE, AzureOpenAIStructuredLLM\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________________ ERROR collecting tests/llms/test_deepseek.py _________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_deepseek.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_deepseek.py:6: in <module>\n    from mem0.configs.llms.base import BaseLlmConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n__________________ ERROR collecting tests/llms/test_gemini.py __________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_gemini.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_gemini.py:6: in <module>\n    from mem0.configs.llms.base import BaseLlmConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n___________________ ERROR collecting tests/llms/test_groq.py ___________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_groq.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_groq.py:5: in <module>\n    from mem0.configs.llms.base import BaseLlmConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________________ ERROR collecting tests/llms/test_langchain.py _________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_langchain.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_langchain.py:5: in <module>\n    from mem0.configs.llms.base import BaseLlmConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________________ ERROR collecting tests/llms/test_litellm.py __________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_litellm.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_litellm.py:5: in <module>\n    from mem0.configs.llms.base import BaseLlmConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________________ ERROR collecting tests/llms/test_lm_studio.py _________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_lm_studio.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_lm_studio.py:5: in <module>\n    from mem0.configs.llms.lmstudio import LMStudioConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n__________________ ERROR collecting tests/llms/test_ollama.py __________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_ollama.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_ollama.py:5: in <module>\n    from mem0.configs.llms.ollama import OllamaConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n__________________ ERROR collecting tests/llms/test_openai.py __________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_openai.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_openai.py:6: in <module>\n    from mem0.configs.llms.openai import OpenAIConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________________ ERROR collecting tests/llms/test_together.py _________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_together.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_together.py:5: in <module>\n    from mem0.configs.llms.base import BaseLlmConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n___________________ ERROR collecting tests/llms/test_vllm.py ___________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/llms/test_vllm.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/llms/test_vllm.py:5: in <module>\n    from mem0 import AsyncMemory, Memory\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n__________________ ERROR collecting tests/memory/test_kuzu.py __________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/memory/test_kuzu.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/memory/test_kuzu.py:4: in <module>\n    from mem0.memory.kuzu_memory import MemoryGraph\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n__________________ ERROR collecting tests/memory/test_main.py __________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/memory/test_main.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/memory/test_main.py:6: in <module>\n    from mem0.memory.main import AsyncMemory, Memory\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________ ERROR collecting tests/memory/test_neptune_analytics_memory.py ________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/memory/test_neptune_analytics_memory.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/memory/test_neptune_analytics_memory.py:4: in <module>\n    from mem0.graphs.neptune.neptunegraph import MemoryGraph\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_____________ ERROR collecting tests/memory/test_neptune_memory.py _____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/memory/test_neptune_memory.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/memory/test_neptune_memory.py:4: in <module>\n    from mem0.graphs.neptune.neptunedb import MemoryGraph\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________________ ERROR collecting tests/memory/test_storage.py _________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/memory/test_storage.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/memory/test_storage.py:9: in <module>\n    from mem0.memory.storage import SQLiteManager\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_____________________ ERROR collecting tests/test_main.py ______________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/test_main.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/test_main.py:6: in <module>\n    from mem0.configs.base import MemoryConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n____________________ ERROR collecting tests/test_memory.py _____________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/test_memory.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/test_memory.py:5: in <module>\n    from mem0 import Memory\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n______________ ERROR collecting tests/test_memory_integration.py _______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/test_memory_integration.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/test_memory_integration.py:3: in <module>\n    from mem0.memory.main import Memory\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_____________________ ERROR collecting tests/test_proxy.py _____________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/test_proxy.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/test_proxy.py:5: in <module>\n    from mem0 import Memory, MemoryClient\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________ ERROR collecting tests/vector_stores/test_azure_ai_search.py _________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_azure_ai_search.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_azure_ai_search.py:5: in <module>\n    from azure.core.exceptions import HttpResponseError\nE   ModuleNotFoundError: No module named 'azure'\n___________ ERROR collecting tests/vector_stores/test_azure_mysql.py ___________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_azure_mysql.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_azure_mysql.py:5: in <module>\n    from mem0.vector_stores.azure_mysql import AzureMySQL, OutputData\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n______________ ERROR collecting tests/vector_stores/test_baidu.py ______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_baidu.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_baidu.py:4: in <module>\n    from pymochow.exception import ServerError\nE   ModuleNotFoundError: No module named 'pymochow'\n____________ ERROR collecting tests/vector_stores/test_cassandra.py ____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_cassandra.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_cassandra.py:5: in <module>\n    from mem0.vector_stores.cassandra import CassandraDB, OutputData\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_____________ ERROR collecting tests/vector_stores/test_chroma.py ______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_chroma.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_chroma.py:5: in <module>\n    from mem0.vector_stores.chroma import ChromaDB\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n___________ ERROR collecting tests/vector_stores/test_databricks.py ____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_databricks.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_databricks.py:3: in <module>\n    from databricks.sdk.service.vectorsearch import VectorIndexType, QueryVectorIndexResponse, ResultManifest, ResultData, ColumnInfo\nE   ModuleNotFoundError: No module named 'databricks'\n__________ ERROR collecting tests/vector_stores/test_elasticsearch.py __________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_elasticsearch.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_elasticsearch.py:10: in <module>\n    raise ImportError(\"Elasticsearch requires extra dependencies. Install with `pip install elasticsearch`\") from None\nE   ImportError: Elasticsearch requires extra dependencies. Install with `pip install elasticsearch`\n______________ ERROR collecting tests/vector_stores/test_faiss.py ______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_faiss.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_faiss.py:5: in <module>\n    import faiss\nE   ModuleNotFoundError: No module named 'faiss'\n_____ ERROR collecting tests/vector_stores/test_langchain_vector_store.py ______\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_langchain_vector_store.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_langchain_vector_store.py:4: in <module>\n    from langchain_community.vectorstores import VectorStore\nE   ModuleNotFoundError: No module named 'langchain_community'\n_____________ ERROR collecting tests/vector_stores/test_milvus.py ______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_milvus.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_milvus.py:13: in <module>\n    from mem0.vector_stores.milvus import MilvusDB\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_____________ ERROR collecting tests/vector_stores/test_mongodb.py _____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_mongodb.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_mongodb.py:5: in <module>\n    from mem0.vector_stores.mongodb import MongoDB\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n________ ERROR collecting tests/vector_stores/test_neptune_analytics.py ________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_neptune_analytics.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_neptune_analytics.py:8: in <module>\n    from mem0.utils.factory import VectorStoreFactory\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n___________ ERROR collecting tests/vector_stores/test_opensearch.py ____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_opensearch.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_opensearch.py:11: in <module>\n    raise ImportError(\"OpenSearch requires extra dependencies. Install with `pip install opensearch-py`\") from None\nE   ImportError: OpenSearch requires extra dependencies. Install with `pip install opensearch-py`\n____________ ERROR collecting tests/vector_stores/test_pgvector.py _____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_pgvector.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_pgvector.py:7: in <module>\n    from mem0.vector_stores.pgvector import PGVector\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n____________ ERROR collecting tests/vector_stores/test_pinecone.py _____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_pinecone.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_pinecone.py:5: in <module>\n    from mem0.vector_stores.pinecone import PineconeDB\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_____________ ERROR collecting tests/vector_stores/test_qdrant.py ______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_qdrant.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_qdrant.py:5: in <module>\n    from qdrant_client import QdrantClient\nE   ModuleNotFoundError: No module named 'qdrant_client'\n___________ ERROR collecting tests/vector_stores/test_s3_vectors.py ____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_s3_vectors.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_s3_vectors.py:1: in <module>\n    from mem0.configs.vector_stores.s3_vectors import S3VectorsConfig\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n____________ ERROR collecting tests/vector_stores/test_supabase.py _____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_supabase.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_supabase.py:5: in <module>\n    from mem0.configs.vector_stores.supabase import IndexMeasure, IndexMethod\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_________ ERROR collecting tests/vector_stores/test_upstash_vector.py __________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_upstash_vector.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_upstash_vector.py:7: in <module>\n    from mem0.vector_stores.upstash_vector import UpstashVector\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n_____________ ERROR collecting tests/vector_stores/test_valkey.py ______________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_valkey.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_valkey.py:8: in <module>\n    from valkey.exceptions import ResponseError\nE   ModuleNotFoundError: No module named 'valkey'\n_____ ERROR collecting tests/vector_stores/test_vertex_ai_vector_search.py _____\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_vertex_ai_vector_search.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_vertex_ai_vector_search.py:4: in <module>\n    from google.api_core import exceptions\nE   ModuleNotFoundError: No module named 'google.api_core'\n____________ ERROR collecting tests/vector_stores/test_weaviate.py _____________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/vector_stores/test_weaviate.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/vector_stores/test_weaviate.py:8: in <module>\n    import weaviate\nE   ModuleNotFoundError: No module named 'weaviate'\n=========================== short test summary info ============================\nERROR tests/configs/test_prompts.py\nERROR tests/embeddings/test_azure_openai_embeddings.py\nERROR tests/embeddings/test_fastembed_embeddings.py\nERROR tests/embeddings/test_gemini_emeddings.py\nERROR tests/embeddings/test_huggingface_embeddings.py\nERROR tests/embeddings/test_lm_studio_embeddings.py\nERROR tests/embeddings/test_ollama_embeddings.py\nERROR tests/embeddings/test_openai_embeddings.py\nERROR tests/embeddings/test_vertexai_embeddings.py\nERROR tests/llms/test_azure_openai.py\nERROR tests/llms/test_azure_openai_structured.py\nERROR tests/llms/test_deepseek.py\nERROR tests/llms/test_gemini.py\nERROR tests/llms/test_groq.py\nERROR tests/llms/test_langchain.py\nERROR tests/llms/test_litellm.py\nERROR tests/llms/test_lm_studio.py\nERROR tests/llms/test_ollama.py\nERROR tests/llms/test_openai.py\nERROR tests/llms/test_together.py\nERROR tests/llms/test_vllm.py\nERROR tests/memory/test_kuzu.py\nERROR tests/memory/test_main.py\nERROR tests/memory/test_neptune_analytics_memory.py\nERROR tests/memory/test_neptune_memory.py\nERROR tests/memory/test_storage.py\nERROR tests/test_main.py\nERROR tests/test_memory.py\nERROR tests/test_memory_integration.py\nERROR tests/test_proxy.py\nERROR tests/vector_stores/test_azure_ai_search.py\nERROR tests/vector_stores/test_azure_mysql.py\nERROR tests/vector_stores/test_baidu.py\nERROR tests/vector_stores/test_cassandra.py\nERROR tests/vector_stores/test_chroma.py\nERROR tests/vector_stores/test_databricks.py\nERROR tests/vector_stores/test_elasticsearch.py\nERROR tests/vector_stores/test_faiss.py\nERROR tests/vector_stores/test_langchain_vector_store.py\nERROR tests/vector_stores/test_milvus.py\nERROR tests/vector_stores/test_mongodb.py\nERROR tests/vector_stores/test_neptune_analytics.py\nERROR tests/vector_stores/test_opensearch.py\nERROR tests/vector_stores/test_pgvector.py\nERROR tests/vector_stores/test_pinecone.py\nERROR tests/vector_stores/test_qdrant.py\nERROR tests/vector_stores/test_s3_vectors.py\nERROR tests/vector_stores/test_supabase.py\nERROR tests/vector_stores/test_upstash_vector.py\nERROR tests/vector_stores/test_valkey.py\nERROR tests/vector_stores/test_vertex_ai_vector_search.py\nERROR tests/vector_stores/test_weaviate.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 52 errors during collection !!!!!!!!!!!!!!!!!!!\n============================== 52 errors in 3.88s ==============================\nmake: *** [test] Error 2\n","exit_code":2,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_57","type":"reasoning","text":"**Analyzing missing package metadata cause**"}}
{"type":"item.started","item":{"id":"item_58","type":"command_execution","command":"/bin/zsh -lc \"rg -n \\\"\\\\[tool\\\\.hatch\\\\.envs|skip-install|template\\\" pyproject.toml\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_58","type":"command_execution","command":"/bin/zsh -lc \"rg -n \\\"\\\\[tool\\\\.hatch\\\\.envs|skip-install|template\\\" pyproject.toml\"","aggregated_output":"108:[tool.hatch.envs.dev_py_3_9]\n118:[tool.hatch.envs.dev_py_3_10]\n128:[tool.hatch.envs.dev_py_3_11]\n138:[tool.hatch.envs.dev_py_3_12]\n148:[tool.hatch.envs.default.scripts]\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_59","type":"reasoning","text":"**Investigating missing package metadata issue**"}}
{"type":"item.started","item":{"id":"item_60","type":"command_execution","command":"/bin/zsh -lc \"hatch run python -c \\\"import importlib.metadata as m; print('ok', m.version('mem0ai'))\\\"\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_60","type":"command_execution","command":"/bin/zsh -lc \"hatch run python -c \\\"import importlib.metadata as m; print('ok', m.version('mem0ai'))\\\"\"","aggregated_output":"ok 1.0.4\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_61","type":"reasoning","text":"**Investigating test environment inconsistency**"}}
{"type":"item.completed","item":{"id":"item_62","type":"agent_message","text":"`make test` failed due environment/dependency issues, so Iâ€™m reproducing with a narrow test and inspecting the hatch Python environment to determine whether this is a pre-existing setup issue versus a code regression from Forge changes."}}
{"type":"item.started","item":{"id":"item_63","type":"command_execution","command":"/bin/zsh -lc 'hatch run pytest tests/configs/test_prompts.py -q'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_63","type":"command_execution","command":"/bin/zsh -lc 'hatch run pytest tests/configs/test_prompts.py -q'","aggregated_output":"\n==================================== ERRORS ====================================\n________________ ERROR collecting tests/configs/test_prompts.py ________________\nImportError while importing test module '/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/tests/configs/test_prompts.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:563: in from_name\n    return next(cls.discover(name=name))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   StopIteration\n\nDuring handling of the above exception, another exception occurred:\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/configs/test_prompts.py:1: in <module>\n    from mem0.configs import prompts\nmem0/__init__.py:3: in <module>\n    __version__ = importlib.metadata.version(\"mem0ai\")\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:1009: in version\n    return distribution(distribution_name).version\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:982: in distribution\n    return Distribution.from_name(distribution_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/metadata/__init__.py:565: in from_name\n    raise PackageNotFoundError(name)\nE   importlib.metadata.PackageNotFoundError: No package metadata was found for mem0ai\n=========================== short test summary info ============================\nERROR tests/configs/test_prompts.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.11s\n","exit_code":2,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_64","type":"reasoning","text":"**Inspecting Python and Pytest in Hatch Environment**"}}
{"type":"item.started","item":{"id":"item_65","type":"command_execution","command":"/bin/zsh -lc \"hatch run sh -c 'which python; python -V; which pytest; python -c \\\"import sys,importlib.metadata as m; print(sys.executable); print(m.version(\\\\\\\"mem0ai\\\\\\\"))\\\"'\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_65","type":"command_execution","command":"/bin/zsh -lc \"hatch run sh -c 'which python; python -V; which pytest; python -c \\\"import sys,importlib.metadata as m; print(sys.executable); print(m.version(\\\\\\\"mem0ai\\\\\\\"))\\\"'\"","aggregated_output":"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/bin/python\nPython 3.14.2\n/opt/homebrew/bin/pytest\n/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/bin/python\n1.0.4\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_66","type":"reasoning","text":"**Confirming hatch env pip location**"}}
{"type":"item.started","item":{"id":"item_67","type":"command_execution","command":"/bin/zsh -lc 'hatch run which pip && hatch run pip -V'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_67","type":"command_execution","command":"/bin/zsh -lc 'hatch run which pip && hatch run pip -V'","aggregated_output":"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/bin/pip\npip 25.3 from /Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages/pip (python 3.14)\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_68","type":"reasoning","text":"**Planning test environment setup**"}}
{"type":"item.completed","item":{"id":"item_69","type":"agent_message","text":"I identified the failure cause: `hatch run test` is currently picking global `pytest` because `pytest` isnâ€™t installed in the default hatch env, so tests run outside the project env. Iâ€™ll now mirror CI setup inside the hatch env (`pip install -e \".[test,graph,vector_stores,llms,extras]\"` + `ruff`) and rerun validation."}}
{"type":"item.started","item":{"id":"item_70","type":"command_execution","command":"/bin/zsh -lc 'hatch run pip install --upgrade pip && hatch run pip install -e \".[test,graph,vector_stores,llms,extras]\" && hatch run pip install ruff'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_70","type":"command_execution","command":"/bin/zsh -lc 'hatch run pip install --upgrade pip && hatch run pip install -e \".[test,graph,vector_stores,llms,extras]\" && hatch run pip install ruff'","aggregated_output":"Requirement already satisfied: pip in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (25.3)\nCollecting pip\n  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\nDownloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.8/1.8 MB 22.5 MB/s  0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 25.3\n    Uninstalling pip-25.3:\n      Successfully uninstalled pip-25.3\nSuccessfully installed pip-26.0.1\nObtaining file:///Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Checking if build backend supports build_editable: started\n  Checking if build backend supports build_editable: finished with status 'done'\n  Getting requirements to build editable: started\n  Getting requirements to build editable: finished with status 'done'\n  Installing backend dependencies: started\n  Installing backend dependencies: finished with status 'done'\n  Preparing editable metadata (pyproject.toml): started\n  Preparing editable metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: openai>=1.90.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (from mem0ai==1.0.4) (2.24.0)\nRequirement already satisfied: posthog>=3.5.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (from mem0ai==1.0.4) (7.9.3)\nRequirement already satisfied: protobuf<6.0.0,>=5.29.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (from mem0ai==1.0.4) (5.29.6)\nRequirement already satisfied: pydantic>=2.7.3 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (from mem0ai==1.0.4) (2.12.5)\nRequirement already satisfied: pytz>=2024.1 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (from mem0ai==1.0.4) (2025.2)\nRequirement already satisfied: qdrant-client>=1.9.1 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (from mem0ai==1.0.4) (1.17.0)\nRequirement already satisfied: sqlalchemy>=2.0.31 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages (from mem0ai==1.0.4) (2.0.47)\nCollecting boto3>=1.34.0 (from mem0ai==1.0.4)\n  Downloading boto3-1.42.56-py3-none-any.whl.metadata (6.7 kB)\nCollecting elasticsearch<9.0.0,>=8.0.0 (from mem0ai==1.0.4)\n  Downloading elasticsearch-8.19.3-py3-none-any.whl.metadata (9.1 kB)\nCollecting fastembed>=0.3.1 (from mem0ai==1.0.4)\n  Downloading fastembed-0.7.4-py3-none-any.whl.metadata (10 kB)\nCollecting langchain-community>=0.0.0 (from mem0ai==1.0.4)\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting opensearch-py>=2.0.0 (from mem0ai==1.0.4)\n  Downloading opensearch_py-3.1.0-py3-none-any.whl.metadata (7.2 kB)\nCollecting sentence-transformers>=5.0.0 (from mem0ai==1.0.4)\n  Downloading sentence_transformers-5.2.3-py3-none-any.whl.metadata (16 kB)\nCollecting kuzu>=0.11.0 (from mem0ai==1.0.4)\n  Downloading kuzu-0.11.3.tar.gz (19.4 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.4/19.4 MB 16.8 MB/s  0:00:01\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nCollecting langchain-aws>=0.2.23 (from mem0ai==1.0.4)\n  Downloading langchain_aws-1.3.0-py3-none-any.whl.metadata (2.0 kB)\nCollecting langchain-memgraph>=0.1.0 (from mem0ai==1.0.4)\n  Downloading langchain_memgraph-0.1.12-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain-neo4j>=0.4.0 (from mem0ai==1.0.4)\n  Downloading langchain_neo4j-0.8.0-py3-none-any.whl.metadata (5.9 kB)\nCollecting neo4j>=5.23.1 (from mem0ai==1.0.4)\n  Downloading neo4j-6.1.0-py3-none-any.whl.metadata (5.3 kB)\nCollecting rank-bm25>=0.2.2 (from mem0ai==1.0.4)\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting google-genai>=1.0.0 (from mem0ai==1.0.4)\n  Downloading google_genai-1.64.0-py3-none-any.whl.metadata (53 kB)\nCollecting google-generativeai>=0.3.0 (from mem0ai==1.0.4)\n  Downloading google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\nCollecting groq>=0.3.0 (from mem0ai==1.0.4)\n  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\nCollecting litellm>=1.74.0 (from mem0ai==1.0.4)\n  Downloading litellm-1.81.15-py3-none-any.whl.metadata (30 kB)\nCollecting ollama>=0.1.0 (from mem0ai==1.0.4)\n  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\nCollecting together>=0.2.10 (from mem0ai==1.0.4)\n  Downloading together-2.2.0-py3-none-any.whl.metadata (23 kB)\nCollecting vertexai>=0.1.0 (from mem0ai==1.0.4)\n  Downloading vertexai-1.71.1-py3-none-any.whl.metadata (10 kB)\nCollecting pytest-asyncio>=0.23.7 (from mem0ai==1.0.4)\n  Downloading pytest_asyncio-1.3.0-py3-none-any.whl.metadata (4.1 kB)\nCollecting pytest-mock>=3.14.0 (from mem0ai==1.0.4)\n  Downloading pytest_mock-3.15.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting pytest>=8.2.2 (from mem0ai==1.0.4)\n  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\nCollecting azure-identity>=1.24.0 (from mem0ai==1.0.4)\n  Downloading azure_identity-1.25.2-py3-none-any.whl.metadata (90 kB)\nCollecting azure-search-documents>=11.4.0b8 (from mem0ai==1.0.4)\n  Downloading azure_search_documents-11.7.0b2-py3-none-any.whl.metadata (22 kB)\nCollecting cassandra-driver>=3.29.0 (from mem0ai==1.0.4)\n  Downloading cassandra_driver-3.29.3.tar.gz (294 kB)\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'error'\n  error: subprocess-exited-with-error\n  \n  Ã— Getting requirements to build wheel did not run successfully.\n  â”‚ exit code: 1\n  â•°â”€> [43 lines of output]\n      Downloading https://pypi.python.org/packages/source/s/setuptools/setuptools-0.9.6.tar.gz\n      Extracting in /Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/tmpjz0o23kk\n      Traceback (most recent call last):\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-install-3za8rgc5/cassandra-driver_68aeeb38bce04afca0d5c53342eba13c/ez_setup.py\", line 115, in use_setuptools\n          import pkg_resources\n      ModuleNotFoundError: No module named 'pkg_resources'\n      \n      During handling of the above exception, another exception occurred:\n      \n      Traceback (most recent call last):\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n          main()\n          ~~~~^^\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n          json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n                                   ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.14/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 143, in get_requires_for_build_wheel\n          return hook(config_settings)\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-build-env-256cqeh6/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\", line 333, in get_requires_for_build_wheel\n          return self._get_build_requires(config_settings, requirements=[])\n                 ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-build-env-256cqeh6/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\", line 301, in _get_build_requires\n          self.run_setup()\n          ~~~~~~~~~~~~~~^^\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-build-env-256cqeh6/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\", line 520, in run_setup\n          super().run_setup(setup_script=setup_script)\n          ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-build-env-256cqeh6/overlay/lib/python3.14/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n          exec(code, locals())\n          ~~~~^^^^^^^^^^^^^^^^\n        File \"<string>\", line 20, in <module>\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-install-3za8rgc5/cassandra-driver_68aeeb38bce04afca0d5c53342eba13c/ez_setup.py\", line 117, in use_setuptools\n          return _do_download(version, download_base, to_dir, download_delay)\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-install-3za8rgc5/cassandra-driver_68aeeb38bce04afca0d5c53342eba13c/ez_setup.py\", line 102, in _do_download\n          _build_egg(egg, tarball, to_dir)\n          ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-install-3za8rgc5/cassandra-driver_68aeeb38bce04afca0d5c53342eba13c/ez_setup.py\", line 75, in _build_egg\n          _extractall(tar)\n          ~~~~~~~~~~~^^^^^\n        File \"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-install-3za8rgc5/cassandra-driver_68aeeb38bce04afca0d5c53342eba13c/ez_setup.py\", line 203, in _extractall\n          self.chown(tarinfo, dirpath)\n          ~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n      TypeError: TarFile.chown() missing 1 required positional argument: 'numeric_owner'\n      [end of output]\n  \n  note: This error originates from a subprocess, and is likely not a problem with pip.\nERROR: Failed to build 'cassandra-driver' when getting requirements to build wheel\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_71","type":"reasoning","text":"**Identifying Python version incompatibility**"}}
{"type":"item.started","item":{"id":"item_72","type":"command_execution","command":"/bin/zsh -lc 'hatch run dev_py_3_11:python -V && hatch run dev_py_3_11:which python && hatch run dev_py_3_11:which pytest'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_73","type":"reasoning","text":"**Noting long install delay**"}}
{"type":"item.completed","item":{"id":"item_74","type":"agent_message","text":"The default hatch env is Python 3.14, which is incompatible with part of this dependency set. Iâ€™m switching validation to the repoâ€™s configured `dev_py_3_11` hatch environment (aligned with CI matrix) and checking whether it can run the required commands successfully."}}
{"type":"item.completed","item":{"id":"item_75","type":"reasoning","text":"**Monitoring package build progress**"}}
{"type":"item.completed","item":{"id":"item_72","type":"command_execution","command":"/bin/zsh -lc 'hatch run dev_py_3_11:python -V && hatch run dev_py_3_11:which python && hatch run dev_py_3_11:which pytest'","aggregated_output":"Creating environment: dev_py_3_11\nInstalling project in development mode\nWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /cli/__init__.py:239 in main                                                 â”‚\nâ”‚                                                                              â”‚\nâ”‚   236                                                                        â”‚\nâ”‚   237 def main():  # no cov                                                  â”‚\nâ”‚   238 â”‚   try:                                                               â”‚\nâ”‚ â± 239 â”‚   â”‚   hatch(prog_name=\"hatch\", windows_expand_args=False)            â”‚\nâ”‚   240 â”‚   except Exception:  # noqa: BLE001                                  â”‚\nâ”‚   241 â”‚   â”‚   import sys                                                     â”‚\nâ”‚   242                                                                        â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /core.py:1485 in __call__                                                    â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /core.py:1406 in main                                                        â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /core.py:1873 in invoke                                                      â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /core.py:1269 in invoke                                                      â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /core.py:824 in invoke                                                       â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /decorators.py:34 in new_func                                                â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /cli/run/__init__.py:156 in run                                              â”‚\nâ”‚                                                                              â”‚\nâ”‚   153 â”‚   elif not env_name:                                                 â”‚\nâ”‚   154 â”‚   â”‚   env_name = \"system\"                                            â”‚\nâ”‚   155 â”‚                                                                      â”‚\nâ”‚ â± 156 â”‚   ctx.invoke(                                                        â”‚\nâ”‚   157 â”‚   â”‚   run_command,                                                   â”‚\nâ”‚   158 â”‚   â”‚   args=[command, *final_args],                                   â”‚\nâ”‚   159 â”‚   â”‚   env_names=[env_name],                                          â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /core.py:824 in invoke                                                       â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/click â”‚\nâ”‚ /decorators.py:46 in new_func                                                â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /cli/env/run.py:137 in run                                                   â”‚\nâ”‚                                                                              â”‚\nâ”‚   134 â”‚   elif not matrix_selected and (included_variables or excluded_varia â”‚\nâ”‚   135 â”‚   â”‚   app.abort(f\"Variable selection is unsupported for non-matrix e â”‚\nâ”‚   136 â”‚                                                                      â”‚\nâ”‚ â± 137 â”‚   for context in app.runner_context(                                 â”‚\nâ”‚   138 â”‚   â”‚   environments,                                                  â”‚\nâ”‚   139 â”‚   â”‚   ignore_compat=ignore_compat or matrix_selected,                â”‚\nâ”‚   140 â”‚   â”‚   display_header=matrix_selected,                                â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /cli/application.py:121 in runner_context                                    â”‚\nâ”‚                                                                              â”‚\nâ”‚   118 â”‚   â”‚   â”‚   â”‚   context = ExecutionContext(environment)                â”‚\nâ”‚   119 â”‚   â”‚   â”‚   â”‚   yield context                                          â”‚\nâ”‚   120 â”‚   â”‚   â”‚   â”‚                                                          â”‚\nâ”‚ â± 121 â”‚   â”‚   â”‚   â”‚   self.prepare_environment(environment, keep_env=keep_en â”‚\nâ”‚   122 â”‚   â”‚   â”‚   â”‚   self.execute_context(context)                          â”‚\nâ”‚   123 â”‚   â”‚                                                                  â”‚\nâ”‚   124 â”‚   â”‚   if incompatible:                                               â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /cli/application.py:51 in prepare_environment                                â”‚\nâ”‚                                                                              â”‚\nâ”‚    48 â”‚   â”‚   return self.project.get_environment(env_name)                  â”‚\nâ”‚    49 â”‚                                                                      â”‚\nâ”‚    50 â”‚   def prepare_environment(self, environment: EnvironmentInterface, * â”‚\nâ”‚ â±  51 â”‚   â”‚   self.project.prepare_environment(environment, keep_env=keep_en â”‚\nâ”‚    52 â”‚                                                                      â”‚\nâ”‚    53 â”‚   def run_shell_commands(self, context: ExecutionContext) -> None:   â”‚\nâ”‚    54 â”‚   â”‚   with context.env.command_context():                            â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /project/core.py:236 in prepare_environment                                  â”‚\nâ”‚                                                                              â”‚\nâ”‚   233 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   )                                          â”‚\nâ”‚   234 â”‚   â”‚                                                                  â”‚\nâ”‚   235 â”‚   â”‚   with environment.app_status_dependency_state_check():          â”‚\nâ”‚ â± 236 â”‚   â”‚   â”‚   new_dep_hash = environment.dependency_hash()               â”‚\nâ”‚   237 â”‚   â”‚                                                                  â”‚\nâ”‚   238 â”‚   â”‚   current_dep_hash = self.env_metadata.dependency_hash(environme â”‚\nâ”‚   239 â”‚   â”‚   if new_dep_hash != current_dep_hash:                           â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /env/plugin/interface.py:781 in dependency_hash                              â”‚\nâ”‚                                                                              â”‚\nâ”‚    778 â”‚   â”‚   \"\"\"                                                           â”‚\nâ”‚    779 â”‚   â”‚   from hatch.utils.dep import hash_dependencies                 â”‚\nâ”‚    780 â”‚   â”‚                                                                 â”‚\nâ”‚ â±  781 â”‚   â”‚   return hash_dependencies(self.all_dependencies_complex)       â”‚\nâ”‚    782 â”‚                                                                     â”‚\nâ”‚    783 â”‚   @contextmanager                                                   â”‚\nâ”‚    784 â”‚   def app_status_creation(self):                                    â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/python@3.14/3.14.2_1/Frameworks/Python.framework/Versio â”‚\nâ”‚ ns/3.14/lib/python3.14/functools.py:1126 in __get__                          â”‚\nâ”‚                                                                              â”‚\nâ”‚   1123 â”‚   â”‚   â”‚   raise TypeError(msg) from None                            â”‚\nâ”‚   1124 â”‚   â”‚   val = cache.get(self.attrname, _NOT_FOUND)                    â”‚\nâ”‚   1125 â”‚   â”‚   if val is _NOT_FOUND:                                         â”‚\nâ”‚ â± 1126 â”‚   â”‚   â”‚   val = self.func(instance)                                 â”‚\nâ”‚   1127 â”‚   â”‚   â”‚   try:                                                      â”‚\nâ”‚   1128 â”‚   â”‚   â”‚   â”‚   cache[self.attrname] = val                            â”‚\nâ”‚   1129 â”‚   â”‚   â”‚   except TypeError:                                         â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /env/plugin/interface.py:421 in all_dependencies_complex                     â”‚\nâ”‚                                                                              â”‚\nâ”‚    418 â”‚   â”‚   workspace_names = {dep.name.lower() for dep in local_deps}    â”‚\nâ”‚    419 â”‚   â”‚                                                                 â”‚\nâ”‚    420 â”‚   â”‚   filtered_deps: list[Dependency] = []                          â”‚\nâ”‚ â±  421 â”‚   â”‚   for dep in self.dependencies_complex:                         â”‚\nâ”‚    422 â”‚   â”‚   â”‚   dep_obj = dep if isinstance(dep, Dependency) else Depende â”‚\nâ”‚    423 â”‚   â”‚   â”‚                                                             â”‚\nâ”‚    424 â”‚   â”‚   â”‚   if dep_obj.name.lower() in workspace_names and dep_obj.ex â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/python@3.14/3.14.2_1/Frameworks/Python.framework/Versio â”‚\nâ”‚ ns/3.14/lib/python3.14/functools.py:1126 in __get__                          â”‚\nâ”‚                                                                              â”‚\nâ”‚   1123 â”‚   â”‚   â”‚   raise TypeError(msg) from None                            â”‚\nâ”‚   1124 â”‚   â”‚   val = cache.get(self.attrname, _NOT_FOUND)                    â”‚\nâ”‚   1125 â”‚   â”‚   if val is _NOT_FOUND:                                         â”‚\nâ”‚ â± 1126 â”‚   â”‚   â”‚   val = self.func(instance)                                 â”‚\nâ”‚   1127 â”‚   â”‚   â”‚   try:                                                      â”‚\nâ”‚   1128 â”‚   â”‚   â”‚   â”‚   cache[self.attrname] = val                            â”‚\nâ”‚   1129 â”‚   â”‚   â”‚   except TypeError:                                         â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /env/plugin/interface.py:399 in dependencies_complex                         â”‚\nâ”‚                                                                              â”‚\nâ”‚    396 â”‚   â”‚   # Ensure these are checked last to speed up initial environme â”‚\nâ”‚    397 â”‚   â”‚   # they will already be installed along with the project       â”‚\nâ”‚    398 â”‚   â”‚   if self.dev_mode or self.features or self.dependency_groups:  â”‚\nâ”‚ â±  399 â”‚   â”‚   â”‚   all_dependencies_complex.extend(self.project_dependencies â”‚\nâ”‚    400 â”‚   â”‚                                                                 â”‚\nâ”‚    401 â”‚   â”‚   return all_dependencies_complex                               â”‚\nâ”‚    402                                                                       â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/python@3.14/3.14.2_1/Frameworks/Python.framework/Versio â”‚\nâ”‚ ns/3.14/lib/python3.14/functools.py:1126 in __get__                          â”‚\nâ”‚                                                                              â”‚\nâ”‚   1123 â”‚   â”‚   â”‚   raise TypeError(msg) from None                            â”‚\nâ”‚   1124 â”‚   â”‚   val = cache.get(self.attrname, _NOT_FOUND)                    â”‚\nâ”‚   1125 â”‚   â”‚   if val is _NOT_FOUND:                                         â”‚\nâ”‚ â± 1126 â”‚   â”‚   â”‚   val = self.func(instance)                                 â”‚\nâ”‚   1127 â”‚   â”‚   â”‚   try:                                                      â”‚\nâ”‚   1128 â”‚   â”‚   â”‚   â”‚   cache[self.attrname] = val                            â”‚\nâ”‚   1129 â”‚   â”‚   â”‚   except TypeError:                                         â”‚\nâ”‚                                                                              â”‚\nâ”‚ /opt/homebrew/Cellar/hatch/1.16.3/libexec/lib/python3.14/site-packages/hatch â”‚\nâ”‚ /env/plugin/interface.py:318 in project_dependencies_complex                 â”‚\nâ”‚                                                                              â”‚\nâ”‚    315 â”‚   â”‚   â”‚   â”‚   â”‚   f\"Feature `{feature}` of field `tool.hatch.envs.{ â”‚\nâ”‚    316 â”‚   â”‚   â”‚   â”‚   â”‚   f\"defined in the dynamic field `project.optional- â”‚\nâ”‚    317 â”‚   â”‚   â”‚   â”‚   )                                                     â”‚\nâ”‚ â±  318 â”‚   â”‚   â”‚   â”‚   raise ValueError(message)                             â”‚\nâ”‚    319 â”‚   â”‚   â”‚                                                             â”‚\nâ”‚    320 â”‚   â”‚   â”‚   all_dependencies_complex.extend([                         â”‚\nâ”‚    321 â”‚   â”‚   â”‚   â”‚   dep if isinstance(dep, Dependency) else Dependency(st â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\nValueError: Feature `vector-stores` of field \n`tool.hatch.envs.dev_py_3_11.features` is not defined in the dynamic field \n`project.optional-dependencies`\n","exit_code":1,"status":"failed"}}
{"type":"item.completed","item":{"id":"item_76","type":"reasoning","text":"**Resolving hatch env Python version**"}}
{"type":"item.started","item":{"id":"item_77","type":"command_execution","command":"/bin/zsh -lc 'which python3.11 && python3.11 -V'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_77","type":"command_execution","command":"/bin/zsh -lc 'which python3.11 && python3.11 -V'","aggregated_output":"/opt/homebrew/bin/python3.11\nPython 3.11.14\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_78","type":"reasoning","text":"**Planning local environment removal**"}}
{"type":"item.started","item":{"id":"item_79","type":"command_execution","command":"/bin/zsh -lc \"env | rg '\"'^HATCH'\"' || true\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_79","type":"command_execution","command":"/bin/zsh -lc \"env | rg '\"'^HATCH'\"' || true\"","aggregated_output":"HATCH_CACHE_DIR=/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/cache/hatch\nHATCH_DATA_DIR=/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_80","type":"reasoning","text":"**Planning command execution approach**"}}
{"type":"item.completed","item":{"id":"item_81","type":"agent_message","text":"I found a better path that still follows repo commands: force hatchâ€™s default env to Python 3.11 (CI-compatible), then rerun install + `make lint`/`make test`. Iâ€™m recreating the hatch env now with `HATCH_PYTHON=3.11`."}}
{"type":"item.started","item":{"id":"item_82","type":"command_execution","command":"/bin/zsh -lc 'hatch env remove default || true\nHATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run python -V\nHATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run which python\nHATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run which pytest || true'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_82","type":"command_execution","command":"/bin/zsh -lc 'hatch env remove default || true\nHATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run python -V\nHATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run which python\nHATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run which pytest || true'","aggregated_output":"Removing environment: default\nCreating environment: default\nInstalling project in development mode\nChecking dependencies\nPython 3.11.14\n/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/bin/python\n/opt/homebrew/bin/pytest\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_83","type":"reasoning","text":"**Installing extras for testing**"}}
{"type":"item.started","item":{"id":"item_84","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pip install --upgrade pip && HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pip install -e \".[test,graph,vector_stores,llms,extras]\" && HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pip install ruff'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_85","type":"reasoning","text":"**Monitoring command progress**"}}
{"type":"item.completed","item":{"id":"item_84","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pip install --upgrade pip && HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pip install -e \".[test,graph,vector_stores,llms,extras]\" && HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pip install ruff'","aggregated_output":"Requirement already satisfied: pip in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (25.3)\nCollecting pip\n  Using cached pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\nUsing cached pip-26.0.1-py3-none-any.whl (1.8 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 25.3\n    Uninstalling pip-25.3:\n      Successfully uninstalled pip-25.3\nSuccessfully installed pip-26.0.1\nObtaining file:///Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Checking if build backend supports build_editable: started\n  Checking if build backend supports build_editable: finished with status 'done'\n  Getting requirements to build editable: started\n  Getting requirements to build editable: finished with status 'done'\n  Installing backend dependencies: started\n  Installing backend dependencies: finished with status 'done'\n  Preparing editable metadata (pyproject.toml): started\n  Preparing editable metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: openai>=1.90.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from mem0ai==1.0.4) (2.24.0)\nRequirement already satisfied: posthog>=3.5.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from mem0ai==1.0.4) (7.9.3)\nRequirement already satisfied: protobuf<6.0.0,>=5.29.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from mem0ai==1.0.4) (5.29.6)\nRequirement already satisfied: pydantic>=2.7.3 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from mem0ai==1.0.4) (2.12.5)\nRequirement already satisfied: pytz>=2024.1 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from mem0ai==1.0.4) (2025.2)\nRequirement already satisfied: qdrant-client>=1.9.1 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from mem0ai==1.0.4) (1.17.0)\nRequirement already satisfied: sqlalchemy>=2.0.31 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from mem0ai==1.0.4) (2.0.47)\nCollecting boto3>=1.34.0 (from mem0ai==1.0.4)\n  Using cached boto3-1.42.56-py3-none-any.whl.metadata (6.7 kB)\nCollecting elasticsearch<9.0.0,>=8.0.0 (from mem0ai==1.0.4)\n  Using cached elasticsearch-8.19.3-py3-none-any.whl.metadata (9.1 kB)\nCollecting fastembed>=0.3.1 (from mem0ai==1.0.4)\n  Using cached fastembed-0.7.4-py3-none-any.whl.metadata (10 kB)\nCollecting langchain-community>=0.0.0 (from mem0ai==1.0.4)\n  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting opensearch-py>=2.0.0 (from mem0ai==1.0.4)\n  Using cached opensearch_py-3.1.0-py3-none-any.whl.metadata (7.2 kB)\nCollecting sentence-transformers>=5.0.0 (from mem0ai==1.0.4)\n  Using cached sentence_transformers-5.2.3-py3-none-any.whl.metadata (16 kB)\nCollecting kuzu>=0.11.0 (from mem0ai==1.0.4)\n  Using cached kuzu-0.11.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\nCollecting langchain-aws>=0.2.23 (from mem0ai==1.0.4)\n  Using cached langchain_aws-1.3.0-py3-none-any.whl.metadata (2.0 kB)\nCollecting langchain-memgraph>=0.1.0 (from mem0ai==1.0.4)\n  Using cached langchain_memgraph-0.1.12-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain-neo4j>=0.4.0 (from mem0ai==1.0.4)\n  Using cached langchain_neo4j-0.8.0-py3-none-any.whl.metadata (5.9 kB)\nCollecting neo4j>=5.23.1 (from mem0ai==1.0.4)\n  Using cached neo4j-6.1.0-py3-none-any.whl.metadata (5.3 kB)\nCollecting rank-bm25>=0.2.2 (from mem0ai==1.0.4)\n  Using cached rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting google-genai>=1.0.0 (from mem0ai==1.0.4)\n  Using cached google_genai-1.64.0-py3-none-any.whl.metadata (53 kB)\nCollecting google-generativeai>=0.3.0 (from mem0ai==1.0.4)\n  Using cached google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\nCollecting groq>=0.3.0 (from mem0ai==1.0.4)\n  Using cached groq-1.0.0-py3-none-any.whl.metadata (16 kB)\nCollecting litellm>=1.74.0 (from mem0ai==1.0.4)\n  Using cached litellm-1.81.15-py3-none-any.whl.metadata (30 kB)\nCollecting ollama>=0.1.0 (from mem0ai==1.0.4)\n  Using cached ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\nCollecting together>=0.2.10 (from mem0ai==1.0.4)\n  Using cached together-2.2.0-py3-none-any.whl.metadata (23 kB)\nCollecting vertexai>=0.1.0 (from mem0ai==1.0.4)\n  Using cached vertexai-1.71.1-py3-none-any.whl.metadata (10 kB)\nCollecting pytest-asyncio>=0.23.7 (from mem0ai==1.0.4)\n  Using cached pytest_asyncio-1.3.0-py3-none-any.whl.metadata (4.1 kB)\nCollecting pytest-mock>=3.14.0 (from mem0ai==1.0.4)\n  Using cached pytest_mock-3.15.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting pytest>=8.2.2 (from mem0ai==1.0.4)\n  Using cached pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\nCollecting azure-identity>=1.24.0 (from mem0ai==1.0.4)\n  Using cached azure_identity-1.25.2-py3-none-any.whl.metadata (90 kB)\nCollecting azure-search-documents>=11.4.0b8 (from mem0ai==1.0.4)\n  Using cached azure_search_documents-11.7.0b2-py3-none-any.whl.metadata (22 kB)\nCollecting cassandra-driver>=3.29.0 (from mem0ai==1.0.4)\n  Using cached cassandra_driver-3.29.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.9 kB)\nCollecting chromadb>=0.4.24 (from mem0ai==1.0.4)\n  Using cached chromadb-1.5.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\nCollecting databricks-sdk>=0.63.0 (from mem0ai==1.0.4)\n  Using cached databricks_sdk-0.92.0-py3-none-any.whl.metadata (40 kB)\nCollecting dbutils>=3.0.3 (from mem0ai==1.0.4)\n  Using cached dbutils-3.1.2-py3-none-any.whl.metadata (2.4 kB)\nCollecting faiss-cpu>=1.7.4 (from mem0ai==1.0.4)\n  Using cached faiss_cpu-1.13.2-cp310-abi3-macosx_14_0_arm64.whl.metadata (7.6 kB)\nCollecting pinecone-text>=0.10.0 (from mem0ai==1.0.4)\n  Using cached pinecone_text-0.11.0-py3-none-any.whl.metadata (10 kB)\nCollecting pinecone<=7.3.0 (from mem0ai==1.0.4)\n  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\nCollecting psycopg-pool<4.0.0,>=3.2.6 (from mem0ai==1.0.4)\n  Using cached psycopg_pool-3.3.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting psycopg>=3.2.8 (from mem0ai==1.0.4)\n  Using cached psycopg-3.3.3-py3-none-any.whl.metadata (4.3 kB)\nCollecting pymilvus<2.6.0,>=2.4.0 (from mem0ai==1.0.4)\n  Using cached pymilvus-2.5.18-py3-none-any.whl.metadata (6.2 kB)\nCollecting pymochow>=2.2.9 (from mem0ai==1.0.4)\n  Using cached pymochow-2.3.6-py3-none-any.whl.metadata (311 bytes)\nCollecting pymongo>=4.13.2 (from mem0ai==1.0.4)\n  Using cached pymongo-4.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (10.0 kB)\nCollecting pymysql>=1.1.0 (from mem0ai==1.0.4)\n  Using cached pymysql-1.1.2-py3-none-any.whl.metadata (4.3 kB)\nCollecting redis<6.0.0,>=5.0.0 (from mem0ai==1.0.4)\n  Using cached redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\nCollecting redisvl<1.0.0,>=0.1.0 (from mem0ai==1.0.4)\n  Using cached redisvl-0.14.0-py3-none-any.whl.metadata (19 kB)\nCollecting upstash-vector>=0.1.0 (from mem0ai==1.0.4)\n  Using cached upstash_vector-0.8.0-py3-none-any.whl.metadata (17 kB)\nCollecting valkey>=6.0.0 (from mem0ai==1.0.4)\n  Using cached valkey-6.1.1-py3-none-any.whl.metadata (8.2 kB)\nCollecting vecs>=0.4.0 (from mem0ai==1.0.4)\n  Using cached vecs-0.4.5-py3-none-any.whl\nCollecting weaviate-client<4.15.0,>=4.4.0 (from mem0ai==1.0.4)\n  Using cached weaviate_client-4.14.4-py3-none-any.whl.metadata (3.7 kB)\nCollecting elastic-transport<9,>=8.15.1 (from elasticsearch<9.0.0,>=8.0.0->mem0ai==1.0.4)\n  Using cached elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: python-dateutil in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from elasticsearch<9.0.0,>=8.0.0->mem0ai==1.0.4) (2.9.0.post0)\nRequirement already satisfied: typing-extensions in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from elasticsearch<9.0.0,>=8.0.0->mem0ai==1.0.4) (4.15.0)\nRequirement already satisfied: urllib3<3,>=1.26.2 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch<9.0.0,>=8.0.0->mem0ai==1.0.4) (2.6.3)\nRequirement already satisfied: certifi in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch<9.0.0,>=8.0.0->mem0ai==1.0.4) (2026.1.4)\nCollecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone<=7.3.0->mem0ai==1.0.4)\n  Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\nCollecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone<=7.3.0->mem0ai==1.0.4)\n  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\nCollecting packaging<25.0,>=24.2 (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<=7.3.0->mem0ai==1.0.4)\n  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: requests<3.0.0,>=2.32.3 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<=7.3.0->mem0ai==1.0.4) (2.32.5)\nRequirement already satisfied: setuptools>69 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from pymilvus<2.6.0,>=2.4.0->mem0ai==1.0.4) (80.9.0)\nRequirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.49.1 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from pymilvus<2.6.0,>=2.4.0->mem0ai==1.0.4) (1.78.1)\nCollecting python-dotenv<2.0.0,>=1.0.1 (from pymilvus<2.6.0,>=2.4.0->mem0ai==1.0.4)\n  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\nCollecting ujson>=2.0.0 (from pymilvus<2.6.0,>=2.4.0->mem0ai==1.0.4)\n  Using cached ujson-5.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.4 kB)\nCollecting pandas>=1.2.4 (from pymilvus<2.6.0,>=2.4.0->mem0ai==1.0.4)\n  Using cached pandas-3.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (79 kB)\nCollecting milvus-lite>=2.4.0 (from pymilvus<2.6.0,>=2.4.0->mem0ai==1.0.4)\n  Using cached milvus_lite-2.5.1-py3-none-macosx_11_0_arm64.whl.metadata (10.0 kB)\nCollecting PyJWT>=2.9.0 (from redis<6.0.0,>=5.0.0->mem0ai==1.0.4)\n  Using cached pyjwt-2.11.0-py3-none-any.whl.metadata (4.0 kB)\nCollecting jsonpath-ng>=1.5.0 (from redisvl<1.0.0,>=0.1.0->mem0ai==1.0.4)\n  Using cached jsonpath_ng-1.8.0-py3-none-any.whl\nCollecting ml-dtypes<1.0.0,>=0.4.0 (from redisvl<1.0.0,>=0.1.0->mem0ai==1.0.4)\n  Using cached ml_dtypes-0.5.4-cp311-cp311-macosx_10_9_universal2.whl.metadata (8.9 kB)\nRequirement already satisfied: numpy<3,>=1.26.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from redisvl<1.0.0,>=0.1.0->mem0ai==1.0.4) (2.4.2)\nCollecting python-ulid>=3.0.0 (from redisvl<1.0.0,>=0.1.0->mem0ai==1.0.4)\n  Using cached python_ulid-3.1.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting pyyaml<7.0,>=5.4 (from redisvl<1.0.0,>=0.1.0->mem0ai==1.0.4)\n  Using cached pyyaml-6.0.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.4 kB)\nCollecting tenacity>=8.2.2 (from redisvl<1.0.0,>=0.1.0->mem0ai==1.0.4)\n  Using cached tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from pydantic>=2.7.3->mem0ai==1.0.4) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from pydantic>=2.7.3->mem0ai==1.0.4) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from pydantic>=2.7.3->mem0ai==1.0.4) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<=7.3.0->mem0ai==1.0.4) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<=7.3.0->mem0ai==1.0.4) (3.11)\nRequirement already satisfied: httpx<0.29.0,>=0.26.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4) (0.28.1)\nCollecting validators==0.34.0 (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting authlib<1.3.2,>=1.2.1 (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\nCollecting grpcio-tools<2.0.0,>=1.66.2 (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached grpcio_tools-1.78.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\nCollecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached grpcio_health_checking-1.78.1-py3-none-any.whl.metadata (1.2 kB)\nCollecting deprecation<3.0.0,>=2.1.0 (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\nCollecting cryptography (from authlib<1.3.2,>=1.2.1->weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached cryptography-46.0.5-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\nINFO: pip is looking at multiple versions of grpcio-health-checking to determine which version is compatible with other requirements. This could take a while.\nCollecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached grpcio_health_checking-1.78.0-py3-none-any.whl.metadata (1.2 kB)\n  Using cached grpcio_health_checking-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_health_checking-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_health_checking-1.75.0-py3-none-any.whl.metadata (1.0 kB)\n  Using cached grpcio_health_checking-1.74.0-py3-none-any.whl.metadata (1.0 kB)\n  Using cached grpcio_health_checking-1.73.1-py3-none-any.whl.metadata (1.0 kB)\n  Using cached grpcio_health_checking-1.73.0-py3-none-any.whl.metadata (1.0 kB)\nINFO: pip is still looking at multiple versions of grpcio-health-checking to determine which version is compatible with other requirements. This could take a while.\n  Using cached grpcio_health_checking-1.72.2-py3-none-any.whl.metadata (1.0 kB)\n  Using cached grpcio_health_checking-1.72.1-py3-none-any.whl.metadata (1.0 kB)\n  Using cached grpcio_health_checking-1.71.2-py3-none-any.whl.metadata (1.0 kB)\nINFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\nCollecting grpcio-tools<2.0.0,>=1.66.2 (from weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached grpcio_tools-1.78.0-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.76.0-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.75.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.75.0-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.74.0-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.73.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.73.0-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\nINFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n  Using cached grpcio_tools-1.72.2-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.72.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (5.3 kB)\n  Using cached grpcio_tools-1.71.2-cp311-cp311-macosx_10_14_universal2.whl.metadata (5.3 kB)\nRequirement already satisfied: anyio in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4) (4.12.1)\nRequirement already satisfied: httpcore==1.* in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from httpx<0.29.0,>=0.26.0->weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4) (1.0.9)\nRequirement already satisfied: h11>=0.16 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4) (0.16.0)\nCollecting azure-core>=1.31.0 (from azure-identity>=1.24.0->mem0ai==1.0.4)\n  Using cached azure_core-1.38.2-py3-none-any.whl.metadata (48 kB)\nCollecting msal>=1.31.0 (from azure-identity>=1.24.0->mem0ai==1.0.4)\n  Using cached msal-1.35.0-py3-none-any.whl.metadata (11 kB)\nCollecting msal-extensions>=1.2.0 (from azure-identity>=1.24.0->mem0ai==1.0.4)\n  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\nCollecting azure-common>=1.1 (from azure-search-documents>=11.4.0b8->mem0ai==1.0.4)\n  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\nCollecting isodate>=0.6.0 (from azure-search-documents>=11.4.0b8->mem0ai==1.0.4)\n  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\nCollecting botocore<1.43.0,>=1.42.56 (from boto3>=1.34.0->mem0ai==1.0.4)\n  Using cached botocore-1.42.56-py3-none-any.whl.metadata (5.9 kB)\nCollecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.34.0->mem0ai==1.0.4)\n  Using cached jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\nCollecting s3transfer<0.17.0,>=0.16.0 (from boto3>=1.34.0->mem0ai==1.0.4)\n  Using cached s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: six>=1.5 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from python-dateutil->elasticsearch<9.0.0,>=8.0.0->mem0ai==1.0.4) (1.17.0)\nCollecting geomet>=1.1 (from cassandra-driver>=3.29.0->mem0ai==1.0.4)\n  Using cached geomet-1.1.0-py3-none-any.whl.metadata (11 kB)\nCollecting build>=1.0.3 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting pybase64>=1.4.1 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached pybase64-1.4.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.7 kB)\nCollecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached uvicorn-0.41.0-py3-none-any.whl.metadata (6.7 kB)\nCollecting posthog>=3.5.0 (from mem0ai==1.0.4)\n  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached onnxruntime-1.24.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (5.0 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting tokenizers>=0.13.2 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\nCollecting pypika>=0.48.9 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached pypika-0.51.1-py2.py3-none-any.whl.metadata (51 kB)\nRequirement already satisfied: tqdm>=4.65.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from chromadb>=0.4.24->mem0ai==1.0.4) (4.67.3)\nCollecting overrides>=7.3.1 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting importlib-resources (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\nCollecting bcrypt>=4.0.1 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\nCollecting typer>=0.9.0 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached typer-0.24.1-py3-none-any.whl.metadata (16 kB)\nCollecting kubernetes>=28.1.0 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting mmh3>=4.0.1 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached mmh3-5.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (14 kB)\nCollecting orjson>=3.9.12 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached orjson-3.11.7-cp311-cp311-macosx_15_0_arm64.whl.metadata (41 kB)\nCollecting rich>=10.11.0 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached rich-14.3.3-py3-none-any.whl.metadata (18 kB)\nCollecting jsonschema>=4.19.0 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: backoff>=1.10.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from posthog>=3.5.0->mem0ai==1.0.4) (2.2.1)\nRequirement already satisfied: distro>=1.5.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from posthog>=3.5.0->mem0ai==1.0.4) (1.9.0)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\nCollecting cffi>=2.0.0 (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.6 kB)\nCollecting pycparser (from cffi>=2.0.0->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client<4.15.0,>=4.4.0->mem0ai==1.0.4)\n  Using cached pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\nCollecting google-auth~=2.0 (from databricks-sdk>=0.63.0->mem0ai==1.0.4)\n  Using cached google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk>=0.63.0->mem0ai==1.0.4)\n  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk>=0.63.0->mem0ai==1.0.4)\n  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk>=0.63.0->mem0ai==1.0.4)\n  Using cached pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\nCollecting huggingface-hub<2.0,>=0.20 (from fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\nCollecting loguru<0.8.0,>=0.7.2 (from fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nCollecting pillow<12.0,>=10.3.0 (from fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached pillow-11.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\nCollecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached py_rust_stemmers-0.1.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.4 kB)\nCollecting filelock (from huggingface-hub<2.0,>=0.20->fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached filelock-3.24.3-py3-none-any.whl.metadata (2.0 kB)\nCollecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.20->fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\nCollecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.20->fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached hf_xet-1.3.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\nCollecting shellingham (from huggingface-hub<2.0,>=0.20->fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting typer-slim (from huggingface-hub<2.0,>=0.20->fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached typer_slim-0.24.0-py3-none-any.whl.metadata (4.2 kB)\nCollecting click (from geomet>=1.1->cassandra-driver>=3.29.0->mem0ai==1.0.4)\n  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\nCollecting websockets<15.1.0,>=13.0.0 (from google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\nRequirement already satisfied: sniffio in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from google-genai>=1.0.0->mem0ai==1.0.4) (1.3.1)\nCollecting aiohttp>=3.10.11 (from google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached aiohttp-3.13.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10.11->google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting aiosignal>=1.4.0 (from aiohttp>=3.10.11->google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting attrs>=17.3.0 (from aiohttp>=3.10.11->google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\nCollecting frozenlist>=1.1.1 (from aiohttp>=3.10.11->google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached frozenlist-1.8.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (20 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp>=3.10.11->google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached multidict-6.7.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.3 kB)\nCollecting propcache>=0.2.0 (from aiohttp>=3.10.11->google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached propcache-0.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\nCollecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10.11->google-genai>=1.0.0->mem0ai==1.0.4)\n  Using cached yarl-1.22.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (75 kB)\nCollecting google-ai-generativelanguage==0.6.15 (from google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\nCollecting google-api-core (from google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached google_api_core-2.30.0-py3-none-any.whl.metadata (3.1 kB)\nCollecting google-api-python-client (from google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached google_api_python_client-2.190.0-py3-none-any.whl.metadata (7.0 kB)\nCollecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached proto_plus-1.27.1-py3-none-any.whl.metadata (2.2 kB)\nCollecting googleapis-common-protos<2.0.0,>=1.56.3 (from google-api-core->google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\nCollecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached grpcio_status-1.78.1-py3-none-any.whl.metadata (1.3 kB)\nINFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n  Using cached grpcio_status-1.78.0-py3-none-any.whl.metadata (1.3 kB)\n  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\nINFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n  Using cached grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n  Using cached grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting rpds-py>=0.25.0 (from jsonschema>=4.19.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached rpds_py-0.30.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\nCollecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\nCollecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nCollecting langchain-core>=1.2.15 (from langchain-aws>=0.2.23->mem0ai==1.0.4)\n  Using cached langchain_core-1.2.15-py3-none-any.whl.metadata (4.4 kB)\nCollecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\nCollecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nCollecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached pydantic_settings-2.13.1-py3-none-any.whl.metadata (3.4 kB)\nCollecting langsmith<1.0.0,>=0.1.125 (from langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached langsmith-0.7.6-py3-none-any.whl.metadata (15 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\nCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\nCollecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core>=1.2.15->langchain-aws>=0.2.23->mem0ai==1.0.4)\n  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting uuid-utils<1.0,>=0.12.0 (from langchain-core>=1.2.15->langchain-aws>=0.2.23->mem0ai==1.0.4)\n  Using cached uuid_utils-0.14.1-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (4.8 kB)\nCollecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=1.2.15->langchain-aws>=0.2.23->mem0ai==1.0.4)\n  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\nCollecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nCollecting xxhash>=3.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached xxhash-3.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\nCollecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached zstandard-0.25.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.3 kB)\nCollecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.0.0->mem0ai==1.0.4)\n  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\nCollecting langchain>=1.0.0 (from langchain-memgraph>=0.1.0->mem0ai==1.0.4)\n  Using cached langchain-1.2.10-py3-none-any.whl.metadata (5.7 kB)\nCollecting memgraph-toolbox>=0.1.8 (from langchain-memgraph>=0.1.0->mem0ai==1.0.4)\n  Using cached memgraph_toolbox-0.1.9-py3-none-any.whl.metadata (5.0 kB)\nCollecting langgraph<1.1.0,>=1.0.8 (from langchain>=1.0.0->langchain-memgraph>=0.1.0->mem0ai==1.0.4)\n  Using cached langgraph-1.0.9-py3-none-any.whl.metadata (7.4 kB)\nCollecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.8->langchain>=1.0.0->langchain-memgraph>=0.1.0->mem0ai==1.0.4)\n  Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting langgraph-prebuilt<1.1.0,>=1.0.8 (from langgraph<1.1.0,>=1.0.8->langchain>=1.0.0->langchain-memgraph>=0.1.0->mem0ai==1.0.4)\n  Using cached langgraph_prebuilt-1.0.8-py3-none-any.whl.metadata (5.2 kB)\nCollecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.8->langchain>=1.0.0->langchain-memgraph>=0.1.0->mem0ai==1.0.4)\n  Using cached langgraph_sdk-0.3.9-py3-none-any.whl.metadata (1.6 kB)\nCollecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain>=1.0.0->langchain-memgraph>=0.1.0->mem0ai==1.0.4)\n  Using cached ormsgpack-1.12.2-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (3.2 kB)\nCollecting neo4j-graphrag<2.0.0,>=1.12.0 (from langchain-neo4j>=0.4.0->mem0ai==1.0.4)\n  Using cached neo4j_graphrag-1.13.0-py3-none-any.whl.metadata (19 kB)\nCollecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.20->fastembed>=0.3.1->mem0ai==1.0.4)\n  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nCollecting json-repair<0.45.0,>=0.44.1 (from neo4j-graphrag<2.0.0,>=1.12.0->langchain-neo4j>=0.4.0->mem0ai==1.0.4)\n  Using cached json_repair-0.44.1-py3-none-any.whl.metadata (12 kB)\nCollecting pypdf<7.0.0,>=6.0.0 (from neo4j-graphrag<2.0.0,>=1.12.0->langchain-neo4j>=0.4.0->mem0ai==1.0.4)\n  Using cached pypdf-6.7.3-py3-none-any.whl.metadata (7.1 kB)\nCollecting scipy<2.0.0,>=1.13.0 (from neo4j-graphrag<2.0.0,>=1.12.0->langchain-neo4j>=0.4.0->mem0ai==1.0.4)\n  Using cached scipy-1.17.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\nCollecting types-pyyaml<7.0.0,>=6.0.12.20240917 (from neo4j-graphrag<2.0.0,>=1.12.0->langchain-neo4j>=0.4.0->mem0ai==1.0.4)\n  Using cached types_pyyaml-6.0.12.20250915-py3-none-any.whl.metadata (1.7 kB)\nCollecting fastuuid>=0.13.0 (from litellm>=1.74.0->mem0ai==1.0.4)\n  Using cached fastuuid-0.14.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.1 kB)\nCollecting importlib-metadata>=6.8.0 (from litellm>=1.74.0->mem0ai==1.0.4)\n  Using cached importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\nCollecting jinja2<4.0.0,>=3.1.2 (from litellm>=1.74.0->mem0ai==1.0.4)\n  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting tiktoken>=0.7.0 (from litellm>=1.74.0->mem0ai==1.0.4)\n  Using cached tiktoken-0.12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\nCollecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm>=1.74.0->mem0ai==1.0.4)\n  Using cached markupsafe-3.0.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\nCollecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm>=1.74.0->mem0ai==1.0.4)\n  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\nCollecting sympy (from onnxruntime>=1.14.1->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: jiter<1,>=0.10.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from openai>=1.90.0->mem0ai==1.0.4) (0.13.0)\nCollecting Events (from opensearch-py>=2.0.0->mem0ai==1.0.4)\n  Using cached Events-0.5-py3-none-any.whl.metadata (3.9 kB)\nCollecting opensearch-protobufs==0.19.0 (from opensearch-py>=2.0.0->mem0ai==1.0.4)\n  Using cached opensearch_protobufs-0.19.0-py3-none-any.whl.metadata (678 bytes)\nCollecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\nCollecting mmh3>=4.0.1 (from chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\nCollecting nltk<4.0.0,>=3.9.1 (from pinecone-text>=0.10.0->mem0ai==1.0.4)\n  Using cached nltk-3.9.3-py3-none-any.whl.metadata (3.2 kB)\nCollecting types-requests<3.0.0,>=2.25.0 (from pinecone-text>=0.10.0->mem0ai==1.0.4)\n  Using cached types_requests-2.32.4.20260107-py3-none-any.whl.metadata (2.0 kB)\nCollecting joblib (from nltk<4.0.0,>=3.9.1->pinecone-text>=0.10.0->mem0ai==1.0.4)\n  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\nCollecting regex>=2021.8.3 (from nltk<4.0.0,>=3.9.1->pinecone-text>=0.10.0->mem0ai==1.0.4)\n  Using cached regex-2026.2.19-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\nCollecting future (from pymochow>=2.2.9->mem0ai==1.0.4)\n  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\nCollecting dnspython<3.0.0,>=2.6.1 (from pymongo>=4.13.2->mem0ai==1.0.4)\n  Using cached dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\nCollecting iniconfig>=1.0.1 (from pytest>=8.2.2->mem0ai==1.0.4)\n  Using cached iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\nCollecting pluggy<2,>=1.5 (from pytest>=8.2.2->mem0ai==1.0.4)\n  Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting pygments>=2.7.2 (from pytest>=8.2.2->mem0ai==1.0.4)\n  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: portalocker<4.0,>=2.7.0 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from qdrant-client>=1.9.1->mem0ai==1.0.4) (3.2.0)\nRequirement already satisfied: h2<5,>=3 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai==1.0.4) (4.3.0)\nRequirement already satisfied: hyperframe<7,>=6.1 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai==1.0.4) (6.1.0)\nRequirement already satisfied: hpack<5,>=4.1 in ./.agentpr_runtime/data/hatch/env/virtual/mem0ai/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai==1.0.4) (4.1.0)\nCollecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\nCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\nCollecting transformers<6.0.0,>=4.41.0 (from sentence-transformers>=5.0.0->mem0ai==1.0.4)\n  Using cached transformers-5.2.0-py3-none-any.whl.metadata (32 kB)\nCollecting torch>=1.11.0 (from sentence-transformers>=5.0.0->mem0ai==1.0.4)\n  Using cached torch-2.10.0-2-cp311-none-macosx_11_0_arm64.whl.metadata (31 kB)\nCollecting scikit-learn (from sentence-transformers>=5.0.0->mem0ai==1.0.4)\n  Using cached scikit_learn-1.8.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\nCollecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers>=5.0.0->mem0ai==1.0.4)\n  Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\nCollecting tabulate>=0.9.0 (from together>=0.2.10->mem0ai==1.0.4)\n  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nCollecting types-tabulate>=0.9.0.20240106 (from together>=0.2.10->mem0ai==1.0.4)\n  Using cached types_tabulate-0.9.0.20241207-py3-none-any.whl.metadata (1.8 kB)\nCollecting types-tqdm>=4.67.0.20250516 (from together>=0.2.10->mem0ai==1.0.4)\n  Using cached types_tqdm-4.67.3.20260205-py3-none-any.whl.metadata (1.7 kB)\nCollecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers>=5.0.0->mem0ai==1.0.4)\n  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nCollecting annotated-doc>=0.0.2 (from typer>=0.9.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached httptools-0.7.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.5 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached uvloop-0.22.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.20 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached watchfiles-1.1.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\nCollecting pgvector==0.3.* (from vecs>=0.4.0->mem0ai==1.0.4)\n  Using cached pgvector-0.3.6-py3-none-any.whl.metadata (13 kB)\nCollecting psycopg2-binary==2.9.* (from vecs>=0.4.0->mem0ai==1.0.4)\n  Using cached psycopg2_binary-2.9.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\nCollecting flupy==1.* (from vecs>=0.4.0->mem0ai==1.0.4)\n  Using cached flupy-1.2.3-py3-none-any.whl.metadata (4.2 kB)\nCollecting deprecated==1.2.* (from vecs>=0.4.0->mem0ai==1.0.4)\n  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\nCollecting wrapt<2,>=1.10 (from deprecated==1.2.*->vecs>=0.4.0->mem0ai==1.0.4)\n  Using cached wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\nCollecting google-cloud-aiplatform==1.71.1 (from google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl.metadata (32 kB)\nCollecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\nCollecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached google_cloud_bigquery-3.40.1-py3-none-any.whl.metadata (8.2 kB)\nCollecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached google_cloud_resource_manager-1.16.0-py3-none-any.whl.metadata (9.9 kB)\nCollecting shapely<3.0.0dev (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached shapely-2.1.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\nCollecting docstring-parser<1 (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\nWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\nCollecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\nCollecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached google_resumable_media-2.8.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai>=0.1.0->mem0ai==1.0.4)\n  Using cached google_crc32c-1.8.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (1.7 kB)\nCollecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached httplib2-0.31.2-py3-none-any.whl.metadata (2.2 kB)\nCollecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached google_auth_httplib2-0.3.0-py3-none-any.whl.metadata (3.1 kB)\nCollecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting pyparsing<4,>=3.1 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.3.0->mem0ai==1.0.4)\n  Using cached pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\nCollecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb>=0.4.24->mem0ai==1.0.4)\n  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\nCollecting threadpoolctl>=3.2.0 (from scikit-learn->sentence-transformers>=5.0.0->mem0ai==1.0.4)\n  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nUsing cached elasticsearch-8.19.3-py3-none-any.whl (952 kB)\nUsing cached elastic_transport-8.17.1-py3-none-any.whl (64 kB)\nUsing cached pinecone-7.3.0-py3-none-any.whl (587 kB)\nUsing cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\nUsing cached packaging-24.2-py3-none-any.whl (65 kB)\nUsing cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\nUsing cached psycopg_pool-3.3.0-py3-none-any.whl (39 kB)\nUsing cached pymilvus-2.5.18-py3-none-any.whl (244 kB)\nUsing cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\nUsing cached redis-5.3.1-py3-none-any.whl (272 kB)\nUsing cached redisvl-0.14.0-py3-none-any.whl (196 kB)\nUsing cached ml_dtypes-0.5.4-cp311-cp311-macosx_10_9_universal2.whl (679 kB)\nUsing cached pyyaml-6.0.3-cp311-cp311-macosx_11_0_arm64.whl (175 kB)\nUsing cached weaviate_client-4.14.4-py3-none-any.whl (437 kB)\nUsing cached validators-0.34.0-py3-none-any.whl (43 kB)\nUsing cached Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\nUsing cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\nUsing cached grpcio_health_checking-1.71.2-py3-none-any.whl (18 kB)\nUsing cached grpcio_tools-1.71.2-cp311-cp311-macosx_10_14_universal2.whl (5.4 MB)\nUsing cached azure_identity-1.25.2-py3-none-any.whl (191 kB)\nUsing cached azure_core-1.38.2-py3-none-any.whl (217 kB)\nUsing cached azure_search_documents-11.7.0b2-py3-none-any.whl (432 kB)\nUsing cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nUsing cached boto3-1.42.56-py3-none-any.whl (140 kB)\nUsing cached botocore-1.42.56-py3-none-any.whl (14.6 MB)\nUsing cached jmespath-1.1.0-py3-none-any.whl (20 kB)\nUsing cached s3transfer-0.16.0-py3-none-any.whl (86 kB)\nUsing cached cassandra_driver-3.29.3-cp311-cp311-macosx_11_0_arm64.whl (364 kB)\nUsing cached chromadb-1.5.1-cp39-abi3-macosx_11_0_arm64.whl (20.0 MB)\nUsing cached posthog-5.4.0-py3-none-any.whl (105 kB)\nUsing cached bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl (495 kB)\nUsing cached build-1.4.0-py3-none-any.whl (24 kB)\nUsing cached cryptography-46.0.5-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\nUsing cached cffi-2.0.0-cp311-cp311-macosx_11_0_arm64.whl (180 kB)\nUsing cached databricks_sdk-0.92.0-py3-none-any.whl (810 kB)\nUsing cached google_auth-2.48.0-py3-none-any.whl (236 kB)\nUsing cached rsa-4.9.1-py3-none-any.whl (34 kB)\nUsing cached dbutils-3.1.2-py3-none-any.whl (32 kB)\nUsing cached faiss_cpu-1.13.2-cp310-abi3-macosx_14_0_arm64.whl (3.5 MB)\nUsing cached fastembed-0.7.4-py3-none-any.whl (108 kB)\nUsing cached huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\nUsing cached hf_xet-1.3.0-cp37-abi3-macosx_11_0_arm64.whl (3.5 MB)\nUsing cached loguru-0.7.3-py3-none-any.whl (61 kB)\nUsing cached pillow-11.3.0-cp311-cp311-macosx_11_0_arm64.whl (4.7 MB)\nUsing cached py_rust_stemmers-0.1.5-cp311-cp311-macosx_11_0_arm64.whl (272 kB)\nUsing cached tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl (3.0 MB)\nUsing cached geomet-1.1.0-py3-none-any.whl (31 kB)\nUsing cached google_genai-1.64.0-py3-none-any.whl (728 kB)\nUsing cached tenacity-9.1.4-py3-none-any.whl (28 kB)\nUsing cached websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl (173 kB)\nUsing cached aiohttp-3.13.3-cp311-cp311-macosx_11_0_arm64.whl (494 kB)\nUsing cached multidict-6.7.1-cp311-cp311-macosx_11_0_arm64.whl (44 kB)\nUsing cached yarl-1.22.0-cp311-cp311-macosx_11_0_arm64.whl (94 kB)\nUsing cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nUsing cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\nUsing cached attrs-25.4.0-py3-none-any.whl (67 kB)\nUsing cached frozenlist-1.8.0-cp311-cp311-macosx_11_0_arm64.whl (50 kB)\nUsing cached google_generativeai-0.8.6-py3-none-any.whl (155 kB)\nUsing cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\nUsing cached google_api_core-2.30.0-py3-none-any.whl (173 kB)\nUsing cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\nUsing cached grpcio_status-1.71.2-py3-none-any.whl (14 kB)\nUsing cached proto_plus-1.27.1-py3-none-any.whl (50 kB)\nUsing cached groq-1.0.0-py3-none-any.whl (138 kB)\nUsing cached isodate-0.7.2-py3-none-any.whl (22 kB)\nUsing cached jsonschema-4.26.0-py3-none-any.whl (90 kB)\nUsing cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\nUsing cached kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\nUsing cached durationpy-0.10-py3-none-any.whl (3.9 kB)\nUsing cached kuzu-0.11.3-cp311-cp311-macosx_11_0_arm64.whl (4.1 MB)\nUsing cached langchain_aws-1.3.0-py3-none-any.whl (170 kB)\nUsing cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\nUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nUsing cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\nUsing cached langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\nUsing cached langchain_core-1.2.15-py3-none-any.whl (502 kB)\nUsing cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nUsing cached langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\nUsing cached langsmith-0.7.6-py3-none-any.whl (325 kB)\nUsing cached marshmallow-3.26.2-py3-none-any.whl (50 kB)\nUsing cached pydantic_settings-2.13.1-py3-none-any.whl (58 kB)\nUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nUsing cached uuid_utils-0.14.1-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (604 kB)\nUsing cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nUsing cached langchain_memgraph-0.1.12-py3-none-any.whl (20 kB)\nUsing cached langchain-1.2.10-py3-none-any.whl (111 kB)\nUsing cached langgraph-1.0.9-py3-none-any.whl (158 kB)\nUsing cached langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\nUsing cached langgraph_prebuilt-1.0.8-py3-none-any.whl (35 kB)\nUsing cached langgraph_sdk-0.3.9-py3-none-any.whl (90 kB)\nUsing cached langchain_neo4j-0.8.0-py3-none-any.whl (48 kB)\nUsing cached neo4j-6.1.0-py3-none-any.whl (325 kB)\nUsing cached neo4j_graphrag-1.13.0-py3-none-any.whl (222 kB)\nUsing cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\nUsing cached json_repair-0.44.1-py3-none-any.whl (22 kB)\nUsing cached pypdf-6.7.3-py3-none-any.whl (331 kB)\nUsing cached scipy-1.17.1-cp311-cp311-macosx_14_0_arm64.whl (20.3 MB)\nUsing cached types_pyyaml-6.0.12.20250915-py3-none-any.whl (20 kB)\nUsing cached litellm-1.81.15-py3-none-any.whl (14.7 MB)\nUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\nUsing cached fastuuid-0.14.0-cp311-cp311-macosx_11_0_arm64.whl (254 kB)\nUsing cached importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\nUsing cached markupsafe-3.0.3-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\nUsing cached memgraph_toolbox-0.1.9-py3-none-any.whl (31 kB)\nUsing cached milvus_lite-2.5.1-py3-none-macosx_11_0_arm64.whl (24.4 MB)\nUsing cached msal-1.35.0-py3-none-any.whl (120 kB)\nUsing cached pyjwt-2.11.0-py3-none-any.whl (28 kB)\nUsing cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\nUsing cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\nUsing cached ollama-0.6.1-py3-none-any.whl (14 kB)\nUsing cached onnxruntime-1.24.2-cp311-cp311-macosx_14_0_arm64.whl (17.2 MB)\nUsing cached opensearch_py-3.1.0-py3-none-any.whl (385 kB)\nUsing cached opensearch_protobufs-0.19.0-py3-none-any.whl (39 kB)\nUsing cached opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\nUsing cached opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\nUsing cached opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\nUsing cached opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\nUsing cached opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\nUsing cached opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\nUsing cached orjson-3.11.7-cp311-cp311-macosx_15_0_arm64.whl (125 kB)\nUsing cached ormsgpack-1.12.2-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (378 kB)\nUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\nUsing cached pandas-3.0.1-cp311-cp311-macosx_11_0_arm64.whl (9.9 MB)\nUsing cached pinecone_text-0.11.0-py3-none-any.whl (22 kB)\nUsing cached mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\nUsing cached nltk-3.9.3-py3-none-any.whl (1.5 MB)\nUsing cached types_requests-2.32.4.20260107-py3-none-any.whl (20 kB)\nUsing cached propcache-0.4.1-cp311-cp311-macosx_11_0_arm64.whl (47 kB)\nUsing cached psycopg-3.3.3-py3-none-any.whl (212 kB)\nUsing cached pyasn1-0.6.2-py3-none-any.whl (83 kB)\nUsing cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\nUsing cached pybase64-1.4.3-cp311-cp311-macosx_11_0_arm64.whl (31 kB)\nUsing cached pymochow-2.3.6-py3-none-any.whl (78 kB)\nUsing cached pymongo-4.16.0-cp311-cp311-macosx_11_0_arm64.whl (862 kB)\nUsing cached dnspython-2.8.0-py3-none-any.whl (331 kB)\nUsing cached pymysql-1.1.2-py3-none-any.whl (45 kB)\nUsing cached pypika-0.51.1-py2.py3-none-any.whl (60 kB)\nUsing cached pytest-9.0.2-py3-none-any.whl (374 kB)\nUsing cached pluggy-1.6.0-py3-none-any.whl (20 kB)\nUsing cached iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\nUsing cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\nUsing cached pytest_asyncio-1.3.0-py3-none-any.whl (15 kB)\nUsing cached pytest_mock-3.15.1-py3-none-any.whl (10 kB)\nUsing cached python_ulid-3.1.0-py3-none-any.whl (11 kB)\nUsing cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nUsing cached referencing-0.37.0-py3-none-any.whl (26 kB)\nUsing cached regex-2026.2.19-cp311-cp311-macosx_11_0_arm64.whl (288 kB)\nUsing cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nUsing cached rich-14.3.3-py3-none-any.whl (310 kB)\nUsing cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\nUsing cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nUsing cached rpds_py-0.30.0-cp311-cp311-macosx_11_0_arm64.whl (359 kB)\nUsing cached sentence_transformers-5.2.3-py3-none-any.whl (494 kB)\nUsing cached transformers-5.2.0-py3-none-any.whl (10.4 MB)\nUsing cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\nUsing cached tiktoken-0.12.0-cp311-cp311-macosx_11_0_arm64.whl (995 kB)\nUsing cached together-2.2.0-py3-none-any.whl (330 kB)\nUsing cached click-8.3.1-py3-none-any.whl (108 kB)\nUsing cached filelock-3.24.3-py3-none-any.whl (24 kB)\nUsing cached tabulate-0.9.0-py3-none-any.whl (35 kB)\nUsing cached torch-2.10.0-2-cp311-none-macosx_11_0_arm64.whl (79.4 MB)\nUsing cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\nUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\nUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\nUsing cached typer-0.24.1-py3-none-any.whl (56 kB)\nUsing cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\nUsing cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\nUsing cached types_tabulate-0.9.0.20241207-py3-none-any.whl (8.3 kB)\nUsing cached types_tqdm-4.67.3.20260205-py3-none-any.whl (23 kB)\nUsing cached ujson-5.11.0-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\nUsing cached upstash_vector-0.8.0-py3-none-any.whl (18 kB)\nUsing cached uvicorn-0.41.0-py3-none-any.whl (68 kB)\nUsing cached httptools-0.7.1-cp311-cp311-macosx_11_0_arm64.whl (110 kB)\nUsing cached uvloop-0.22.1-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\nUsing cached valkey-6.1.1-py3-none-any.whl (259 kB)\nUsing cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\nUsing cached flupy-1.2.3-py3-none-any.whl (12 kB)\nUsing cached pgvector-0.3.6-py3-none-any.whl (24 kB)\nUsing cached psycopg2_binary-2.9.11-cp311-cp311-macosx_11_0_arm64.whl (3.9 MB)\nUsing cached wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\nUsing cached vertexai-1.71.1-py3-none-any.whl (7.3 kB)\nUsing cached google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl (6.2 MB)\nUsing cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\nUsing cached google_cloud_bigquery-3.40.1-py3-none-any.whl (262 kB)\nUsing cached google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\nUsing cached google_cloud_resource_manager-1.16.0-py3-none-any.whl (400 kB)\nUsing cached google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\nUsing cached google_crc32c-1.8.0-cp311-cp311-macosx_12_0_arm64.whl (31 kB)\nUsing cached google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\nUsing cached grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\nUsing cached shapely-2.1.2-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\nUsing cached watchfiles-1.1.1-cp311-cp311-macosx_11_0_arm64.whl (394 kB)\nUsing cached websocket_client-1.9.0-py3-none-any.whl (82 kB)\nUsing cached xxhash-3.6.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\nUsing cached zipp-3.23.0-py3-none-any.whl (10 kB)\nUsing cached zstandard-0.25.0-cp311-cp311-macosx_11_0_arm64.whl (640 kB)\nUsing cached Events-0.5-py3-none-any.whl (6.8 kB)\nUsing cached flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\nUsing cached future-1.0.0-py3-none-any.whl (491 kB)\nUsing cached google_api_python_client-2.190.0-py3-none-any.whl (14.7 MB)\nUsing cached google_auth_httplib2-0.3.0-py3-none-any.whl (9.5 kB)\nUsing cached httplib2-0.31.2-py3-none-any.whl (91 kB)\nUsing cached pyparsing-3.3.2-py3-none-any.whl (122 kB)\nUsing cached uritemplate-4.2.0-py3-none-any.whl (11 kB)\nUsing cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\nUsing cached joblib-1.5.3-py3-none-any.whl (309 kB)\nUsing cached pycparser-3.0-py3-none-any.whl (48 kB)\nUsing cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\nUsing cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\nUsing cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\nUsing cached scikit_learn-1.8.0-cp311-cp311-macosx_12_0_arm64.whl (8.1 MB)\nUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nUsing cached typer_slim-0.24.0-py3-none-any.whl (3.4 kB)\nBuilding wheels for collected packages: mem0ai\n  Building editable for mem0ai (pyproject.toml): started\n  Building editable for mem0ai (pyproject.toml): finished with status 'done'\n  Created wheel for mem0ai: filename=mem0ai-1.0.4-py3-none-any.whl size=12261 sha256=5074f4bd44238c2cea123c92becb277cb0a13b17afde7ce6cbe3287eb3197169\n  Stored in directory: /Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/tmp/pip-ephem-wheel-cache-lbkp538s/wheels/7d/fc/7b/d5fa9dae1e4775d20f4384cc0a894f229f5f25ad8f4ff497d0\nSuccessfully built mem0ai\nInstalling collected packages: pypika, py-rust-stemmers, mpmath, mmh3, kuzu, jsonpath-ng, flatbuffers, Events, durationpy, azure-common, zstandard, zipp, xxhash, wrapt, websockets, websocket-client, valkey, validators, uvloop, uuid-utils, uritemplate, ujson, types-tabulate, types-requests, types-pyyaml, threadpoolctl, tenacity, tabulate, sympy, shellingham, shapely, scipy, safetensors, rpds-py, regex, rank-bm25, pyyaml, python-ulid, python-dotenv, pyproject_hooks, pypdf, pyparsing, pymysql, PyJWT, pygments, pycparser, pybase64, pyasn1, psycopg2-binary, psycopg-pool, psycopg, proto-plus, propcache, pluggy, pinecone-plugin-interface, pillow, pgvector, packaging, overrides, ormsgpack, orjson, opentelemetry-proto, oauthlib, networkx, neo4j, mypy-extensions, multidict, ml-dtypes, milvus-lite, mdurl, MarkupSafe, loguru, jsonpointer, json-repair, joblib, jmespath, isodate, iniconfig, importlib-resources, httpx-sse, httptools, hf-xet, googleapis-common-protos, google-crc32c, future, fsspec, frozenlist, flupy, filelock, fastuuid, elastic-transport, docstring-parser, dnspython, dbutils, click, bcrypt, attrs, annotated-doc, aiohappyeyeballs, yarl, watchfiles, uvicorn, typing-inspect, types-tqdm, tiktoken, scikit-learn, rsa, requests-toolbelt, requests-oauthlib, referencing, redis, pytest, pymongo, pymochow, pyasn1-modules, posthog, pinecone-plugin-assistant, pandas, opentelemetry-exporter-otlp-proto-common, opensearch-protobufs, onnxruntime, nltk, memgraph-toolbox, marshmallow, markdown-it-py, jsonpatch, jinja2, importlib-metadata, httplib2, grpcio-tools, grpcio-status, grpcio-health-checking, google-resumable-media, geomet, faiss-cpu, elasticsearch, deprecation, deprecated, cffi, build, botocore, azure-core, aiosignal, vecs, upstash-vector, torch, s3transfer, rich, redisvl, pytest-mock, pytest-asyncio, pymilvus, pydantic-settings, pinecone-text, pinecone, opentelemetry-api, opensearch-py, ollama, neo4j-graphrag, langsmith, langgraph-sdk, kubernetes, jsonschema-specifications, grpc-google-iam-v1, groq, dataclasses-json, cryptography, cassandra-driver, azure-search-documents, aiohttp, typer, together, opentelemetry-semantic-conventions, langchain-core, jsonschema, google-auth, boto3, authlib, weaviate-client, typer-slim, opentelemetry-sdk, msal, mem0ai, langgraph-checkpoint, langchain-text-splitters, langchain-aws, google-auth-httplib2, google-api-core, databricks-sdk, opentelemetry-exporter-otlp-proto-grpc, msal-extensions, langgraph-prebuilt, langchain-classic, huggingface-hub, google-genai, google-cloud-core, google-api-python-client, tokenizers, langgraph, langchain-community, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-ai-generativelanguage, azure-identity, transformers, litellm, langchain-neo4j, langchain, google-generativeai, google-cloud-aiplatform, fastembed, chromadb, sentence-transformers, langchain-memgraph, vertexai\n  Attempting uninstall: posthog\n    Found existing installation: posthog 7.9.3\n    Uninstalling posthog-7.9.3:\n      Successfully uninstalled posthog-7.9.3\n  Attempting uninstall: mem0ai\n    Found existing installation: mem0ai 1.0.4\n    Uninstalling mem0ai-1.0.4:\n      Successfully uninstalled mem0ai-1.0.4\n\nSuccessfully installed Events-0.5 MarkupSafe-3.0.3 PyJWT-2.11.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 annotated-doc-0.0.4 attrs-25.4.0 authlib-1.3.1 azure-common-1.1.28 azure-core-1.38.2 azure-identity-1.25.2 azure-search-documents-11.7.0b2 bcrypt-5.0.0 boto3-1.42.56 botocore-1.42.56 build-1.4.0 cassandra-driver-3.29.3 cffi-2.0.0 chromadb-1.5.1 click-8.3.1 cryptography-46.0.5 databricks-sdk-0.92.0 dataclasses-json-0.6.7 dbutils-3.1.2 deprecated-1.2.18 deprecation-2.1.0 dnspython-2.8.0 docstring-parser-0.17.0 durationpy-0.10 elastic-transport-8.17.1 elasticsearch-8.19.3 faiss-cpu-1.13.2 fastembed-0.7.4 fastuuid-0.14.0 filelock-3.24.3 flatbuffers-25.12.19 flupy-1.2.3 frozenlist-1.8.0 fsspec-2024.12.0 future-1.0.0 geomet-1.1.0 google-ai-generativelanguage-0.6.15 google-api-core-2.30.0 google-api-python-client-2.190.0 google-auth-2.48.0 google-auth-httplib2-0.3.0 google-cloud-aiplatform-1.71.1 google-cloud-bigquery-3.40.1 google-cloud-core-2.5.0 google-cloud-resource-manager-1.16.0 google-cloud-storage-2.19.0 google-crc32c-1.8.0 google-genai-1.64.0 google-generativeai-0.8.6 google-resumable-media-2.8.0 googleapis-common-protos-1.72.0 groq-1.0.0 grpc-google-iam-v1-0.14.3 grpcio-health-checking-1.71.2 grpcio-status-1.71.2 grpcio-tools-1.71.2 hf-xet-1.3.0 httplib2-0.31.2 httptools-0.7.1 httpx-sse-0.4.3 huggingface-hub-1.4.1 importlib-metadata-8.7.1 importlib-resources-6.5.2 iniconfig-2.3.0 isodate-0.7.2 jinja2-3.1.6 jmespath-1.1.0 joblib-1.5.3 json-repair-0.44.1 jsonpatch-1.33 jsonpath-ng-1.8.0 jsonpointer-3.0.0 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 kubernetes-35.0.0 kuzu-0.11.3 langchain-1.2.10 langchain-aws-1.3.0 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.15 langchain-memgraph-0.1.12 langchain-neo4j-0.8.0 langchain-text-splitters-1.1.1 langgraph-1.0.9 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.8 langgraph-sdk-0.3.9 langsmith-0.7.6 litellm-1.81.15 loguru-0.7.3 markdown-it-py-4.0.0 marshmallow-3.26.2 mdurl-0.1.2 mem0ai-1.0.4 memgraph-toolbox-0.1.9 milvus-lite-2.5.1 ml-dtypes-0.5.4 mmh3-4.1.0 mpmath-1.3.0 msal-1.35.0 msal-extensions-1.3.1 multidict-6.7.1 mypy-extensions-1.1.0 neo4j-6.1.0 neo4j-graphrag-1.13.0 networkx-3.6.1 nltk-3.9.3 oauthlib-3.3.1 ollama-0.6.1 onnxruntime-1.24.2 opensearch-protobufs-0.19.0 opensearch-py-3.1.0 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 orjson-3.11.7 ormsgpack-1.12.2 overrides-7.7.0 packaging-24.2 pandas-3.0.1 pgvector-0.3.6 pillow-11.3.0 pinecone-7.3.0 pinecone-plugin-assistant-1.8.0 pinecone-plugin-interface-0.0.7 pinecone-text-0.11.0 pluggy-1.6.0 posthog-5.4.0 propcache-0.4.1 proto-plus-1.27.1 psycopg-3.3.3 psycopg-pool-3.3.0 psycopg2-binary-2.9.11 py-rust-stemmers-0.1.5 pyasn1-0.6.2 pyasn1-modules-0.4.2 pybase64-1.4.3 pycparser-3.0 pydantic-settings-2.13.1 pygments-2.19.2 pymilvus-2.5.18 pymochow-2.3.6 pymongo-4.16.0 pymysql-1.1.2 pyparsing-3.3.2 pypdf-6.7.3 pypika-0.51.1 pyproject_hooks-1.2.0 pytest-9.0.2 pytest-asyncio-1.3.0 pytest-mock-3.15.1 python-dotenv-1.2.1 python-ulid-3.1.0 pyyaml-6.0.3 rank-bm25-0.2.2 redis-5.3.1 redisvl-0.14.0 referencing-0.37.0 regex-2026.2.19 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.3.3 rpds-py-0.30.0 rsa-4.9.1 s3transfer-0.16.0 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.17.1 sentence-transformers-5.2.3 shapely-2.1.2 shellingham-1.5.4 sympy-1.14.0 tabulate-0.9.0 tenacity-9.1.4 threadpoolctl-3.6.0 tiktoken-0.12.0 together-2.2.0 tokenizers-0.22.2 torch-2.10.0 transformers-5.2.0 typer-0.24.1 typer-slim-0.24.0 types-pyyaml-6.0.12.20250915 types-requests-2.32.4.20260107 types-tabulate-0.9.0.20241207 types-tqdm-4.67.3.20260205 typing-inspect-0.9.0 ujson-5.11.0 upstash-vector-0.8.0 uritemplate-4.2.0 uuid-utils-0.14.1 uvicorn-0.41.0 uvloop-0.22.1 validators-0.34.0 valkey-6.1.1 vecs-0.4.5 vertexai-1.71.1 watchfiles-1.1.1 weaviate-client-4.14.4 websocket-client-1.9.0 websockets-15.0.1 wrapt-1.17.3 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0 zstandard-0.25.0\nCollecting ruff\n  Downloading ruff-0.15.2-py3-none-macosx_11_0_arm64.whl.metadata (26 kB)\nDownloading ruff-0.15.2-py3-none-macosx_11_0_arm64.whl (10.2 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.2/10.2 MB 39.7 MB/s  0:00:00\nInstalling collected packages: ruff\nSuccessfully installed ruff-0.15.2\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_86","type":"reasoning","text":"**Verifying test environment path**"}}
{"type":"item.started","item":{"id":"item_87","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run which pytest && HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pytest --version'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_87","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run which pytest && HATCH_PYTHON=/opt/homebrew/bin/python3.11 hatch run pytest --version'","aggregated_output":"/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/.agentpr_runtime/data/hatch/env/virtual/mem0ai/bin/pytest\npytest 9.0.2\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_88","type":"reasoning","text":"**Running lint checks**"}}
{"type":"item.started","item":{"id":"item_89","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 make lint'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_89","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 make lint'","aggregated_output":"All checks passed!\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_90","type":"reasoning","text":"**Running extended tests**"}}
{"type":"item.completed","item":{"id":"item_91","type":"agent_message","text":"Dependency setup is now aligned with CI in the local hatch env, and lint passes. Iâ€™m running full `make test` next; if there are failures, Iâ€™ll separate pre-existing failures from any Forge regression."}}
{"type":"item.started","item":{"id":"item_92","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 make test'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_93","type":"reasoning","text":"**Waiting for test output**"}}
{"type":"item.completed","item":{"id":"item_92","type":"command_execution","command":"/bin/zsh -lc 'HATCH_PYTHON=/opt/homebrew/bin/python3.11 make test'","aggregated_output":"============================= test session starts ==============================\nplatform darwin -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0\nrootdir: /Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0\nconfigfile: pyproject.toml\nplugins: anyio-4.12.1, mock-3.15.1, langsmith-0.7.6, asyncio-1.3.0\nasyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollected 531 items\n\ntests/configs/test_prompts.py ...                                        [  0%]\ntests/embeddings/test_azure_openai_embeddings.py ........                [  2%]\ntests/embeddings/test_fastembed_embeddings.py ..                         [  2%]\ntests/embeddings/test_gemini_emeddings.py ....                           [  3%]\ntests/embeddings/test_huggingface_embeddings.py ......                   [  4%]\ntests/embeddings/test_lm_studio_embeddings.py .                          [  4%]\ntests/embeddings/test_ollama_embeddings.py ..                            [  4%]\ntests/embeddings/test_openai_embeddings.py .....                         [  5%]\ntests/embeddings/test_vertexai_embeddings.py .......                     [  7%]\ntests/llms/test_azure_openai.py ........                                 [  8%]\ntests/llms/test_azure_openai_structured.py ....                          [  9%]\ntests/llms/test_deepseek.py ...                                          [  9%]\ntests/llms/test_gemini.py ..                                             [ 10%]\ntests/llms/test_groq.py ..                                               [ 10%]\ntests/llms/test_langchain.py .....                                       [ 11%]\ntests/llms/test_litellm.py ...                                           [ 12%]\ntests/llms/test_lm_studio.py ..                                          [ 12%]\ntests/llms/test_ollama.py .                                              [ 12%]\ntests/llms/test_openai.py .......                                        [ 14%]\ntests/llms/test_together.py ..                                           [ 14%]\ntests/llms/test_vllm.py ....                                             [ 15%]\ntests/memory/test_kuzu.py .....                                          [ 16%]\ntests/memory/test_main.py ....                                           [ 16%]\ntests/memory/test_neo4j_cypher_syntax.py ..............                  [ 19%]\ntests/memory/test_neptune_analytics_memory.py ...........                [ 21%]\ntests/memory/test_neptune_memory.py ............                         [ 23%]\ntests/memory/test_storage.py ..............                              [ 26%]\ntests/test_main.py .............                                         [ 29%]\ntests/test_memory.py ...........                                         [ 31%]\ntests/test_memory_integration.py ....                                    [ 31%]\ntests/test_proxy.py ......                                               [ 32%]\ntests/test_telemetry.py ...                                              [ 33%]\ntests/vector_stores/test_azure_ai_search.py .....................        [ 37%]\ntests/vector_stores/test_azure_mysql.py ............s.                   [ 40%]\ntests/vector_stores/test_baidu.py ..........                             [ 41%]\ntests/vector_stores/test_cassandra.py .................                  [ 45%]\ntests/vector_stores/test_chroma.py ...............                       [ 48%]\ntests/vector_stores/test_databricks.py ..............                    [ 50%]\ntests/vector_stores/test_elasticsearch.py ..............                 [ 53%]\ntests/vector_stores/test_faiss.py ...........                            [ 55%]\ntests/vector_stores/test_langchain_vector_store.py ..........            [ 57%]\ntests/vector_stores/test_milvus.py ..............                        [ 59%]\ntests/vector_stores/test_mongodb.py ................                     [ 62%]\ntests/vector_stores/test_neptune_analytics.py sssssssss                  [ 64%]\ntests/vector_stores/test_opensearch.py ............                      [ 66%]\ntests/vector_stores/test_pgvector.py ................................... [ 73%]\n...............                                                          [ 76%]\ntests/vector_stores/test_pinecone.py ...............                     [ 79%]\ntests/vector_stores/test_qdrant.py ...................                   [ 82%]\ntests/vector_stores/test_s3_vectors.py ........                          [ 84%]\ntests/vector_stores/test_supabase.py .........                           [ 85%]\ntests/vector_stores/test_upstash_vector.py ..................            [ 89%]\ntests/vector_stores/test_valkey.py ..................................... [ 96%]\n......                                                                   [ 97%]\ntests/vector_stores/test_vertex_ai_vector_search.py .....                [ 98%]\ntests/vector_stores/test_weaviate.py .........                           [100%]\n\n================== 521 passed, 10 skipped in 96.49s (0:01:36) ==================\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_94","type":"reasoning","text":"**Verifying no tracked changes**"}}
{"type":"item.started","item":{"id":"item_95","type":"command_execution","command":"/bin/zsh -lc 'git status --short'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_95","type":"command_execution","command":"/bin/zsh -lc 'git status --short'","aggregated_output":"?? .agentpr_runtime/\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_96","type":"reasoning","text":"**Summarizing final status and results**"}}
{"type":"item.completed","item":{"id":"item_97","type":"agent_message","text":"Status: PASS\n\nFiles changed:\n- No additional tracked file changes were made in this stage (`git status --short` shows only untracked `.agentpr_runtime/`).\n- Forge integration is already present on this branch in:\n  - [mem0/llms/openai.py](/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/mem0/llms/openai.py)\n  - [docs/components/llms/models/forge.mdx](/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/docs/components/llms/models/forge.mdx)\n  - [docs/llms.txt](/Users/yi/Documents/Career/TensorBlcok/agentpr/workspaces/mem0/docs/llms.txt)\n\nTest/lint results:\n- `HATCH_PYTHON=/opt/homebrew/bin/python3.11 make lint` -> PASS (`All checks passed!`)\n- `HATCH_PYTHON=/opt/homebrew/bin/python3.11 make test` -> PASS (`521 passed, 10 skipped in 96.49s`)\n- CI-style dependency bootstrap executed in the project-local hatch env before rerun:\n  - `hatch run pip install -e \".[test,graph,vector_stores,llms,extras]\"`\n  - `hatch run pip install ruff`\n\nNotes:\n- Initial `make test` failed in a preconfigured default env because global `pytest` was being used (missing test extras). Recreating/running hatch default with Python 3.11 and installing CI dependencies resolved this.\n- No policy blockers remain.\n\nWhat was pushed (if any):\n- Nothing was pushed (`allow_agent_push=false`; no commit/push performed)."}}
{"type":"turn.completed","usage":{"input_tokens":2377514,"cached_input_tokens":2214016,"output_tokens":12199}}
